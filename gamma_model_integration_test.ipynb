{
 "metadata": {
  "name": "",
  "signature": "sha256:a3ff3cbfc90f740c3f6c238d9140523ad978252eb3cf732203e7552486bd8ef9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Gamma model integration test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Try Gamma Poisson Model inference on data generated from that model. Should recover synthetic data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "If you want overdispersion in the model:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set the following to `True`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "overdisp = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Generate Test Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.stats as stats\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import gamma_model as gp\n",
      "from helpers import *\n",
      "%matplotlib inline\n",
      "\n",
      "np.random.seed(11739)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define model parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "U = 100  # units\n",
      "T = 10000  # time points/frames\n",
      "Kdata = 3  # number of latent states\n",
      "dt = 1/30  # seconds per frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Generate Markov chains"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make transition matrix\n",
      "A = np.array([[0.98, 0.05], [0.02, 0.95]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chain = np.empty((T, Kdata))\n",
      "\n",
      "chain[0, :] = 0  # start all categories \"off\"\n",
      "for t in xrange(1, T):\n",
      "    for k in xrange(Kdata):\n",
      "        chain[t, k] = stats.bernoulli.rvs(A[1, chain[t - 1, k]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matshow(chain.T);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Baseline distributions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bl_shape = 3\n",
      "bl_scale = 4\n",
      "# baselines should follow a different distribution\n",
      "bl = stats.gamma.rvs(a=bl_shape, scale=bl_scale, size=U) \n",
      "\n",
      "xx = np.linspace(0, 50, 1000)\n",
      "plt.plot(xx, stats.gamma.pdf(xx, a=bl_shape, scale=bl_scale))\n",
      "plt.title('Baseline firing distribution');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Firing rate effect distributions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# firing rates\n",
      "fr_shape = 15\n",
      "fr_rate = 15\n",
      "lam = stats.gamma.rvs(a=fr_shape, scale=1/fr_rate, size=(Kdata, U))\n",
      "\n",
      "xx = np.linspace(0, 5, 1000)\n",
      "plt.plot(xx, stats.gamma.pdf(xx, a=fr_shape, scale=1/fr_rate))\n",
      "plt.title('Category effect firing distribution');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overdispersion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if overdisp:\n",
      "    xx = np.linspace(0, 2, 300)\n",
      "    th_scale = 100\n",
      "    plt.plot(xx, stats.gamma.pdf(xx, a=th_scale, scale=1./th_scale))\n",
      "    plt.title('Overdispersion Effect');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "External regressors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# just as above, make a set of Markov-esque regressors\n",
      "\n",
      "# number of regressors\n",
      "R = 3  \n",
      "\n",
      "# \"transition matrix\" -- want regressors to have some temporal coherence\n",
      "AX = np.array([[0.98, 0.05], [0.02, 0.95]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xchain = np.empty((T, R))\n",
      "\n",
      "Xchain[0, :] = 0  # start second category off\n",
      "for t in xrange(1, T):\n",
      "    for k in xrange(0, R):\n",
      "        Xchain[t, k] = stats.bernoulli.rvs(AX[1, Xchain[t - 1, k]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matshow(Xchain.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xf = pd.DataFrame(Xchain, columns=map(lambda x: 'X' + str(x), xrange(R)))\n",
      "Xf.index.name = 'frame'\n",
      "Xf = Xf.reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xf.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make firing rate effects for each (regressor, unit)\n",
      "Xfr_shape = 45\n",
      "Xfr_scale = 1. / 45\n",
      "Xlam = stats.gamma.rvs(a=Xfr_shape, scale=Xfr_scale, size=(R, U))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx = np.linspace(0, 5, 1000)\n",
      "plt.plot(xx, stats.gamma.pdf(xx, a=Xfr_shape, scale=Xfr_scale))\n",
      "plt.title('Regressor effect firing distribution');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Calculate firing rates"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let $\\lambda_0$ be the baseline, $\\lambda_k$ the firing rate for latent category $i$ with binary indicator variable $z_{tk}$ and $\\nu_{r}$ be the firing rate effect for external regressor $r$ with value $x_{tr}$. Let $\\theta_{t}$ be an overdispersion factor for each time bin. The firing rate of unit $u$ at time $t$ is then given by\n",
      "\n",
      "$$\n",
      "\\mu_{tu} = \\lambda_{0u} \\theta_{tu} \\prod_k  \\lambda_{ku}^{z_{tk}}\n",
      "\\prod_r \\nu_{ru}^{x_{tr}}\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate rate within each time bin\n",
      "fr = bl * np.exp(chain.dot(np.log(lam)) + Xchain.dot(np.log(Xlam))) * dt\n",
      "fr += 1e-5  # in case we get exactly 0\n",
      "\n",
      "# add overdispersion\n",
      "if overdisp:\n",
      "    theta = stats.gamma.rvs(a=10, scale=1./10, size=fr.shape)\n",
      "    fr *= theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get a crude sense of population firing\n",
      "plt.hist(fr.ravel() / dt, bins=1000);\n",
      "plt.xlim(0, 50);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Look at generated data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matshow(fr.T / dt, vmax=30);\n",
      "plt.colorbar();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# draw from Poisson\n",
      "N = stats.poisson.rvs(fr)\n",
      "matshow(N.T, vmax=1);\n",
      "plt.colorbar();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make count frame\n",
      "df = pd.DataFrame(N)\n",
      "df.index.name = 'frame'\n",
      "df = df.reset_index()\n",
      "df = pd.melt(df, id_vars='frame')\n",
      "df.columns = ['frame', 'unit', 'count']\n",
      "df['movie'] = 1\n",
      "\n",
      "df = df.merge(Xf)\n",
      "\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, convert (frame, movie) pairs to unique times:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = frames_to_times(df)\n",
      "M = df.shape[0]\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Set up Priors"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Priors on baseline:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use a hierarchical model for both baselines and firing rate effects, with  \n",
      "$$\n",
      "\\lambda_{u} \\sim \\mathrm{Ga}(c, c\\theta) \\\\\n",
      "c \\sim \\text{Ga}(s, r) \\\\\n",
      "\\theta \\sim \\text{Ga}(t, w) \\\\\n",
      "\\mathbb{E}[\\lambda_{u}] = \\frac{1}{\\theta} \\\\\n",
      "\\mathrm{var}[\\lambda_{u}] = \\frac{1}{c \\theta^2}\n",
      "$$\n",
      "In other words, we can think of $\\frac{1}{\\theta}$ as a *mean parameter* and $\\frac{1}{c}$ as a *variance parameter*.\n",
      "\n",
      "We want the baseline rates to have a fairly reasonable prior and the effect rates to have a very sparse prior, closely concentrated around 1."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following function will help us get a sense of the distribution on $\\lambda$ induced by our hyperparameter choices."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bl_mean_shape = 2\n",
      "bl_mean_rate = 40 * dt  # actual parameter should be per-bin rate\n",
      "bl_shape_shape = 30\n",
      "bl_shape_rate = 30\n",
      "\n",
      "baseline_dict = ({\n",
      "            'prior_shape_shape': bl_shape_shape, \n",
      "            'prior_shape_rate': bl_shape_rate, \n",
      "            'prior_mean_shape': bl_mean_shape, \n",
      "            'prior_mean_rate': bl_mean_rate})\n",
      "\n",
      "# make some plots\n",
      "plt.figure(figsize=(12, 4))\n",
      "\n",
      "plt.subplot(1, 3, 1)\n",
      "xx = np.linspace(0, 50, 1000)\n",
      "plt.plot(xx, stats.invgamma.pdf(xx, a=bl_mean_shape, scale=bl_mean_rate / dt))\n",
      "plt.title('baseline mean parameter prior');\n",
      "plt.xlabel('spikes per second')\n",
      "\n",
      "plt.subplot(1, 3, 2)\n",
      "xx = np.linspace(0, 80, 1000)\n",
      "plt.plot(xx, stats.invgamma.pdf(xx, a=bl_shape_shape, scale=bl_shape_rate))\n",
      "plt.title('baseline variance parameter prior');\n",
      "plt.xlim(0, 15)\n",
      "\n",
      "plt.subplot(1, 3, 3)\n",
      "samples = gamma_from_hypers([bl_mean_shape, bl_mean_rate], \n",
      "                            [bl_shape_shape, bl_shape_rate], 1e5)\n",
      "sns.kdeplot(samples / dt, gridsize=1e4, clip=(0, 150))\n",
      "plt.title(r'$\\lambda$ baseline prior distribution')\n",
      "plt.xlim(0, 100);\n",
      "plt.xlabel('spikes per second');\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Priors on latent firing rate effects:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set number of categories to fit\n",
      "K = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fr_shape_shape = 2 * np.ones((K,))\n",
      "fr_shape_rate = 1e-3 * np.ones((K,))\n",
      "fr_mean_shape = 4000 * np.ones((K,))\n",
      "fr_mean_rate = 4000 * np.ones((K,))\n",
      "\n",
      "fr_latent_dict = ({\n",
      "            'prior_shape_shape': fr_shape_shape, \n",
      "            'prior_shape_rate': fr_shape_rate, \n",
      "            'prior_mean_shape': fr_mean_shape, \n",
      "            'prior_mean_rate': fr_mean_rate})\n",
      "\n",
      "# make some plots\n",
      "plt.figure(figsize=(12, 4))\n",
      "\n",
      "plt.subplot(1, 3, 1)\n",
      "xx = np.linspace(0, 2, 500)\n",
      "plt.plot(xx, stats.invgamma.pdf(xx, a=fr_mean_shape[0], scale=fr_mean_rate[0]))\n",
      "plt.title('effect mean parameter prior');\n",
      "\n",
      "plt.subplot(1, 3, 2)\n",
      "xx = np.linspace(0, 0.01, 500)\n",
      "plt.plot(xx, stats.invgamma.pdf(xx, a=fr_shape_shape[0], scale=fr_shape_rate[0]))\n",
      "plt.title('effect variance parameter prior');\n",
      "\n",
      "plt.subplot(1, 3, 3)\n",
      "samples = gamma_from_hypers([fr_mean_shape[0], fr_mean_rate[0]], \n",
      "                            [fr_shape_shape[0], fr_shape_rate[0]], 1e5)\n",
      "sns.kdeplot(samples, gridsize=5000, clip=(0, 5))\n",
      "plt.title(r'$\\lambda$ effect prior distribution')\n",
      "plt.xlim(0, 3);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Priors on $A$, $\\pi$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###### A ###############\n",
      "A_off = 10\n",
      "A_on = 1\n",
      "Avec = np.r_[A_off, A_on].reshape(2, 1, 1)\n",
      "A_prior = np.tile(Avec, (1, 2, K))\n",
      "\n",
      "###### pi ###############\n",
      "pi_off = 15\n",
      "pi_on = 1\n",
      "pi_prior = np.tile(np.r_[pi_off, pi_on].reshape(2, 1), (1, K))\n",
      "\n",
      "latent_dict = {'A_prior': A_prior, 'pi_prior': pi_prior}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx = np.linspace(0, 1, 100)\n",
      "plt.figure(figsize=(12, 4))\n",
      "plt.subplot(1, 3, 1)\n",
      "plt.plot(xx, stats.beta.pdf(xx, A_prior[1, 0, 0], A_prior[0, 0, 0]))\n",
      "plt.title(r'Transition $0 \\rightarrow 1$');\n",
      "\n",
      "plt.subplot(1, 3, 2)\n",
      "plt.plot(xx, stats.beta.pdf(xx, A_prior[1, 1, 0], A_prior[0, 1, 0]))\n",
      "plt.title(r'Transition $1 \\rightarrow 1$');\n",
      "\n",
      "plt.subplot(1, 3, 3)\n",
      "plt.plot(xx, stats.beta.pdf(xx, pi_prior[1, 0], pi_prior[0, 0]))\n",
      "plt.title('Initial state value');\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Priors on $\\theta$ (overdispersion)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "od_shape = 6\n",
      "od_rate = 5\n",
      "od_dict = {'prior_shape': od_shape * np.ones((M,)), 'prior_rate': od_rate * np.ones((M,))}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx = np.linspace(0, 4, 100)\n",
      "plt.plot(xx, stats.gamma.pdf(xx, a=od_shape, scale=1./od_rate))\n",
      "plt.title('Overdispersion effect prior');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Priors on $\\upsilon$ (regression coefficients)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ups_shape = 11\n",
      "ups_rate = 10\n",
      "reg_shape = ups_shape * np.ones((U, R))  # shape\n",
      "reg_rate = ups_rate * np.ones((U, R))  # rate\n",
      "\n",
      "reg_dict = {'prior_shape': reg_shape, 'prior_rate': reg_rate}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx = np.linspace(0, 2, 100)\n",
      "plt.plot(xx, stats.gamma.pdf(xx, a=ups_shape, scale=1./ups_rate))\n",
      "plt.title('Regression effect prior');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Initial guesses for posterior parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# baseline posteriors\n",
      "bld = ({'post_shape_shape': bl_shape_shape, 'post_shape_rate': bl_shape_rate, \n",
      "        'post_mean_shape': bl_mean_shape, 'post_mean_rate': bl_mean_rate,\n",
      "        'post_child_shape': np.ones((U,)), 'post_child_rate': np.ones((U,))})\n",
      "baseline_dict.update(bld)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# firing rate effects for latents\n",
      "frd = ({'post_shape_shape': fr_shape_shape, 'post_shape_rate': fr_shape_rate, \n",
      "        'post_mean_shape': fr_mean_shape, 'post_mean_rate': fr_mean_rate,\n",
      "        'post_child_shape': np.ones((U, K)), 'post_child_rate': np.ones((U, K))})\n",
      "fr_latent_dict.update(frd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# latent states\n",
      "\n",
      "# E[z]\n",
      "# initialize pretty much at random (10% 1's)\n",
      "rand_frac = 0.1\n",
      "xi_mat = (rand_frac >= np.random.rand(T, K))\n",
      "xi_mat = xi_mat.astype('float')\n",
      "z_prior = np.dstack([1 - xi_mat, xi_mat]).transpose((2, 0, 1))\n",
      "\n",
      "# E[zz]\n",
      "Xi_mat = rand_frac >= np.random.rand(2, 2, T - 1, K)\n",
      "Xi_mat = Xi_mat.astype('float')\n",
      "\n",
      "ld = ({'A_post': A_prior, 'pi_post': pi_prior, 'z_prior': z_prior,\n",
      "       'zz_prior': Xi_mat, 'logZ_prior': np.zeros((K,))})\n",
      "latent_dict.update(ld)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# firing rate regressors\n",
      "# since we know exact update for a_mat, use that\n",
      "nn = df['count']\n",
      "uu = df['unit']\n",
      "NX = nn[:, np.newaxis] * df.iloc[:, -R:]\n",
      "a_mat = NX.groupby(uu).sum().values\n",
      "b_mat = a_mat.copy()\n",
      "\n",
      "reg_dict.update({'post_shape': a_mat, 'post_rate': b_mat})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# overdispersion\n",
      "od_dict.update({'post_shape': np.ones((M,)), 'post_rate': np.ones((M,))})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Do inference with random restarts:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numstarts = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitobjs = []\n",
      "Lvals = []\n",
      "for idx in xrange(numstarts):\n",
      "    gpm = gp.GammaModel(df, K)\n",
      "    gpm.initialize_baseline(**jitter_inits(baseline_dict, 0.25))\n",
      "    gpm.initialize_fr_latents(**jitter_inits(fr_latent_dict, 0.25))\n",
      "    gpm.initialize_latents(**jitter_inits(latent_dict, 0.25))\n",
      "    # gpm.initialize_fr_regressors(**jitter_inits(reg_dict, 0.005))\n",
      "    # gpm.initialize_fr_regressors(**reg_dict)\n",
      "    if overdisp:\n",
      "        gpm.initialize_overdispersion(**jitter_inits(od_dict, 0.25))\n",
      "    gpm.finalize()\n",
      "    \n",
      "    print \"Start {} -----------------------\".format(idx)\n",
      "    %time gpm.do_inference(tol=1e-4, verbosity=2)\n",
      "    print \"Final L = {}\".format(gpm.L())\n",
      "    Lvals.append(gpm.L())\n",
      "    fitobjs.append(gpm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pick out best fit\n",
      "bestind = np.argmax(Lvals)\n",
      "gpm = fitobjs[bestind]\n",
      "del fitobjs  # to save memory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Check results"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Do we correctly recover $z$?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Zoom in on a small part of the time series:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Trng = (500, 1000)\n",
      "matshow(chain.T[:, slice(*Trng)], vmin=0, vmax=1);\n",
      "matshow(gpm.xi.T[:, slice(*Trng)], vmin=0, vmax=1);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What about the whole time series?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matshow(chain.T, vmin=0, vmax=1);\n",
      "matshow(gpm.xi.T, vmin=0, vmax=1);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matshow(chain.T);\n",
      "plt.title('Actual states')\n",
      "matshow(gpm.xi.T, vmin=0, vmax=1);\n",
      "plt.title('Inferred states')\n",
      "matshow(fr.T / dt, vmax=30);\n",
      "plt.title('Actual firing rate')\n",
      "matshow(np.exp(gpm.xi.dot(np.log(gpm.alpha / gpm.beta))).T / dt, vmax=30)\n",
      "plt.title('Inferred firing rate')\n",
      "matshow(N.T, vmin=0, vmax=1);\n",
      "plt.title('Spike rastergram');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match = (chain.T.dot(gpm.xi) + (1 - chain.T).dot(1 - gpm.xi)) / T\n",
      "mismatch = (chain.T.dot(1 - gpm.xi) + (1 - chain.T).dot(gpm.xi)) / T\n",
      "overlap = np.maximum(match, mismatch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Calculate overlap between actual and inferred latents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define the overlap as the maximum of the match or mismatch percentage. That is, if $x$ and $y$ are binary vectors, \n",
      "$$\n",
      "\\mathrm{overlap} = \\max \\{ \\mathbb{E}[xy + (1-x)(1-y)], \\mathbb{E}[(1-x)y + x(1-y)]\\}\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matshow(overlap, vmin=0, vmax=1)\n",
      "plt.colorbar();\n",
      "plt.xlabel('Inferred categories');\n",
      "plt.ylabel('Actual categories');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print overlap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Diagnostics for gamma-distributed variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at what we get for $\\lambda$, $\\theta$, and $\\upsilon$:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\lambda$ population distributions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(8, 4))\n",
      "\n",
      "plt.subplot(1, 2, 1)\n",
      "for kk in xrange(1, K):\n",
      "    samples = gamma_from_hypers(gpm.lam_post_mean[:, kk], gpm.lam_post_var[:, kk], 1e5)\n",
      "    sns.kdeplot(samples, gridsize=5000, clip=(0, 5), label=str(kk))\n",
      "plt.title(r'$\\lambda$ effect posterior distribution')\n",
      "plt.xlim(0, 3);\n",
      "\n",
      "plt.subplot(1, 2, 2)\n",
      "samples = gamma_from_hypers(gpm.lam_post_mean[:, 0], gpm.lam_post_var[:, 0], 1e5)\n",
      "sns.kdeplot(samples / dt, gridsize=1e4, clip=(0, 100))\n",
      "plt.title(r'$\\lambda$ baseline posterior distribution')\n",
      "plt.xlim(0, 100);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\lambda$ terms (baselines and latents for each unit)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot histogram of baseline firing rates and of baseline posterior means:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(lam[0], bins=50, normed=True, alpha=0.25)\n",
      "inferred_means = ((gpm.alpha - 1) / gpm.beta)[0] / dt\n",
      "plt.hist(inferred_means, bins=50, normed=True, alpha=0.25);\n",
      "plt.legend(['actual', 'inferred']);\n",
      "plt.title('Baseline firing rates');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(lam[0], inferred_means);\n",
      "plt.xlabel('actual')\n",
      "plt.ylabel('inferred')\n",
      "plt.title('baseline rates');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Same thing, but for effects. (Lump them all together for convenience)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(lam[1:].ravel(), bins=50, normed=True, alpha=0.25)\n",
      "inferred_effects = ((gpm.alpha - 1) / gpm.beta)[1:].ravel()\n",
      "plt.hist(inferred_effects, bins=50, normed=True, alpha=0.25);\n",
      "plt.legend(['actual', 'inferred']);\n",
      "plt.title('Firing rate effects');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\theta$ terms (overdispersion)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if overdisp:\n",
      "    inferred_means = ((gpm.omega - 1) / gpm.zeta).ravel()\n",
      "    plt.hist(theta.ravel(), bins=500, normed=True, alpha=0.25)\n",
      "    plt.hist(inferred_means, bins=500, normed=True, alpha=0.25);\n",
      "    plt.legend(['actual', 'inferred']);\n",
      "    plt.title('Overdispersion effects');\n",
      "    plt.ylim(0, 2);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(theta.ravel(), inferred_means, alpha=0.01);\n",
      "plt.xlabel('actual')\n",
      "plt.ylabel('inferred')\n",
      "plt.title('overdispersion');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\upsilon$ terms (regressors)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inferred_means = ((gpm.aa - 1) / gpm.bb).ravel()\n",
      "plt.hist(Xlam.ravel(), bins=50, normed=True, alpha=0.25)\n",
      "plt.hist(inferred_means, bins=50, normed=True, alpha=0.25);\n",
      "plt.legend(['actual', 'inferred']);\n",
      "plt.title('Regression effects');\n",
      "plt.ylim(0, 5);\n",
      "plt.xlim(0, 2);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(Xlam.ravel(), inferred_means);\n",
      "plt.xlabel('actual')\n",
      "plt.ylabel('inferred')\n",
      "plt.title('regression weights');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}