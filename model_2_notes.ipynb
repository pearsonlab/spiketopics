{
 "metadata": {
  "name": "",
  "signature": "sha256:16956762fad29f1c1868180bf9f2b74514ce7495efef4596d2814b4cd6f4f0eb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this model, we construct a structured variational ansatz that is a product over Markov chains that we solve exactly using forwards-backwards."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model definition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For $T$ times, $U$ units, and $K$ topics, let\n",
      "$$\n",
      "\\lambda_{ku} \\sim \\text{Ga}(a_{ku}, b_{ku}) \\quad \\text{firing rate for each (topic, unit)} \\\\\n",
      "p(z_{tk}|z_{(t-1)k}) = A^{(k)}_{z_{t}, z_{t-1}} \\quad \\text{a column-stochastic Markov matrix} \\\\\n",
      "z_{0k} \\sim \\text{Bern}(\\zeta_{k}) \\quad \\text{the prior on initial state for each topic} \\\\ \n",
      "A^{(k)}_{1i} \\sim \\text{Be}(\\alpha_{ik}, \\beta_{ik}) \\quad \\text{state transition probabilities for each topic} \\\\\n",
      "N_{tu} \\sim \\text{Pois}\\left(\\sum_k z_{tk}\\lambda_{ku} \\right) \\quad \\text{spike count at time $t$ for unit $u$}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we have written $A$ as a column-stochastic matrix\n",
      "$$\n",
      "A = \n",
      "\\begin{pmatrix}\n",
      "\\tau_{0 \\rightarrow 0} & \\tau_{1 \\rightarrow 0} \\\\\n",
      "\\tau_{0 \\rightarrow 1} & \\tau_{1 \\rightarrow 1}\n",
      "\\end{pmatrix}\n",
      "$$\n",
      "such that the evolution of an initial distribution $p(z_0) = \\pi_0$ evolves in time via\n",
      "$$\n",
      "p(z_t) = A^t\\pi_0\n",
      "$$\n",
      "\n",
      "In what follows, we will write $\\tau^{(k)}_{0 \\rightarrow 1} = \\tau_{0k}$ and $\\tau^{(k)}_{1 \\rightarrow 1} = \\tau_{1k}$, so that the within-state transitions have priors\n",
      "$$\n",
      "\\tau_{ik} \\sim \\text{Be}(\\alpha_{ik}, \\beta_{ik})\n",
      "$$\n",
      "and the initial distributions have priors\n",
      "$$\n",
      "\\zeta_k \\sim \\text{Be}(\\upsilon_{1k}, \\upsilon_{2k})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Joint distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to find \n",
      "$$\n",
      "p(N, z, \\lambda) = p(N|z, \\lambda)p(z)p(\\lambda)\n",
      "$$\n",
      "\n",
      "As above, we can easily write the first factor:\n",
      "$$\n",
      "p(N|z, \\lambda) \\propto \\prod_{tu} \\left(\\sum_k z_{tk}\\lambda_{ku} \\right)^{N_{tu}} e^{-\\sum_k z_{tk}\\lambda_{ku}}\n",
      "$$\n",
      "\n",
      "However, as before, this will not take the exponential form unless we introduce the auxiliary variables $n_{ktu}$ with $\\sum_k n_{ktu} = N_{tu}$. With this, we can expand the first factor in the above via the multinomial theorem to write\n",
      "$$\n",
      "p(n|z, \\lambda) \\propto \\prod_{kt} \\left( \\prod_u \\frac{\\lambda_{ku}^{n_{ktu}}}{n_{ktu}!} e^{-\\lambda_{ku}} \\right)^{z_{tk}}\n",
      "$$\n",
      "with $n_{ktu} = 0$ for $z_{tk} = 0$.\n",
      "\n",
      "That is, we have decoupled the total spike count into the results of separate Poisson processes for each latent factor, coupled through the constraint $\\sum_k n_{ktu} = N_{tu}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition, given $n$, $\\lambda$, and $z$s for the other chains, we can compute $p(z_{\\bullet k}|rest)$ via the forwards-backwards algorithm."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Warm-up: Simplest HMM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider the case of a single unit $U = 1$ and a single category $K = 1$ plus a baseline rate $\\lambda_0$ ($z_{t0} \\equiv 1$).\n",
      "\n",
      "We will assume all spikes result either from the baseline rate or the single categorical variable, so that the observation model takes the form\n",
      "$$\n",
      "p(N_t|z_t, \\lambda) = \\frac{(\\lambda_0 + z_t\\lambda)^{N_t}}{N_t !} e^{-(\\lambda_0 + z\\lambda)}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In what follows, I am essentially reproducing the derivation in Murphy, \"Machine Learning: A Probabilistic Approach.\""
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Forwards:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to calculate the vector \n",
      "$$\n",
      "\\alpha_t \\equiv p(z_t|n_{1:t})\n",
      "$$\n",
      "This can be done by decomposing\n",
      "$$\n",
      "\\alpha_t = p(z_t|n_{1:t}) = p(z_t|n_t, n_{1:t-1}) \\propto p(n_t|z_t, n_{1:t-1})p(z_t|n_{1:t-1}) \n",
      "= p(n_t|z_t)p(z_t|n_{1:t-1}) \\\\\n",
      "= p(n_t|z_t) \\sum_{z_{t-1}} p(z_t|z_{t-1})p(z_{t-1}|n_{1:t-1}) = p(n_t|z_t) \\sum_{z_{t-1}} p(z_t|z_{t-1}) \\alpha_{t-1}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now if we define $\\psi_t \\equiv p(n_t|z_t)$ to be the local evidence at time $t$, then we have the update rule\n",
      "$$\n",
      "\\alpha_t \\propto \\psi_t \\odot (A \\cdot \\alpha_{t - 1})\n",
      "$$\n",
      "with the constraint that, for all $t$, $\\boldsymbol{1}^T\\alpha_t = 1$\n",
      "\n",
      "Note also that since $\\alpha_t \\propto p(n_t|z_t)p(z_t|n_{1:t-1})$, its normalization constant,\n",
      "$Z_t = \\sum_{z_t} \\alpha_t = p(n_t|n_{1:t-1})$. This allows us to calculate the marginal probability of the data:\n",
      "$$\n",
      "p(\\mathcal{D}) = \\prod_t p(n_t|p_{1:t-1}) \\quad \\Rightarrow \\quad\n",
      "\\log p(\\mathcal{D}) = \\sum_z \\log Z_t\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Backwards:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We ultimately want to calculate $\\gamma_t \\equiv p(z_t|n_{1:T})$. And because of the independence of past and future given any hidden state in the chain, we can write\n",
      "$$\n",
      "\\gamma_t = p(z_t|n_{1:T}) = \\frac{p(z_t, n_{t+1:T}|n_{1:t})}{p(n_{t+1:T})} \\propto p(n_{t+1:T}|z_t)p(z_t|n_{1:t}) = \\beta_t \\alpha_t\n",
      "$$\n",
      "where $\\beta_t \\equiv p(n_{t+1:T}|z_t)$. Thus, if we can calculate $\\beta_t$, we can calculate $\\gamma_t$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But we can calculate $\\beta_t$ moving backward through time:\n",
      "$$\n",
      "\\beta_{t - 1} = p(n_{t:T}|z_{t-1}) = \\sum_{z_t} p(n_{t:T}|z_t)p(z_t|z_{t-1}) \n",
      "= \\sum_{z_t} p(n_{t+1:T}|z_t)p(n_t|z_t)p(z_t|z_{t-1})\n",
      "= A^T (\\beta_t \\odot \\psi_t)\n",
      "$$\n",
      "with the initialization $\\beta_T = 1$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Transition probabilities:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For computing sufficient statistics, we also want to know the joint probability\n",
      "$$\n",
      "\\Xi_{t+1, t} \\equiv p(z_{t + 1}, z_t|n_{1:T}) \\propto p(z_{t+1}, z_t, n_{1:T}) =\n",
      "p(n_{t+1:T}|z_{t+1})p(z_{t+1}|z_t)p(z_t|n_{1:t})p(n_{1:t}) \\\\\n",
      "\\propto p(n_{t+2:T}|z_{t+1}) p(n_{t+1}|z_{t+1}) p(z_{t+1}|z_t)p(z_t|n_{1:t}) \\\\\n",
      "\\propto p(z_{t+1}|n_{t+2:T}) p(n_{t+1}|z_{t+1}) p(z_{t+1}|z_t)p(z_t|n_{1:t}) \\\\\n",
      "= A \\odot ((\\beta_{t+1} \\odot \\psi_{t+1}) \\cdot \\alpha_t^T)\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Calculating the pieces:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From above, we have\n",
      "$$\n",
      "A = \n",
      "\\begin{pmatrix}\n",
      "1 - \\tau_0 & 1 - \\tau_1 \\\\\n",
      "\\tau_0 & \\tau_1\n",
      "\\end{pmatrix}\n",
      "\\\\\n",
      "\\psi_t = p(N_t|z_t, \\lambda) = \\frac{(\\lambda_0 + z_t\\lambda)^{N_t}}{N_t !} e^{-(\\lambda_0 + z\\lambda)}\n",
      "\\\\\n",
      "p(z_0) = \\begin{pmatrix} 1 - \\zeta \\\\ \\zeta \\end{pmatrix}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can then run the forwards algorithm to get $\\alpha$ and the backwards algorithm to get $\\beta$. Given both of these, we can multiply and normalize to get $\\gamma_t$, the desired posteriors."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "General HMM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us assume in the above model that we want to calculate\n",
      "$\n",
      "p(z_{1:T,k}|z_{1:T, -k}\\lambda, n, \\tau)\n",
      "$,\n",
      "the conditional posterior of a single chain given the values of all other variables. It is clear that, in this case, we can proceed exactly as above, using the forward-backward algorithm, albeit with the new observation model\n",
      "$$\n",
      "\\psi_t = \\prod_u p(n_{ktu}|z_{1:T,k}, rest) = \\prod_u \n",
      "\\frac{(\\lambda_{ku}z_{tk})^{n_{ktu}}}{n_{ktu}!}\n",
      "e^{-\\lambda_{ku}z_{tk}}\n",
      "$$\n",
      "That is, we simply replace the observed counts $N_{tu}$ with the latent counts $n_{ktu}$ for the given chain."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "$\\mathbb{E}_q[\\log p]$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we calculate explicitly the pieces of $\\mathbb{E}_q[\\log p]$ that depends on $z$ and $n$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starting with $n$, we have\n",
      "$$\n",
      "p(n|rest) = \\binom{N}{n}\\prod_k \\left(\\frac{z_k\\lambda_k}{z^T \\lambda} \\right)^{n_k}\n",
      "$$\n",
      "for which we can calculate\n",
      "$$\n",
      "\\mathbb{E}_q [\\log p(n|rest)] = \\mathbb{E}_q[\\log h] + \\sum_{kt} \\mathbb{E}_q[n_{kt} \\log z_{tk} \\lambda_k] - N \\mathbb{E}_q[\\log z_t^T \\lambda]\n",
      "$$\n",
      "where $h \\equiv \\binom{N}{n}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The term $\\mathbb{E}_q[\\log p(z|rest_{-n})]$ comprises three additional pieces, one arising from the Poisson model and the other two from transition probabilities between states:\n",
      "$$\n",
      "\\mathbb{E}_q[\\log p(z|rest_{-n})] = \\sum_{kt} \\mathbb{E}_q\\left[ \n",
      "- \\lambda_k z_{tk} + z_{tk}^T \\log A^{(k)} z_{t-1,k}\n",
      "+ z_{0k}\\zeta_k\\right]\n",
      "$$\n",
      "where the first term is, naturally, shared with the expectation above and in the matrix multiplication, $z$ is treated as a column vector."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variational ansatz"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we choose a partially factorized ansatz for the posterior:\n",
      "$$\n",
      "q(n, z, \\lambda, \\tau) = q(n|z)q(z)q(\\lambda)q(\\tau)q(\\zeta) = \n",
      "\\left(\\prod_{u} q(n_{\\bullet \\bullet u}| z) \\right) \n",
      "\\left( \\prod_k q(z_{\\bullet k}) \\right) \n",
      "\\left(\\prod_{ku} q(\\lambda_{ku}) \\right) \n",
      "\\left(\\prod_{ik} q(\\tau_{ik}) \\right)\n",
      "\\left(\\prod_{k} q(\\zeta_{k}) \\right) \\\\\n",
      "\\lambda_{ku} \\sim \\text{Ga}(c_{ku}, d_{ku}) \\\\\n",
      "\\tau_{ik} \\sim \\text{Be}(\\gamma_{ik}, \\delta_{ik}) \\\\\n",
      "\\zeta_k \\sim \\text{Be}(\\rho_{1k}, \\rho_{2k})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now to suggest our ansatz $q(n|z)q(z)$, we will split terms as above: $\\log p(z,n|rest) = \\log p(n|z, rest) + \\log p(z|rest_{-n})$.\n",
      "\n",
      "For our $q(z)$ ansatz, we will then make the following exchanges of variables with parameters:\n",
      "$$\n",
      "\\lambda \\rightarrow \\mu \\\\\n",
      "\\tau \\rightarrow \\pi \\\\\n",
      "\\zeta \\rightarrow \\phi \\\\\n",
      "A(\\tau) \\rightarrow \\mathcal{A}(\\pi)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Important**: In this model, because we will replace $n$ with $\\bar{n} \\equiv \\mathbb{E}_{q(n|z)}[n]$, the observation model is no longer Poisson but Gamma when conditioned on $z$:\n",
      "$$\n",
      "p(\\bar{n_{kt}}) \\propto \\prod_u (z_{tk} \\mu_{ku})^{\\bar{n}_{ktu}} e^{-z_{tk}\\mu_{ku}} \\\\\n",
      "= \\exp \\left( \\sum_u (\\bar{n}_{ktu} \\log z_{tk} \\mu_{ku} - z_{tk}\\mu_{ku})\\right)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "so that we have\n",
      "$$\n",
      "\\mathbb{E}_q[\\log q(z)] = \\sum_{kt} \\mathbb{E}_q\\left[ \n",
      "- \\mu_k z_{tk} + z_{tk} \\log \\mathcal{A}^{(k)} z_{t-1,k}\\right] \n",
      "+ \\sum_k \\mathbb{E}_q[z_{0k}\\phi_k]\n",
      "\\\\\n",
      "= \\sum_{kt} \\left[ - \\mu_k\\xi_{tk}\n",
      "+ \\text{tr}((\\Xi^{(k)}_{t, t-1})^T\\log \\mathcal{A}^{(k)})\n",
      "\\right]\n",
      "+ \\sum_k \\xi_{0k}^T \\phi_k\n",
      "$$\n",
      "where we have adopted the shorthand $\\xi_{tk} \\equiv p(z_{tk} = 1)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For $q(n|z)$, we will continue to condition on $z$ but replace $\\lambda \\rightarrow \\eta$ so that\n",
      "$$\n",
      "q(n|z) = \\binom{N}{n}\\prod_k \\left(\\frac{z_k\\eta_k}{z^T \\eta} \\right)^{n_k}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With these assumptions, the expectations above can be further simplified:\n",
      "$$\n",
      "\\mathbb{E}_q [\\log p] = \\mathbb{E}_q[\\log h] + \\sum_{kt} \\left[\n",
      "\\mathbb{E}_q[n_{kt}]\\xi_{tk} (\\psi(c_k) - \\log d_k)  - \\frac{c_k}{d_k} \\xi_{tk} +\n",
      "\\text{tr}((\\Xi^{(k)}_{t, t-1})^T\\mathbb{E}_q[\\log A^{(k)}])\n",
      "\\right] \\\\\n",
      "+ \\sum_k \\xi_{0k}^T\\bar{\\zeta}_k\n",
      "- \\sum_t N_t \\mathbb{E}_q[\\log z_t^T \\lambda] + \\ldots\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly\n",
      "$$\n",
      "\\mathbb{E}_q [\\log q] = \\mathbb{E}_q[\\log h] + \\sum_{kt}\n",
      "\\mathbb{E}_q[n_{kt}]\\xi_{tk} \\log \\eta_{kt} \n",
      "- \\sum_t N_t \\mathbb{E}_q[\\log z_t^T \\eta_t] \\\\\n",
      "+ \\sum_{kt} \\left[\n",
      "- \\mu_k \\xi_{tk} +\n",
      "\\text{tr}((\\Xi^{(k)}_{t, t-1})^T\\log \\mathcal{A}^{(k)})\n",
      "\\right] + \n",
      "\\sum_k \\xi_{0k}^T\\phi_k\n",
      " + \\ldots\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where in each place we include a factor of $\\xi_{tk}$ we also assume all expectations are taken with respect to $z_{tk} = 1$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Updates"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Noting that the ansatz is a fully factorized exponential family form and that the single-variable conditionals are as well, we can use the Blei and Jordan result above \n",
      "$$\n",
      "\\eta_i = \\mathbb{E}_q[g_i(\\theta_{-i}, x)]\n",
      "$$\n",
      "where $\\eta_i$ is the natural parameter for variable $\\theta_i$ in the ansatz and $g_i(\\theta_{-i}, x)$ is the natural parameter conjugate to $\\theta_i$ in the conditional distribution.\n",
      "\n",
      "Using this, we can now write:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\lambda$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\n",
      "c_{ku} \\leftarrow a_{ku} + \\sum_t \\mathbb{E}_q[n_{ktu}] \\\\\n",
      "d_{ku} \\leftarrow b_{ku} + \\sum_t \\mathbb{E}_q[z_{tk}] \\\\\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\tau$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For $\\tau_{ik}$, the updates come from combining the expected number of each type of transition in the chain (summed over all times) with the prior parameters.\n",
      "$$\n",
      "\\gamma_{ik} \\leftarrow \\mathbb{E}_q[m_{i\\rightarrow 1, k}] + \\alpha_{ik}\n",
      "= \\sum_{t}(\\Xi^{(k)}_{t, t-1})_{1i} + \\alpha_{ik} \\\\\n",
      "\\delta_{ik} \\leftarrow \\mathbb{E}_q[m_{i\\rightarrow 0, k}] + \\beta_{ik}\n",
      "= \\sum_{t}(\\Xi^{(k)}_{t, t-1})_{0i} + \\beta_{ik}\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\zeta$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, this is a straightforward exponential family update:\n",
      "$$\n",
      "\\rho_{1k} \\leftarrow \\upsilon_{1k} + \\mathbb{E}_q[z_{0k}] \\\\\n",
      "\\rho_{2k} \\leftarrow \\upsilon_{2k} + 1 - \\mathbb{E}_q[z_{0k}]\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$n|z$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maximizing with respect to $\\eta$ gives\n",
      "$$\n",
      "\\frac{\\partial}{\\partial \\eta_k}\\left[\\mathbb{E}_q[\\log p] - \\mathbb{E}_q[\\log q]\\right] =\n",
      "\\sum_t \\frac{\\partial \\mathbb{E}_q[n_{kt}]}{\\partial \\eta_k}\\xi_{tk}(\\psi(c_k) - \\log d_k -\\log \\eta_k) - \\sum_t \\left(\n",
      "\\frac{\\xi_{tk}}{\\eta_k} \\mathbb{E}_q[n_{kt}] \n",
      "- N_t \\mathbb{E}_q\\left[ \\frac{z_{tk}}{z_t^T\\eta} \\right]\n",
      "\\right) \\\\\n",
      "= \\frac{\\partial \\mathbb{E}_q[n_{kt}]}{\\partial \\eta_k}\\xi_{tk}(\\psi(c_k) - \\log d_k -\\log \\eta_k) = 0 \\\\\n",
      "\\Rightarrow \\quad \\log \\eta_k \\leftarrow \\psi(c_k) - \\log d_k\n",
      "$$\n",
      "where we have used\n",
      "$$\n",
      "N_t\\mathbb{E}_q\\left[ \\frac{z_{tk}}{z_t^T\\eta}\\right]\n",
      "= N_t\\xi_{tk}\n",
      "\\mathbb{E}_q\\left. \\left[ \\frac{1}{z_t^T\\eta}\\right] \\right\\vert_{z_{tk} = 1}\n",
      "= N_t\\frac{\\xi_{tk}}{\\eta_k} \n",
      "\\mathbb{E}_q\\left. \\left[ \\frac{\\eta_k}{z_t^T\\eta}\\right] \\right\\vert_{z_{tk} = 1} = \\frac{\\xi_{tk}}{\\eta_k} \\mathbb{E}_q[n_{kt}]\\vert_{z_{tk} = 1}\n",
      "$$\n",
      "and recall that in all expressions like $\\xi \\mathbb{E}_q[n_{kt}]$ in the Lagrangian, the expectation is taken assuming $z_{tk} = 1$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "z"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "$\\phi$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given the above expressions for $\\mathbb{E}_q[\\log p]$ and $\\mathbb{E}_q[\\log q]$ it is obvious that the difference is minimized if we simply set\n",
      "$$\n",
      "\\phi_k \\leftarrow \\bar{\\zeta}_k = \\frac{\\rho_{1k}}{\\rho_{1k} + \\rho_{2k}}\n",
      "$$\n",
      "in which case the relevant terms in the difference cancel."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "$\\mathcal{A}(\\pi)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In exactly the same way, the relevant terms in the Lagrangian simply cancel if we set \n",
      "$$\n",
      "\\log \\mathcal{A}^{(k)} \\leftarrow \\mathbb{E}_q[\\log A^{(k)}]\n",
      "$$\n",
      "which simplifies to\n",
      "$$\n",
      "\\log \\pi_{ik} \\leftarrow \\psi(\\gamma_{ik}) - \\psi(\\gamma_{ik} + \\delta_{ik})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "$\\mu$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we start by noting that, given the results above for $\\eta$, $\\pi$, and $\\phi$, many terms drop out of the Lagrangian, and the remaining terms involving $\\mu$ can be written\n",
      "$$\n",
      "\\mathcal{L}(\\mu) = \n",
      "-\\sum_k \\xi_{tk}(\\bar{\\lambda}_k - \\mu_k) - \n",
      "\\sum_t N_t \\mathbb{E}_q[\\log z_t^T\\lambda] +\n",
      "\\sum_t N_t \\mathbb{E}_q[\\log z_t^T\\eta] \n",
      "$$\n",
      "where $\\bar{\\lambda} \\equiv \\mathbb{E}_q[\\lambda] = c_k/d_k$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, by convexity of $-\\log$, we can take the expectation over $\\lambda$ inside the second term:\n",
      "$$\n",
      "-\\mathbb{E}_{q(\\lambda)}[\\log z_t^T \\lambda] \\geq -\\log z_t^T \\mathbb{E}_{q(\\lambda)}[\\lambda]\n",
      "= -\\log z_t^T\\bar{\\lambda}\n",
      "$$\n",
      "However, by exactly the same convexity property, for any random variable $X$, we have \n",
      "$$\n",
      "\\mathbb{E}[X] \\geq e^{\\mathbb{E}[\\log X]}\n",
      "$$\n",
      "and since the update equations above give $\\log \\eta_k = \\mathbb{E}_q[\\log \\lambda_k]$, we have $\\bar{\\lambda}_k \\geq \\eta_k$ and thus $\\log z_t^T \\bar{\\lambda} \\geq \\log z_t^T \\eta$. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Note also that since $\\lambda \\sim \\text{Ga}(c, d)$, we have \n",
      "$$\n",
      "\\bar{\\lambda} = \\frac{c}{d} \\\\\n",
      "e^{\\mathbb{E}_q[\\log \\lambda]} = e^{\\psi(c) - \\log d} = \\frac{e^{\\psi(c)}}{d}\n",
      "$$\n",
      "and \n",
      "$$\n",
      "\\psi(c) = \\log c - \\frac{1}{2c} - \\frac{1}{12c^2} + \\ldots\n",
      "$$\n",
      "so that the approximation is exponentially good for large $c$, and $c \\sim \\mathcal{O}\\left(\\frac{N}{K}\\right)$ in our model. )"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a result, then, we can replace $\\mathcal{L}(\\mu)$ with the lower bound\n",
      "$$\n",
      "\\mathcal{L}(\\mu) \\geq \n",
      "-\\sum_k \\xi_{tk}(\\bar{\\lambda}_k - \\mu_k)\n",
      "$$\n",
      "from which we obtain the trivial update rule\n",
      "$$\n",
      "\\mu_k \\leftarrow \\frac{c_k}{d_k}\n",
      "$$\n",
      "when $z_k = 1$ "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}