{
 "metadata": {
  "name": "",
  "signature": "sha256:a47c4cd823ff6c0480e2d8048cbb672103c08db3d6faf13d6ed4d7cd4c44eaf2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this model, we construct a structured variational ansatz that is a product over Markov chains that we solve exactly using forwards-backwards."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model definition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For $T$ times, $U$ units, and $K$ topics, let\n",
      "$$\n",
      "\\lambda_{ku} \\sim \\text{Ga}(a_{ku}, b_{ku}) \\quad \\text{firing rate for each (topic, unit)} \\\\\n",
      "p(z_{tk}|z_{(t-1)k}) = A^{(k)}_{z_{t}, z_{t-1}} \\quad \\text{a column-stochastic Markov matrix} \\\\\n",
      "z_{0k} \\sim \\text{Bern}(\\zeta_{k}) \\quad \\text{the prior on initial state for each topic} \\\\ \n",
      "A^{(k)}_{1i} \\sim \\text{Be}(\\alpha_{ik}, \\beta_{ik}) \\quad \\text{state transition probabilities for each topic} \\\\\n",
      "N_{tu} \\sim \\text{Pois}\\left(\\sum_k z_{tk}\\lambda_{ku} \\right) \\quad \\text{spike count at time $t$ for unit $u$}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we have written $A$ as a column-stochastic matrix\n",
      "$$\n",
      "A = \n",
      "\\begin{pmatrix}\n",
      "\\tau_{0 \\rightarrow 0} & \\tau_{1 \\rightarrow 0} \\\\\n",
      "\\tau_{0 \\rightarrow 1} & \\tau_{1 \\rightarrow 1}\n",
      "\\end{pmatrix}\n",
      "$$\n",
      "such that the evolution of an initial distribution $p(z_0) = \\pi_0$ evolves in time via\n",
      "$$\n",
      "p(z_t) = A^t\\pi_0\n",
      "$$\n",
      "\n",
      "In what follows, we will write $\\tau^{(k)}_{0 \\rightarrow 1} = \\tau_{0k}$ and $\\tau^{(k)}_{1 \\rightarrow 1} = \\tau_{1k}$, so that the within-state transitions have priors\n",
      "$$\n",
      "\\tau_{ik} \\sim \\text{Be}(\\alpha_{ik}, \\beta_{ik})\n",
      "$$\n",
      "and the initial distributions have priors\n",
      "$$\n",
      "\\zeta_k \\sim \\text{Be}(\\upsilon_{1k}, \\upsilon_{2k})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Joint distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to find \n",
      "$$\n",
      "p(N, z, \\lambda) = p(N|z, \\lambda)p(z)p(\\lambda)\n",
      "$$\n",
      "\n",
      "As above, we can easily write the first factor:\n",
      "$$\n",
      "p(N|z, \\lambda) \\propto \\prod_{tu} \\frac{\\left(\\sum_k z_{tk}\\lambda_{ku} \\right)^{N_{tu}}}{N_{tu}!} e^{-\\sum_k z_{tk}\\lambda_{ku}}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, this form will prove difficult to work with unless we introduce the auxiliary variables $n_{ktu}$ with $\\sum_k n_{ktu} = N_{tu}$. With this, we can expand the first factor in the above via the multinomial theorem to write\n",
      "$$\n",
      "p(n|z, \\lambda) = \\prod_{kt} \\left( \\prod_u \\frac{(z_{tk}\\lambda_{ku})^{n_{ktu}}}{n_{ktu}!} e^{-\\lambda_{ku}} \\right)\n",
      "$$\n",
      "with $n_{ktu} = 0$ for $z_{tk} = 0$.\n",
      "\n",
      "That is, we have decoupled the total spike count into the results of separate Poisson processes for each latent factor, coupled through the constraint $\\sum_k n_{ktu} = N_{tu}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, in order to relax the constraint on the counts, we will introduce the Lagrange multiplier $\\eta$:\n",
      "$$\n",
      "\\log p(n|z,\\lambda) \\rightarrow \n",
      "\\sum_{ktu}\\left[ \n",
      "n_{ktu} \\log z_{tk} \\lambda_{ku} - z_{tk}\\lambda_{ku} - \\log n_{ktu}!\n",
      "\\right]\n",
      "- \\sum_{tu} \\log \\eta_{tu} (N_{tu} - \\sum_k n_{ktu})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Warm-up: Simplest HMM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider the case of a single unit $U = 1$ and a single category $K = 1$ plus a baseline rate $\\lambda_0$ ($z_{t0} \\equiv 1$).\n",
      "\n",
      "We will assume all spikes result either from the baseline rate or the single categorical variable, so that the observation model takes the form\n",
      "$$\n",
      "p(N_t|z_t, \\lambda) = \\frac{(\\lambda_0 + z_t\\lambda)^{N_t}}{N_t !} e^{-(\\lambda_0 + z\\lambda)}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In what follows, I am essentially reproducing the derivation in Murphy, \"Machine Learning: A Probabilistic Approach.\""
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Forwards:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to calculate the vector \n",
      "$$\n",
      "\\alpha_t \\equiv p(z_t|n_{1:t})\n",
      "$$\n",
      "This can be done by decomposing\n",
      "$$\n",
      "\\alpha_t = p(z_t|n_{1:t}) = p(z_t|n_t, n_{1:t-1}) \\propto p(n_t|z_t, n_{1:t-1})p(z_t|n_{1:t-1}) \n",
      "= p(n_t|z_t)p(z_t|n_{1:t-1}) \\\\\n",
      "= p(n_t|z_t) \\sum_{z_{t-1}} p(z_t|z_{t-1})p(z_{t-1}|n_{1:t-1}) = p(n_t|z_t) \\sum_{z_{t-1}} p(z_t|z_{t-1}) \\alpha_{t-1}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now if we define $\\psi_t \\equiv p(n_t|z_t)$ to be the local evidence at time $t$, then we have the update rule\n",
      "$$\n",
      "\\alpha_t \\propto \\psi_t \\odot (A \\cdot \\alpha_{t - 1})\n",
      "$$\n",
      "with the constraint that, for all $t$, $\\boldsymbol{1}^T\\alpha_t = 1$\n",
      "\n",
      "Note also that since $\\alpha_t \\propto p(n_t|z_t)p(z_t|n_{1:t-1})$, its normalization constant,\n",
      "$Z_t = \\sum_{z_t} \\alpha_t = p(n_t|n_{1:t-1})$. This allows us to calculate the marginal probability of the data:\n",
      "$$\n",
      "p(\\mathcal{D}) = \\prod_t p(n_t|p_{1:t-1}) \\quad \\Rightarrow \\quad\n",
      "\\log p(\\mathcal{D}) = \\sum_z \\log Z_t\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Backwards:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We ultimately want to calculate $\\gamma_t \\equiv p(z_t|n_{1:T})$. And because of the independence of past and future given any hidden state in the chain, we can write\n",
      "$$\n",
      "\\gamma_t = p(z_t|n_{1:T}) = \\frac{p(z_t, n_{t+1:T}|n_{1:t})}{p(n_{t+1:T})} \\propto p(n_{t+1:T}|z_t)p(z_t|n_{1:t}) = \\beta_t \\alpha_t\n",
      "$$\n",
      "where $\\beta_t \\equiv p(n_{t+1:T}|z_t)$. Thus, if we can calculate $\\beta_t$, we can calculate $\\gamma_t$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But we can calculate $\\beta_t$ moving backward through time:\n",
      "$$\n",
      "\\beta_{t - 1} = p(n_{t:T}|z_{t-1}) = \\sum_{z_t} p(n_{t:T}|z_t)p(z_t|z_{t-1}) \n",
      "= \\sum_{z_t} p(n_{t+1:T}|z_t)p(n_t|z_t)p(z_t|z_{t-1})\n",
      "= A^T (\\beta_t \\odot \\psi_t)\n",
      "$$\n",
      "with the initialization $\\beta_T = 1$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Transition probabilities:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For computing sufficient statistics, we also want to know the joint probability\n",
      "$$\n",
      "\\Xi_{t+1, t} \\equiv p(z_{t + 1}, z_t|n_{1:T}) \\propto p(z_{t+1}, z_t, n_{1:T}) =\n",
      "p(n_{t+1:T}|z_{t+1})p(z_{t+1}|z_t)p(z_t|n_{1:t})p(n_{1:t}) \\\\\n",
      "\\propto p(n_{t+2:T}|z_{t+1}) p(n_{t+1}|z_{t+1}) p(z_{t+1}|z_t)p(z_t|n_{1:t}) \\\\\n",
      "\\propto p(z_{t+1}|n_{t+2:T}) p(n_{t+1}|z_{t+1}) p(z_{t+1}|z_t)p(z_t|n_{1:t}) \\\\\n",
      "= A \\odot ((\\beta_{t+1} \\odot \\psi_{t+1}) \\cdot \\alpha_t^T)\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Calculating the pieces:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From above, we have\n",
      "$$\n",
      "A = \n",
      "\\begin{pmatrix}\n",
      "1 - \\tau_0 & 1 - \\tau_1 \\\\\n",
      "\\tau_0 & \\tau_1\n",
      "\\end{pmatrix}\n",
      "\\\\\n",
      "\\psi_t = p(N_t|z_t, \\lambda) = \\frac{(\\lambda_0 + z_t\\lambda)^{N_t}}{N_t !} e^{-(\\lambda_0 + z\\lambda)}\n",
      "\\\\\n",
      "p(z_0) = \\begin{pmatrix} 1 - \\zeta \\\\ \\zeta \\end{pmatrix}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can then run the forwards algorithm to get $\\alpha$ and the backwards algorithm to get $\\beta$. Given both of these, we can multiply and normalize to get $\\gamma_t$, the desired posteriors."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "General HMM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us assume in the above model that we want to calculate\n",
      "$\n",
      "p(z_{1:T,k}|z_{1:T, -k}\\lambda, n, \\tau)\n",
      "$,\n",
      "the conditional posterior of a single chain given the values of all other variables. It is clear that, in this case, we can proceed exactly as above, using the forward-backward algorithm, albeit with the new observation model\n",
      "$$\n",
      "\\psi_t = \\prod_u p(n_{ktu}|z_{1:T,k}, rest) = \\prod_u \n",
      "\\frac{(\\lambda_{ku}z_{tk})^{n_{ktu}}}{n_{ktu}!}\n",
      "e^{-\\lambda_{ku}z_{tk}}\n",
      "$$\n",
      "That is, we simply replace the observed counts $N_{tu}$ with the latent counts $n_{ktu}$ for the given chain."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "$\\log p(n, z)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we calculate explicitly the pieces of $\\log p$ that depend on $z$ and $n$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starting with the expression involving the Lagrange multipler above, we have\n",
      "$$\n",
      "\\log p(n,z|rest) = \n",
      "\\sum_{ktu}\\left[ \n",
      "n_{ktu} \\log z_{tk} \\lambda_{ku} - z_{tk}\\lambda_{ku} - \\log n_{ktu}!\n",
      "\\right]\n",
      "- \\sum_{tu} \\log \\eta_{tu} (N_{tu} - \\sum_k n_{ktu})\n",
      "$$\n",
      "to which we add the terms for the Markov chain\n",
      "$$\n",
      "\\sum_{ktu} \\left[ \n",
      "- \\lambda_{ku} z_{tk} + z_{tk}^T \\log A^{(k)} z_{t-1,k}\n",
      "+ z_{0k}\\zeta_k\\right]\n",
      "$$\n",
      "where the first term is, naturally, shared with the expectation above and in the matrix multiplication, $z$ is treated as a column vector."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variational ansatz"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we choose a partially factorized ansatz for the posterior:\n",
      "$$\n",
      "q(n, z, \\lambda, \\tau) = q(n|z)q(z)q(\\lambda)q(\\tau)q(\\zeta) = \n",
      "\\left(\\prod_{u} q(n_{\\bullet \\bullet u}| z) \\right) \n",
      "\\left( \\prod_k q(z_{\\bullet k}) \\right) \n",
      "\\left(\\prod_{ku} q(\\lambda_{ku}) \\right) \n",
      "\\left(\\prod_{ik} q(\\tau_{ik}) \\right)\n",
      "\\left(\\prod_{k} q(\\zeta_{k}) \\right) \\\\\n",
      "\\lambda_{ku} \\sim \\text{Ga}(c_{ku}, d_{ku}) \\\\\n",
      "\\tau_{ik} \\sim \\text{Be}(\\gamma_{ik}, \\delta_{ik}) \\\\\n",
      "\\zeta_k \\sim \\text{Be}(\\rho_{1k}, \\rho_{2k})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the $n$ and $z$ terms, we will simply choose a collection of **uncoupled** Poisson process Markov chains with rates $\\mu_{ku}$. Note that this is exactly the same as the original model, save for the constraint/Lagrange multiplier term."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus\n",
      "$$\n",
      "\\log q(n, z) = \n",
      "\\sum_{ktu} \\left[\n",
      "n_{ktu} \\log z_{tk}\\mu_{ku} - z_{tk}\\lambda_{ku} - \\log n_{ktu}! \n",
      "+ z_{tk}^T \\log \\mathcal{A}^{(k)} z_{t-1,k} + z_{0k}^T\\phi_k\n",
      "\\right]\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, given this ansatz, we can easily calculate some useful sufficient statistics:\n",
      "$$\n",
      "\\mathbb{E}_q[z_{tk}] \\equiv \\xi_{tk} \\\\\n",
      "\\mathbb{E}_q[z_{t+1,k}z_{t}^T] \\equiv \\Xi_{t+1, t}^{(k)} \\\\\n",
      "\\mathbb{E}_{q(n|z)}[n_{ktu}] = \\mu_{ku} z_{tk} \\\\\n",
      "\\mathbb{E}_q[n_{ktu}] = \\xi_{tk}\\mu_{ku} \\\\\n",
      "\\mathbb{E}_q[\\lambda_{ku}] = \\bar{\\lambda}_{ku} = \\frac{c_{ku}}{d_{ku}} \\\\\n",
      "\\mathbb{E}_q[\\log \\lambda_{ku}] = \\overline{\\log \\lambda_{ku}} = \\psi(c_{ku}) - \\log d_{ku} \\\\\n",
      "\\mathbb{E}_q[\\zeta_k] = \\bar{\\zeta}_k = \\frac{\\rho_{1k}}{\\rho_{1k} + \\rho_{2k}}\n",
      "$$\n",
      "where the first two quantities are calculable via the forwards-backwards algorithm and the rest follow from our choice of $q$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now it is easy to show that the variational Lagrangian for terms involving $n$ and $z$ parameters takes the form\n",
      "$$\n",
      "\\mathcal{L} = \\mathbb{E}_q[\\log p - \\log q] =\n",
      "\\sum_{ktu} \\left[\n",
      "\\xi_{tk}\\mu_{ku}(\\overline{\\log \\lambda_{ku}} - \\log \\eta_{tu} - \\log \\mu_{ku})\n",
      "-\\xi_{tk}(\\bar{\\lambda}_{ku} - \\mu_{ku})\n",
      "\\right] + \\sum_{tu} N_{tu}\\log \\eta_{tu} \n",
      "\\\\\n",
      "+ \\sum_{ktu} \n",
      "\\text{tr}\\left[ (\\Xi^{(k)}_{t, t-1})^T \\mathbb{E}_q[\\log A^{(k)}]\n",
      "\\right]\n",
      "- \\sum_{ktu} \n",
      "\\text{tr}\\left[ (\\Xi^{(k)}_{t, t-1})^T \\log \\mathcal{A}^{(k)}\n",
      "\\right]\n",
      "+ \\sum_k \\xi_{0k}(\\bar{\\zeta}_k - \\phi_k)\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Updates"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Noting that the ansatz is a fully factorized exponential family form and that the single-variable conditionals are as well, we can use the Blei and Jordan result above \n",
      "$$\n",
      "\\eta_i = \\mathbb{E}_q[g_i(\\theta_{-i}, x)]\n",
      "$$\n",
      "where $\\eta_i$ is the natural parameter for variable $\\theta_i$ in the ansatz and $g_i(\\theta_{-i}, x)$ is the natural parameter conjugate to $\\theta_i$ in the conditional distribution.\n",
      "\n",
      "Using this, we can now write:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\lambda$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\n",
      "c_{ku} \\leftarrow a_{ku} + \\sum_t \\mathbb{E}_q[n_{ktu}] = a_{ku} + \\sum_t \\xi_{tk}\\mu_{ku}\\\\\n",
      "d_{ku} \\leftarrow b_{ku} + \\sum_t \\mathbb{E}_q[z_{tk}] = b_{ku} + \\sum_t \\xi_{tk}\\\\\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\tau$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For $\\tau_{ik}$, the updates come from combining the expected number of each type of transition in the chain (summed over all times) with the prior parameters.\n",
      "$$\n",
      "\\gamma_{ik} \\leftarrow \\mathbb{E}_q[m_{i\\rightarrow 1, k}] + \\alpha_{ik}\n",
      "= \\sum_{t}(\\Xi^{(k)}_{t, t-1})_{1i} + \\alpha_{ik} \\\\\n",
      "\\delta_{ik} \\leftarrow \\mathbb{E}_q[m_{i\\rightarrow 0, k}] + \\beta_{ik}\n",
      "= \\sum_{t}(\\Xi^{(k)}_{t, t-1})_{0i} + \\beta_{ik}\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\zeta$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, this is a straightforward exponential family update:\n",
      "$$\n",
      "\\rho_{1k} \\leftarrow \\upsilon_{1k} + \\mathbb{E}_q[z_{0k}] \\\\\n",
      "\\rho_{2k} \\leftarrow \\upsilon_{2k} + 1 - \\mathbb{E}_q[z_{0k}]\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$\\eta$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maximizing with respect to the Lagrange multiplier $\\eta$ gives\n",
      "$$\n",
      "\\frac{\\partial\\mathcal{L}}{\\partial \\eta_{tu}} =\n",
      "\\frac{1}{\\eta_{tu}} \\left( \n",
      "-\\sum_k \\xi_{tk}\\mu_{ku} + N_{tu}\n",
      "\\right)\n",
      "\\\\\n",
      "\\Rightarrow \\quad \\sum_k \\xi_{tk}\\mu_{ku} = N_{tu}\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "z"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "$\\phi$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given the above expressions for $\\mathbb{E}_q[\\log p]$ and $\\mathbb{E}_q[\\log q]$ it is obvious that the difference is minimized if we simply set\n",
      "$$\n",
      "\\phi_k \\leftarrow \\bar{\\zeta}_k = \\frac{\\rho_{1k}}{\\rho_{1k} + \\rho_{2k}}\n",
      "$$\n",
      "in which case the relevant terms in the difference cancel."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "$\\mathcal{A}(\\pi)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In exactly the same way, the relevant terms in the Lagrangian simply cancel if we set \n",
      "$$\n",
      "\\log \\mathcal{A}^{(k)} \\leftarrow \\mathbb{E}_q[\\log A^{(k)}]\n",
      "$$\n",
      "which simplifies to\n",
      "$$\n",
      "\\log \\pi_{ik} \\leftarrow \\psi(\\gamma_{ik}) - \\psi(\\gamma_{ik} + \\delta_{ik})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "$\\mu$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Lagrangian involving $\\mu$ is\n",
      "$$\n",
      "\\mathcal{L}(\\mu) = \\sum_k \\left[\n",
      "\\mu_k \\xi_k \\left(\n",
      "\\overline{\\log \\lambda_k} - \\log \\eta - \\log \\mu_k + 1)\n",
      "\\right) -\\xi_k \\bar{\\lambda}_k\n",
      "\\right]\n",
      "$$\n",
      "where we have suppressed some indices for clarity and included factors of $\\xi_k$ because $\\mu_k$ is an input to the forwards-backwards algorithm used to calculate $\\xi_k$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus\n",
      "$$\n",
      "\\frac{\\partial\\mathcal{L}}{\\partial\\mu_k} =\n",
      "\\sum_j \\mu_j \\frac{\\partial \\xi_j}{\\partial \\mu_k} \n",
      "(\\overline{\\log \\lambda_j} - \\log \\eta - \\log \\mu_j + 1)\n",
      "+ \\xi_k (\\overline{\\log \\lambda_k} - \\log \\eta - \\log \\mu_k + 1) \n",
      "- \\xi_k\n",
      "-\\sum_j \\bar{\\lambda}_j \\frac{\\partial \\xi_j}{\\partial \\mu_k}\n",
      "\\\\\n",
      "= \\sum_j (\\mu_j - \\bar{\\lambda}_j) \\frac{\\partial \\xi_j}{\\partial \\mu_k}\n",
      "+ \\xi_k (\\overline{\\log \\lambda_k} - \\log \\eta - \\log \\mu_k)\n",
      "+ \\sum_j \\mu_j \\frac{\\partial \\xi_j}{\\partial \\mu_k} \n",
      "(\\overline{\\log \\lambda_j} - \\log \\eta - \\log \\mu_j)\n",
      "\\\\\n",
      "= \\sum_j (\\mu_j - \\bar{\\lambda}_j) \\frac{\\partial \\xi_j}{\\partial \\mu_k}\n",
      "+ \\xi_k (\\overline{\\log \\lambda_k} - \\log \\mu_k)\n",
      "+ \\sum_j \\mu_j \\frac{\\partial \\xi_j}{\\partial \\mu_k} \n",
      "(\\overline{\\log \\lambda_j} - \\log \\mu_j)\n",
      "- (\\xi_k + \\sum_j \\mu_j \\frac{\\partial \\xi_j}{\\partial \\mu_k})\\log \\eta = 0\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now note that, taking the derivative of the $\\eta$ constraint above, we have\n",
      "$$\n",
      "\\frac{\\partial}{\\partial \\mu_k} \\sum_j \\mu_j \\xi_j = \n",
      "\\xi_k + \\sum_j \\mu_j \\frac{\\partial\\xi_j}{\\partial \\mu_k} = 0\n",
      "$$\n",
      "Morever, we note that for $c_k \\gg 1$, $\\overline{\\log \\lambda_k} \\approx \\log \\bar{\\lambda}_k$, since $\\psi(x) \\approx \\log x - \\frac{1}{2x} + \\ldots$.\n",
      "\n",
      "Thus, the equation above is satisfied so long as **both** the $\\eta$ constraint holds and \n",
      "$$\n",
      "\\mu_{ku} \\leftarrow \\bar{\\lambda}_{ku} = \\frac{c_{ku}}{d_{ku}}\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Calculating $\\mathbb{E}_q[z_{tk}]$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As noted above, $\\xi_{tk} \\equiv \\mathbb{E}_q[z_{tk}]$ can be computed by the forwards-backwards algorithm, but the exact identity of the local evidence function is unclear, since the $n_{ktu}$ are unobserved. However, we note that, because the $n_{ktu}$ are generated in our $q$ model by independent Poisson processes with rates $z_{tk}\\mu_{ku}$, the sum $\\sum_k n_{ktu}$ is distributed according to the sum of these rates:\n",
      "$$\n",
      "N_{tu} \\sim \\text{Pois}(\\sum_k z_{tk}\\mu_{ku})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can thus integrate out the unobserved $n_{ktu}$ and approximate a solution by updating each chain in turn, treating it as having an effective rate given by its own observation model plus the mean of all other chains:\n",
      "$$\n",
      "N_{tu} \\sim \\text{Pois}(z_{tk}\\mu_{ku} + \\sum_{j \\neq k}\\xi_{tj}\\mu_{ju})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is not an exact approximation, but is justified when $\\xi$ is almost always 0 or 1."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}