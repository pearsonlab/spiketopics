{
 "metadata": {
  "name": "",
  "signature": "sha256:a3b89428a374acd06ba466a5971553c9d88fefde5c77277eb500f0080f7fe122"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this model, we construct a structured variational ansatz that is a product over Markov chains that we solve exactly using forwards-backwards."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model definition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For $T$ times, $U$ units, and $K$ topics, let\n",
      "$$\n",
      "\\lambda_{ku} \\sim \\text{Ga}(a_{ku}, b_{ku}) \\quad \\text{firing rate for each (topic, unit)} \\\\\n",
      "p(z_{tk}|z_{(t-1)k}) = A^{(k)}_{z_{t}, z_{t-1}} \\quad \\text{a column-stochastic Markov matrix} \\\\\n",
      "z_{0k} \\sim \\text{Bern}(\\zeta_{k}) \\quad \\text{the prior on initial state for each topic} \\\\ \n",
      "A^{(k)}_{1i} \\sim \\text{Be}(\\alpha_{ik}, \\beta_{ik}) \\quad \\text{state transition probabilities for each topic} \\\\\n",
      "N_{tu} \\sim \\text{Pois}\\left(\\sum_k z_{tk}\\lambda_{ku} \\right) \\quad \\text{spike count at time $t$ for unit $u$}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we have written $A$ as a column-stochastic matrix\n",
      "$$\n",
      "A = \n",
      "\\begin{pmatrix}\n",
      "\\tau_{0 \\rightarrow 0} & \\tau_{1 \\rightarrow 0} \\\\\n",
      "\\tau_{0 \\rightarrow 1} & \\tau_{1 \\rightarrow 1}\n",
      "\\end{pmatrix}\n",
      "$$\n",
      "such that the evolution of an initial distribution $p(z_0) = \\pi_0$ evolves in time via\n",
      "$$\n",
      "p(z_t) = A^t\\pi_0\n",
      "$$\n",
      "\n",
      "In what follows, we will write $\\tau^{(k)}_{0 \\rightarrow 1} = \\tau_{0k}$ and $\\tau^{(k)}_{1 \\rightarrow 1} = \\tau_{1k}$, so that the within-state transitions have priors\n",
      "$$\n",
      "\\tau_{ik} \\sim \\text{Be}(\\alpha_{ik}, \\beta_{ik})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Joint distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to find \n",
      "$$\n",
      "p(N, z, \\lambda) = p(N|z, \\lambda)p(z)p(\\lambda)\n",
      "$$\n",
      "\n",
      "As above, we can easily write the first factor:\n",
      "$$\n",
      "p(N|z, \\lambda) \\propto \\prod_{tu} \\left(\\sum_k z_{tk}\\lambda_{ku} \\right)^{N_{tu}} e^{-\\sum_k z_{tk}\\lambda_{ku}}\n",
      "$$\n",
      "\n",
      "However, as before, this will not take the exponential form unless we introduce the auxiliary variables $n_{ktu}$ with $\\sum_k n_{ktu} = N_{tu}$. With this, we can expand the first factor in the above via the multinomial theorem to write\n",
      "$$\n",
      "p(n|z, \\lambda) \\propto \\prod_{kt} \\left( \\prod_u \\frac{\\lambda_{ku}^{n_{ktu}}}{n_{ktu}!} e^{-\\lambda_{ku}} \\right)^{z_{tk}}\n",
      "$$\n",
      "with $n_{ktu} = 0$ for $z_{tk} = 0$.\n",
      "\n",
      "That is, we have decoupled the total spike count into the results of separate Poisson processes for each latent factor, coupled through the constraint $\\sum_k n_{ktu} = N_{tu}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition, given $n$, $\\lambda$, and $z$s for the other chains, we can compute $p(z_{\\bullet k}|rest)$ via the forwards-backwards algorithm."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variational ansatz"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we choose a partially factorized ansatz for the posterior:\n",
      "$$\n",
      "q(n, z, \\lambda, \\nu) = q(n)q(z)q(\\lambda)q(\\tau) = \n",
      "\\left(\\prod_{uk} q(n_{k \\bullet u}, z_{\\bullet k}) \\right) \\left(\\prod_{ku} q(\\lambda_{ku}) \\right) \n",
      " \\left(\\prod_{ik} q(\\tau_{ik}) \\right)\\\\\n",
      "\\lambda_{ku} \\sim \\text{Ga}(c_{ku}, d_{ku}) \\\\\n",
      "\\tau_{ik} \\sim \\text{Be}(\\gamma_{ik}, \\delta_{ik})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Warm-up: Simplest HMM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider the case of a single unit $U = 1$ and a single category $K = 1$ plus a baseline rate $\\lambda_0$ ($z_{t0} \\equiv 1$).\n",
      "\n",
      "We will assume all spikes result either from the baseline rate or the single categorical variable, so that the observation model takes the form\n",
      "$$\n",
      "p(n|z, \\lambda) \\propto \\prod_t \\binom{N_t}{n_t} \\left( \\frac{z_t \\lambda}{\\lambda_0 + z_t \\lambda} \\right)^{n_t} \\left( \\frac{\\lambda_0}{\\lambda_0 + z_t \\lambda} \\right)^{N_t - n_t}\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Forwards:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to calculate the vector \n",
      "$$\n",
      "\\alpha_t \\equiv p(z_t|n_{1:t})\n",
      "$$\n",
      "This can be done by decomposing\n",
      "$$\n",
      "\\alpha_t = p(z_t|n_{1:t}) = p(z_t|n_t, n_{1:t-1}) \\propto p(n_t|z_t, n_{1:t-1})p(z_t|n_{1:t-1}) \n",
      "= p(n_t|z_t)p(z_t|n_{1:t-1}) \\\\\n",
      "= p(n_t|z_t) \\sum_{z_{t-1}} p(z_t|z_{t-1})p(z_{t-1}|n_{1:t-1}) = p(n_t|z_t) \\sum_{z_{t-1}} p(z_t|z_{t-1}) \\alpha_{t-1}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now if we define $\\psi_t \\equiv p(n_t|z_t)$ to be the local evidence at time $t$, then we have the update rule\n",
      "$$\n",
      "\\alpha_t \\propto \\psi_t \\odot (A \\cdot \\alpha_t)\n",
      "$$\n",
      "with the constraint that, for all $t$, $\\boldsymbol{1}^T\\alpha_t = 1$\n",
      "\n",
      "Note also that since $\\alpha_t \\propto p(n_t|z_t)p(z_t|n_{1:t-1})$, its normalization constant,\n",
      "$Z_t = \\sum_{z_t} \\alpha_t = p(n_t|n_{1:t-1})$. This allows us to calculate the marginal probability of the data:\n",
      "$$\n",
      "p(\\mathcal{D}) = \\prod_t p(n_t|p_{1:t-1}) \\quad \\Rightarrow \\\\\n",
      "\\log p(\\mathcal{D}) = \\sum_z \\log Z_t\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}