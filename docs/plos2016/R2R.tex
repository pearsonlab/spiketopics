\pdfoutput=1

\documentclass[12pt,a4paper]{article}
% \usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

% \usepackage{lastpage,fancyhdr,graphicx}
% \usepackage{algorithm}
% \usepackage{algpseudocode}
%
% % amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% % Use adjustwidth environment to exceed column width (see example table in text)
% \usepackage{changepage}
%
% % Use Unicode characters when possible
% \usepackage[utf8x]{inputenc}
%
% % textcomp package and marvosym package for additional characters
% \usepackage{textcomp,marvosym}
%
% % cite package, to clean up citations in the main text. Do not remove.
% \usepackage{cite}
%
% % Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}
%
% % line numbers
% \usepackage[right]{lineno}
%
% % ligatures disabled
% \usepackage{microtype}
% \DisableLigatures[f]{encoding = *, family = * }
%
% % color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}
\definecolor{edit}{HTML}{107896}
\definecolor{added}{HTML}{F26D21}
%
% % array package and thick rules for tables
% \usepackage{array}

\newcommand{\edit}[1]{\textcolor{edit}{#1}}
\newcommand{\added}[1]{\textcolor{added}{#1}}
\usepackage{parskip}
\begin{document}

\edit{We are grateful to both reviewers for their thorough reading and constructive comments on our work. While both reviewers showed some enthusiasm for the results of the current model, each raised a constellation of important issues related to its application. Broadly speaking:
\begin{itemize}
    \item {\bf Reviewer 1} asks that we clarify the limitations and caveats needed in applying our model. More specifically, because the model only infers stimulus features given a fixed data set (stimuli + neuron responses), it is difficult to see how to generalize results across experiments. Moreover, while our experiments show that the model infers sensible features, it is less clear what to do in situations where stimuli have no such labels available.
    \item {\bf Reviewer 3} asks that we provide a more extensive discussion placing our model in the context of other latent variable models for neural response data, many of which also rely on Variational Bayes methods. The reviewer also asks that we provide more explicit detail for the algorithm used to perform inference in the model.
\end{itemize}
}

\edit{In this substantially revised manuscript, we have expanded both our presentation of the model and our discussion of its relation to both previous work and experimental application. In particular:
\begin{enumerate}
    \item We have emphasized assumptions, caveats, and limitations of the present model, including discussion of semi-Markov dynamics, binning, and generalization to new data, as per Reviewer 1.
    \item We have substantially revised the introduction to place our work in the context of other latent variable models, particularly those using similar Variational Bayes methods.
    \item We have moved Algorithm 1 from the Supplement to the main text, with equation references for each step.
    \item As suggested by Reviewer 3, we have extensively edited the figure captions for clarity.
    \item {\color{red} goodness of fit for firing rates?}
    \item A new simulation as suggested by Reviewer 1 that shows how the ability of our model to recover latent features is effected by choices of time step size and transient dynamics.
\end{enumerate}
}

\edit{
Extended responses to these and other points raised by the reviewers appear inline below. We hope the reviewers will agree that these revisions and new analyses materially strengthen the original work while appropriately nuancing its claims.
}

{\bf Reviewer \#1}: The authors propose a statistical modeling approach for identifying stimulus features within a highly complex stimulus space that are important for a set of neurons under study. Objectively searching for what neurons actually code, without getting stuck in our preconceived notions, is of fundamental importance to performing replicable, generalizable neuroscience. They approach this by modeling the spike rate as a combination of independent, latent features, each modeled as an HMM. Unlike a standard HMM, this model effectively breaks up a single (complex) state controlling firing rates into the product of binary states, resulting in a potentially far more interpretable structure, especially for complex, multi-neuron data. One notable aspect of the model is that it is applicable to independently recorded cells as long as the stimulus set is shared, and the stimuli can have different presentation lengths. Additionally, the authors use a variational algorithm to keeps the method highly tractable while keeping it Bayesian. The method is clearly presented and this particular way of deconstructing spike trains into a simple set of features is potentially widely applicable in systems neuroscience.

\edit{We appreciate the reviewer's encouraging assessment of our work. As the reviewer notes (and we elaborate in response to Reviewer 3 below), we believe the particular binary, combinatorial decomposition of firing rates we propose is the key innovation in this work.}

My primary critique of this paper is a fundamental issue of framing of the model’s capabilities. Limitations of the model and its features need to be more clearly and accurately addressed. The authors argue that their “work focuses on detecting features in external stimuli.” They state that features they detect in neural data can be used to tag stimuli and refine the stimulus set they use. However, there is a crucial step missing between the states identified by this model in the neural data and stimulus: we are given a set of features corresponding to each stimulus presented in the experiment, not a function mapping stimulus space to features. This problem is highlighted by the IT example with neurons selective for complex visual features. The authors demonstrate that the states in their model correspond to selectivity for complex visual features, such as monkey close-ups or monkey body parts. These are reasonable conclusions (and serve to validate that the model is acting sensibly), but the analysis of the features relied entirely on the hand-labeled stimulus features given by the authors – opening the door to subjective feature selectivity this paper aims to avoid.


{\color{red}{I want to be really careful here. This is just a first stab.}}

\edit{
The reviewer is correct here in noting that our model does not learn a mapping from stimuli to features. Indeed, because our model uses only an index for each stimulus, along with neural responses, it is difficult to imagine how one might infer such a map without either reference to pixel values (in the case of image stimuli) or neural responses to the new stimulus. This is precisely because our model defines features \emph{only with respect to a given set of neural responses}. As the reviewer has discerned, this is a limitation for generalizing to new populations (e.g., in other brain regions), but does have the advantage of not requiring analysis of the content of stimuli.
}

\edit{
We would also like to note that this limitation is not specific to our model. In fact, it is shared by a large number of other unsupervised machine learning approaches such as topic modeling or the latent linear dynamical systems model of Park et al. cited by Reviewer 3 below. In these cases, the typical strategy for validating models has been to show that when trained on well-understood benchmark data sets, such methods recover interpretable structure that bears some resemblance to either human intuition or ground truth labels. As the reviewer notes, our model does this. Moreover, as we have clarified in the text, none of our experiments makes use of stimulus labels for model fitting. Labels are only used as a point of comparison with inferred features. In fact, in the case of the data set involving IT neurons, the features we discuss in Figure 6 (direct and indirect gaze) \emph{were not provided} as lables in the original data set.
}

\edit{
Finally, in our revised introduction we have attempted to clarify the intended use of our model. The reviewer raises the concern that simply fitting our model to a single set of neurons and stimuli would not be sufficient to refine a much larger stimulus set to which the neurons had not been exposed. This is correct, but is somewhat different than the problem our model is designed to solve. We imagine an experiment (similar to many real electrophysiology experiments) in which animals might be exposed to a wide variety of stimuli, to which individual neurons respond diversely. Our model, applied to the resulting data, would then infer a set of binary tags for each stimulus. As in our Experiments section, it would then fall to the experimenters to determine what commonality existed among stimuli tagged with Feature 1, Feature 2, etc. When these features are interpretable, they suggest new, more focused hypotheses about neural responses that can be tested. The missing link to which the reviewer refers is the generalization from feature tags to interpretable hypotheses.
}

\edit{
Thus for example, in the IT data set, it is clear that Feature 0 corresponds to close-ups of monkey faces, and it would have been easy to see this simply by examining the images tagged with this feature, apart from any experimenter-provided labels. In a screening experiment involving a large collection of stimuli, detecting this feature would have suggested a follow-up experiment in which a larger set of monkey faces might be used.
}

Unlike a regression model like a GLM, this model does not appear to simply generate predictions of the neural responses to new stimuli. For this model to be more helpful in the way the authors suggest for refining stimulus sets in an objective way without a priori labels, we’d like to have an objective estimate of whether or not a feature is present in a new stimulus. Thus, the strong language of the intro and conclusion ought to be backed up by a more compelling demonstration that it can show something new in the stimulus space, something that is necessary to account for the firing rates, beyond a set of predefined features.

\edit{
These issues are related to those addressed above, but we would like to provide the following more focused responses:
\begin{itemize}
    \item The reviewer is correct in that our model is unable to make predictions about neural responses to new stimuli without additional information. In a GLM, this information, the covariates, are provided by the modeler or the experimenter. In our case, if the tags inferred in the original data set are interpretable (as they are in our examples), predictions could be made on the basis of these interpretations. For example, our fitted model is easily able to predict the response of each IT neuron to a new stimulus tagged exclusively with Feature 0. To the degree we are confident that Feature 0 corresponds to close-ups of monkey faces, we can make predictions about the responses of the neurons in our data set to new monkey faces.
    \item As we have noted above, it is not generally possible to create a map between latent features and unseen stimuli in the absence of neural response data to those stimuli (at least not without making use of the content of the stimuli themselves). However, because our model is both generative and Bayesian, it does facilitate predictions about the distribution of population responses in response to new stimuli, conditioned on knowing the feature labels. As noted above, this does rely on the idea that inferred features are often interpretable.
\end{itemize}
}

Specific comments.
\begin{enumerate}
\item Semi-Markov dynamics are emphasized in the introduction (abstract and at line 50 of page 2). Is the comment about the model handling nontrivial state duration distributions justified given the results presented in this paper? The model fits appear to all assume Markov transitions (geometrically distributed duration times).

\edit{
Our experiments indeed used only Markov assumptions, but given that both our supplemental text and code are capable of relaxing this assumption to the semi-Markov case, we thought this important to mention. However, we understand how this can be confusing, and so we have removed mention of semi-Markov dynamics from the abstract and introduction and pointed readers to the supplement.
}

\item The model here defines features as having constant gain effect on the cells when they are present. However, neural responses may include features that are not constant (e.g., oscillatory), and the particular binning used could affect how this model pulls out features as well as the spike count overdispersion. While this model can surely cope with some dynamics, I would like to see a bit of discussion on the assumptions and consequences of this particular definition of feature along with binning choices, perhaps assisted by a simulation. Does changing the bin width on the given examples alter the model’s behavior?

\edit{
The reviewer raises an important issue. Our model is capable of capturing neural dynamics only over the time resolution provided by binning, and this is surely not sufficient for cases where transients and oscillations in firing rate are important. Moreover, under the Poisson assumption, the coefficient of variation of spike counts scales as $\frac{1}{\sqrt{t}}$ for fixed firing rate, so we are incentivized to choose larger bins as a means of increasing the signal-to-noise ratio.
}

\edit{
In our experiments, we have restricted ourselves to ``natural'' bin sizes for each problem: 20ms (a common smoothing window) for the Roitman-Shadlen data and 400ms (the duration of baseline, stimulus exposure, and post-stimulus period) for the McMahon et al. IT data. In the case of the former, this captures a rough accounting of the dynamics (Figure 4C), though one that clearly oversimplifies. In the case of the latter, we are implicitly assuming that the firing rates are constant during each epoch. This assumption is not terrible, but it does ignore the lag in the onset and offset of neural responses.
}

\edit{
To further explore this, we performed a simulation as suggested by the reviewer. We repeated an experiment similar to our synthetic data example, except in this case, the time step used to generate the data ($5$ms) was not necessarily that used to perform inference (5, 10, 20, 50, or 100ms). As expected, recovery performance degrades as coarser and coarser bins are used for inference, but it does so gracefully. Not until a bin size of 50ms (a tenfold increase over the underlying Markov dynamics) is the ability of the model to recover accurate features seriously compromised. We believe this suggests that, so long as the inference time step size is not grossly larger than the feature dynamics of interest, the model should perform well.
}

\edit{
Additionally, we explored the effect of a different kind of dynamics---firing rate transients unrelated to HMM features---by repeating the simulation with a stimulus onset transient added to the start of each trial. As expected, the model accommodated this additional phenomenon by inferring \emph{previously unused} features that could account for the sudden increase in firing. And again, these new features were distince from the data-generating latents until time steps grew large, at which point the model largely lost its ability to capture the transient. Like the above, this suggests that applications of the model should use a time step comparable in magnitude to the fastest dynamics of interest, but that this correspondence need not be precise. Full details and results of both of these simulations are now available in Supplementary Material S3.
}

\item For the model fit performance in figure 4C and 5C-D, could you provide a quantitative summary on how well does this fit the data? I would also like to see a clarification with these inferred rates as to how latent features inferred from the neural responses for those same stimuli as opposed to being a purely predictive measure.

\edit{
We have added these measures to the relevant section of the manuscript. While we believe the best assessment of goodness of fit to the data is the lower bound on the log evidence of the data $\log p(\mathcal{D})$ estimated by our model, this measure is also less than intuitive.
Therefore, we have used a simple normalized RMS error for the firing rate curves in Figure 4C and the inferred firing rates in Figures 5C and D. That is, we calculated $\sqrt{\frac{\mathbb{E}[(f_i - f_a)^2]}
{\mathbb{E}[f_i]\mathbb{E}[f_a]}}$ for each unit, where $f_i$ is the inferred firing rate from the model and $f_a$ is the ``actual'' firing rate estimated from data. In the case of the Roitman data set, the square root of this number ranges from 4 to 12 percent across the traces in Figure 4C. For the McMahon data, this ranges from 18 to roughly 200 percent across neurons. Note, however, that in the second case, we have only a few observations of each stimulus for each unit. Thus, latent binary features may be correctly recovered even when firing rates are only qualitatively reconstructed. We have added a discussion of the significance of these numbers to the main text of the paper.
}

\item On the LIP data from Roitman \& Shadlen, the use of this dataset along with conditioning on motion coherence strikes me as a peculiar choice for this paper because coherence is a label/feature given by the experimenter, and not the actual stimulus - almost the situation this method is designed to avoid. I don’t think this analysis needs to be dropped, but I’d like to see a little more explanation and justification. To elaborate, each stimulus presentation is randomly generated so that the average motion follows the coherence level, and neurons in MT (although this is a different brain area) show stable rates on average to these stimuli. However, in response to repeated presentations of the same random dot stimulus, MT cells can show more complicated temporal dynamics corresponding to the particular stimulus and thus a different stimulus conditioning could potentially invoke a different set of states (see comment 2).
a. One clarification on the analysis: is the conditioning on IN vs. OUT purely on choice, or is motion direction given? Does conditioning on both motion direction and choice (which I think is warranted here) show anything more?

\edit{
We apologize for what we believe is a confusion related to our description of the experiment. The goal of our analysis was to determine how well the binary latent features inferred by our model might match those used by the experimenters in generating the data set. As seen in Figure 4, the features that our model inferred as driving neural responses only partially overlapped with those chosen by the experimenters, and we find this difference illuminating as to both the strengths and limits of our method. More importantly, in answer to several issues raised by the reviewer:
\begin{itemize}
    \item Our method never had access to either the response field variables (IN vs OUT) or the coherences, \emph{per se}. Rather, the model receives a unique stimulus code that combines RF, coherence, and time during the trial. Figure 4A represents the design matrix as specified by the experimenters. Figure 4B is sorted along the same horizontal axis for comparison purposes only.
    \item While we agree with the reviewer that differences in time courses across trials in response to different stimuli with the same coherence are interesting and may be illuminating, we note two things:
    \begin{itemize}
        \item The available dataset only contains stimulus codes corresponding to the coherence and RF (IN vs OUT) presented on a given trial. We are thus prevented (for this data set) from a comparison across identical dot patterns.
        \item Our model only captures regularities across presentations in whatever we code as distinct stimuli. As a result, we are only able to infer what is held in common against repeated presentations of the same motion coherence and RF. Trial-to-trial variation is captured by the variable $\theta$ in our model, which in this experiment was modeled as iid Gamma.
        \item Motion direction was given in the data set, but our experiment used only correct choices. As a result, these two variables were confounded (choosing the target in the RF means that motion was toward the RF). We regret the omission of this detail in our description and have clarified in the text.
    \end{itemize}
\end{itemize}
}
\end{enumerate}

Minor comments
\begin{itemize}
    \item Page 2, line 36 typo: “from a calcium images”

    \edit{Thank you. We have corrected this.}
\end{itemize}

{\bf Reviewer \#3}: Review of Neuron's Eye View: Inferring Features of Complex Stimuli from Neural Responses

The paper suggests a Bayesian hierarchical firing rate model for data analysis that aims to identify features that are hidden in unstructured stimuli, based only on the neural data. The approach falls within the class of the widely studied Poisson latent state space models. Going beyond classic approaches positing a simple low-dimensional latent dynamic system, the authors consider a richer hierarchical distribution over prior dynamic models, an approach that is becoming popular in recent years both in Machine Learning and Computational Neuroscience. The firing rates of neurons in this setting are assumed to be sensitive to multiple discrete time-varying features tied to the stimulus, which are modeled based on Markov (or semi-Markov) dynamics. The authors propose a variational inference mechanism for inferring the latent variables, and demonstrate their results in several experimental settings.

\edit{
This is an excellent summary of our work. The reviewer is clearly well-versed in the relevant literature and has pointed out several ways in which the broader modeling context can be clarified in our work, which we address below.
}

As noted above the model presented belongs to the increasingly studied class of hierarchical latent state space models with a Poisson observation model. The main novelty seems to be in the introduction of the binary latent space variables interpreted as tags and modeled using Markovian (or semi-Markovian) dynamics. I found the presentation of the approach somewhat misleading, as it tends to imply that the paper introduces a novel class of models, while the major novelty seems to be in the interpretation of the hidden latent dynamics. I think this issue should be clarified, in order to set the present work within the general context of research in this field. Moreover, the paper emphasizes the novelty of the variational Bayesian approach for neural data analysis. This is a widely studied research domain with Machine Learning in recent years, and many approaches have been developed, albeit for non-Poisson models (e.g., Variational Inference: A Review for Statisticians for a review 2016, Blei et al). In the context of Poisson models, references 14 and 15 as well as the paper "Unlocking neural population non-stationarities using hierarchical dynamics models." By Park et al (NIPS 2015) provide a very similar framework for neural data analysis, which is difficult to distinguish from the present work. Thus, I feel that paper somewhat over-sells the novelty of the approach. As far as I can see the main novelty is in the interpretation of the latent variables, which may be very helpful for interpreting experimental results, but, in my view, does not constitute the conceptual contribution implied by the authors. In order for the paper to be published, I would urge the authors to put their model in context, and describe precisely how it differs from this recent work, and whether the claimed merits are due to a more flexible modeling framework or to a novel interpretation of the hidden dynamic process.

\edit{
We concur with the reviewer that the field of latent state Poisson models is a rich and active one, and variational Bayes methods are often used for performing inference in related work. And while we also agree with the reviewer that these features are not specific to our work, our goal in the introduction was to give at least some of the rationale behind these models for an audience less well-versed in this subfield. However, the reviewer is correct in noting that more can be done to link our work to existing approaches and place it within the context of recent advances in the field.
}

\edit{
To address this concern, we have substantially expanded our introduction to better place our work in context and include citations both to the Park et al. work and the excellent review by Blei et al. In brief, we view the key points of departure for our work as follows:
\begin{itemize}
    \item Much previous work (Refs. 10-16) has focused on modeling neural responses as driven by linear dynamical systems with continuous latent states. The evolution of these inputs may be conditioned on known covariates $\mathbf{x}_t$, but the focus in these models has been on capturing the dynamics of neural firing (in some cases within single trials), not regularities in spiking across repeated stimulus presentations.
    \item In Park et al., the model captures variability within trials by a latent dynamical system within each trial subject to a slower modulation across trials. We view this as a complementary model, since our model uses a discrete latent state and instead focuses on responses to stimuli that are reliable across trials. Combining this with the Park et al. model would likely help compensate for drift in neural recordings across trials.
    \item A related paper from the Macke group (Ref. 18) also makes use of a discrete latent state (governed by a tree structure) that can be conditioned on external covariates (e.g., stimulus identity). This work improves upon the paper of Escola et al. (2011) by a set of assumptions that effectively reduce the number of parameters in the model. Our model likewise uses discrete latent states but organizes these into a collection of binary HMMs, which are assumed to be deterministically, not probabilistically, related to the presented stimulus. This results in a restriction that the model only ascribe to the latents features that are directly attributable to the stimulus, as the latent features are determined by stimulus alone.
    \item Finally, our model also allows for semi-Markov dynamics and autocorrelated noise in the firing rate gain across bins.
\end{itemize}
}

\edit{
To address this shortcoming, we have revised the introduction extensively to discuss these related models, as well as place our own work within that broader context. Changes are highlighted in the revised manuscript.
}

Moving now to more technical issues. I found the presentation of the model and setup somewhat confusing. I assume that when the authors refer to a time-dependent firing rate they are referring to the firing rate of a doubly stochastic point process depending on external signals. However, the authors do not use point processes in continuous time but model the system in discrete time. The use the symbol $\Lambda$ to denote the time-dependent firing rate at time t. This should be clearly defined in terms of the continuous-time time-dependent firing rate characterizing point processes in continuous time. They do not define $N_m$. Are they referring to the total count until time t or the increment in number of spikes between points in time? In short, I would like to see a fundamental definition of the continuous time point process and its relation to the firing-rate process they describe (or, alternatively, provide a precise reference to this equation).

\edit{
We apologize for the confusion. We everywhere use a discrete time index and model binned spike counts. $N_m$ is defined in the paragraph above its first usage (Eq 1), but this has been clarified in the revised text.
}

Moreover, equation (10) presents the complete log likelihood function. It would be more informative to the reader to first express the likelihood itself, since it simply the product of Poisson distributions and would be much clearer to the reader.

\edit{
We have added this equation to the manuscript.
}

I believe Algorithm 1 should be moved to the main text, as it is comprises an essential part of the paper. Furthermore, each line in the algorithm should refer to a specific equation in the main text or in the supplementary text, so that the implementation of the algorithm is clear and transparent to the reader.

\edit{
We have moved Algorithm 1 to the main paper. It is now located at the end of the Inference section. We have also added equation references for each line.
}

A computational paper of this form should present a self-contained derivation of the algorithm. For example, how are the forward-backward variables in eq. (3) of the supplementary material computed? In short, I would expect a full specification of the algorithm derivation, since there is no other war for a reader to verify its correctness. If certain aspects are standard please refer to a specific equation in a paper/book where it is presented. As a concrete example of the level of detail I would expect in a paper purporting to derive a novel algorithm, please see the appendix of the paper “Unlocking neural population non-stationarities using hierarchical dynamics models", Park et al (NIPS 2015).

\edit{
We agree with the reviewer that verifiability of the algorithm is an important point. Our Algorithm now has specific line references for each step, and the supplement provides full details. As for standard algorithms:
For inference in the HMM, we use the well-known forward-backward algorithm, for which we now provide a textbook citation (Murphy, 2012). For inference in the semi-Markov case, we provide a citation for the relevant algorithm (Yu and Kobayashi, 2006). We have also substantially expanded our treatment of the relevant notation and algorithms for the semi-Markov case in our supplementary materials. Finally, we provide a full implementation of all algorithms used in the paper (with unit tests) at \url{https://github.com/pearsonlab/spiketopics}.
}

As stated previously, there have been several recent papers presenting inference within a variational hierarchical dynamical system Bayesian model. The present paper should clarify the conceptual and practical differences with these works.

\edit{
As noted above, we agree with the reviewer about the importance of clarifying these relationships. We hope that the reviewer will agree that our expanded and revised introduction succeeds much better in placing our work within the context of other related models.
}

Please explain the over-line notation in eq. (4) of the supplementary material.
The experimental results seem interesting and novel, to the best of my knowledge, and point to the power of the method. I found the figures and figure captions rather difficult to follow. While I don’t have specific suggestions, I would urge the authors to try simplifying the explanations in the captions.

\edit{
To simplify notation, we have denoted expectations in the supplement by overlines: $\mathbb{E}[x] = \overline{x}$. This is now explained in the supplement.
}

\edit{We have also endeavored to clarify and simplify the figure captions.}

\end{document}
