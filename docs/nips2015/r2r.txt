We would like to thank the reviewers for their thoughtful consideration of our work. Several reviewers expressed enthusiasm for the paper, while others raised questions about the success of our model in the experiments presented and its relation to other work.

Below, we have collected responses to questions raised by multiple reviewers together and address smaller considerations individually. We believe that several of the model performance issues raised by reviewers resulted from poor explanation on our part, and we attempt to clarify these in the following. Moreover, we offer additional comments (particularly under point 3) which we hope highlight the unique contributions of this work to the rich literature on neural modeling.

First, several misunderstandings arose from our (necessarily) brief treatment of the experiments:


1. **Feature recovery**: Reviewers 2 and 5 raised a concern that our model did not recover all the features present in the Roitman and Shadlen dataset (Figure 3). As a result, our results struck them as not particularly strong, and this diminished their enthusiasm for the method.

However, our discussion of these results seems to have failed to convey two key points:

    1. When the average firing rates for each coherence are plotted with uncertainty indicated (i.e., with error bands), it becomes apparent that some differences between intermediate coherence levels that appear in the experimental design and the plot of means (left bottom panel of Figure 3) do not have much statistical support in the data. That is, our model does recover the features in the data for which there is strong evidence, but parsimoniously prunes those for which there is little evidence. Moreover, because our model enforces this parsimony through a prior, adjusting the prior will result in a higher or lower evidence threshold for feature discovery in the stimulus.

    2. Reviewer 5 notes "no obvious correspondence between actual and discovered features" in Figure 3. This is a failure of communication on our part, and will be remedied in the revised version of the paper (along with the other figure improvements suggested). For example:
        - Feature Z0 is on when the stimulus is out of the response field (and correctly captures the delay between its onset and the differentiation of in vs. out neural responses).
        - Feature Z1 is on whenever the stimulus is in the response field.
        - Feature Z2 captures the early vs late stimulus period for most coherences.
        - Feature Z4 is specific to an interaction between the highest coherence level (51%) and movement into the response field.
    We note that not only does each of these features capture some event determined by the experimenter, but also includes timing information about the neural responses that would not have been known in advance.


2. **Correlated variability**: Reviewers 2 and 5 note that our model does not include correlated variability among units across stimulus presentations. We agree that this aspect of neural firing is significant and a true independence assumption across units is not justified.

However, since the datasets we used were the result of single neuron recording, they did not require this additional modeling complexity, and we omitted it from the paper. However, this is not difficult to add to the model, and we are happy to do so in the revised version of the paper (perhaps in the supplment, in the interest of space).

On a somewhat related note: Reviewer 5 notes that the construction on ll98-103 does not seem to be used in the paper. It is, in fact, necessary for Experiment 3, in which different clips within a large movie databased were presented to different neurons in different experimental sessions. Not every unit saw every clip, clip start times were randomly selected from within the larger movie, and thus different units were presented with quite different sets of movie frames. We regret the additional complexity of the bookkeeping, but we do need this. We will clarify this point in the revision.


3. **Relation to other models**: Reviewers 5, 6, and 7 all questioned the relationship between our model and other extant techniques in the literature.

As Reviewer 5 correctly notes, the key novel feature of the model is its applicability to stimulus sets with no intrinsic metric: by asking which stimuli drive neural firing in similar ways, we are constructing a representation of the stimulus space in which neural population firing itself supplies the metric. In fact, this answers the question raised by Reviewer 7, who asks how our method differs from that of simply modeling neural dynamics and correlating the resulting features against the stimulus set: such an approach requires, a priori, a (usually low-dimensional) representation of the stimulus space against which to correlate.

Reviewer 6, who was enthusiastic about the paper, notes that the interpretation of discovered latent features might be difficult (though cf. our comments in 1.2 about features in the LIP data). We agree, but note that topic models, despite also suffering from this problem, have nonetheless proven capable of discovering sensible structure. Indeed, the motivating applications for our model are in areas of neuroscience such as social and strategic interaction, where the structure of the "stimulus" space is incredibly poorly understood. We believe this work to be most applicable to these and similar cases, where many fewer task conditions are under experimental control and there is a desperate need for methods which *jointly* model neural and stimulus dynamics.

Small issues:

R5:
    - Thank you for these references and corrections.
    - ll55-56. We did not mean to imply a deficiency. Our main point here was about the need for a metric in existing models, as the reviewer notes. We are happy to clarify in the revision.
    - We are happy to employ a more standard MI normalization.

R6:
    - We appreciate the references (and the understanding about limited space!). We will attempt to consolidate and rebalance references in the revision.