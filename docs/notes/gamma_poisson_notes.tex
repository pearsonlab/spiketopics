\documentclass[11pt]{article}
\usepackage{amssymb,amsmath}

\begin{document}
\title{The Gamma-Poisson Model}
\author{John Pearson}
\maketitle

\section{Observation Model}
We assume a Poisson process with $T$ observation times, $N$ observation units, and $K$ latent states. The counts for each unit at each time are then given by

\begin{equation}
    N_{tu} \sim \mathrm{Poisson}(e^{\mu_{tu}})
\end{equation}
with
\begin{equation}
   \mu_{tu} = (ZB)_{tu} = \sum_k z_{tk} b_{ku}
\end{equation}
with $z$ the time series of latent states (assumed binary) and $b$ the regression coefficients. In addition, we assume the $z_t$ have independent Markov transition dynamics within each latent state (see below).

In addition, it will be more convenient for our purposes to rewrite the above expression using $b_{ku} = \log \lambda_{ku}$, so that
\begin{equation}
    p(N_{tu}|\lambda, z) = \frac{\prod_k \lambda_{ku}^{N_{tu} z_{tk}}}{N_{tu}!} e^{-\prod_k \lambda_{ku}^{z_{tk}}}
\end{equation}
which can be rewritten
\begin{equation}
    \log p(N_{tu}|\lambda, z) = N_{tu} \sum_k z_{tk} \log \lambda_{ku} - \prod_k \lambda_{ku}^{z_{tk}} - \log N_{tu}!
\end{equation}
Clearly, if we treat $N$ and $z$ as constants, we have
\begin{equation}
    \lambda_{ku}|N, z \sim \mathrm{Gamma}(\sum_t N_{tu}z_{tk} + 1, \sum_t\prod_{k'\neq k} \lambda_{k'u}^{z_{tk'}})
\end{equation}

\section{Hidden Markov Model}
Here, we assume a hidden Markov model for each latent state. That is, we take
\begin{align}
    A_{ji} &\equiv p(z_{t+1}=j|z_t = i) \\
    \pi_i &\equiv p(z_0 = i)
\end{align}
(Note that this means that the \emph{columns} of $A$ sum to 1, which is the opposite of the usual convention. In other words, in matrix notation, $z_{t+1} = A \cdot z_t$.)

Given this notation, it is straightforward to write the probability of a sequence of hidden states, conditioned on the chain parameters
\begin{equation}
    \log p(z|A, \pi) = \sum_t \log A_{z_{t+1} z_t} + \log \pi_{z_0}
\end{equation}

\section{Priors}
We would also like to put priors on the parameters of the model. For $\lambda$, this is straightforward:
\begin{equation}
    \lambda_{ku} \sim \mathrm{Gamma}(c_{ku}, d_{ku})
\end{equation}

For the parameters of the Markov chain, we have the restriction that the columns must sum to 1, so we place priors on the probability of $z_{0k} = 1$
\begin{equation}
    \pi_{k} \sim \mathrm{Beta}(\rho_{k1}, \rho_{k2})
\end{equation}
and the probabilities of transition \emph{into} the $z_{tk} = 1$ state:
\begin{equation}
    A_{k1i} \sim \mathrm{Beta}(\nu_{ki1}, \nu_{ki2})
\end{equation}

\section{Variational Ansatz}
We would like to approximate the joint posterior density
\begin{equation}
    p(\lambda, z, A, \pi|N) \propto p(N, z|\lambda, A, \pi) p(\lambda) p(A) p(\pi)
\end{equation}
with a structured mean field form that factorizes over chains:
\begin{equation}
     q(\lambda, z, A, \pi) = \prod_{ku} q(\lambda_{ku}) q(z_k) q(A_k) q(\pi_k)
\end{equation}
Given the form taken by the model above, we can readily write down the ansatz
\begin{align}
    \lambda_{ku} &\sim \mathrm{Gamma}(\alpha_{ku}, \beta_{ku}) \\
    z_{1:T, k} &\sim \mathrm{HMM}(\eta_k, \tilde{A}_k, \tilde{\pi}_k) \\
    A_{k1i} &\sim \mathrm{Beta}(\gamma_{ki1}, \gamma_{ki2}) \\
    \pi_k &\sim \mathrm{Beta}(\delta_{k1}, \delta_{k2})
\end{align}
where $\mathrm{HMM}(\ldots)$ denotes the joint posterior over hidden states at each moment in time:
\begin{equation}
    p(z_{1:T}|N, \theta) = \frac{p(z_{1:T}, N|\theta)}{Z}
\end{equation}
where $Z \equiv p(N|\theta)$ and $\theta \equiv (\lambda, A, \pi)$. As we shall see, this posterior is straightforward to calculate via the forward-backward algorithm.

\section{HMM Inference}
Given parameters $\theta \equiv (\lambda, A, \pi)$, the well-known Forward-Backward Algorithm returns the following:
\begin{align}
    \xi_{t} \equiv p(z_{t}|N, \theta) \qquad &\text{posterior marginals}\\
    \Xi_{t, ij} \equiv p(z_{t+1} = j, z_{t} = i|N, \theta) \qquad &\text{two-slice marginals}\\
    \log Z_{t} = \log p(N_{t+1, \bullet}|N_{t\bullet}, \theta) \qquad &\text{partition function}
\end{align}
The first two will be helpful in calculating expections with respect to $q(z)$, while the last gives us the normalization for the joint posterior over all $z$: $\log Z = \sum_t \log Z_{t} = \log p(N_{1:T}|\theta)$.

\section{Evidence Lower Bound (ELBO)}
We begin by writing the joint distribution of the data:
\begin{multline}
    \log p(N, \lambda, z, A,\pi) = \sum_{ktu}\left[ N_{tu} z_{tk} \log \lambda_{ku} - \prod_k \lambda_{ku}^{z_{tk}} - \log N_{tu}!\right] \\
    + \sum_{tk} \log (A_k)_{z_{t+1, k} z_{t, k}} + \log (\pi_k)_{z_{0k}} \\
    + \log p(\lambda) + \log p(A) + \log p(\pi)
\end{multline}

We would like to calculate
\begin{multline}
    \mathcal{L} = \mathbb{E}_q\left[\log \frac{p}{q}\right] = \mathbb{E}_{q(\pi)} \left[\log \frac{p(\pi)}{q(\pi)} \right] + \mathbb{E}_{q(A)} \left[\log \frac{p(A)}{q(A)} \right] + \mathbb{E}_{q(\lambda)} \left[\log \frac{p(\lambda)}{q(\lambda)} \right] \\ + \mathbb{E}_{q}\left[ \log \frac{p(N, z|\lambda, A, \pi)}{q(z)}\right]
\end{multline}
which we will do in pieces.

\subsection{$\pi$}
First, we have
\begin{equation}
    \mathbb{E}_{q(\pi)} \left[\log \frac{p(\pi)}{q(\pi)} \right] = \sum_k \left[(\rho_{k1} - 1)\overline{\log \pi_{k1}} + (\rho_{k2} - 1) \overline{\log \pi_{k0}} - \log B(\rho_{k1}, \rho_{k2}) + H(\pi_k) \right]
\end{equation}
with
\begin{align}
    \overline{\log \pi_{k1}} &= \psi(\delta_{k1}) - \psi(\delta_{k1} + \delta_{k2}) \\
    \overline{\log \pi_{k0}} &= \psi(\delta_{k2}) - \psi(\delta_{k1} + \delta_{k2})
\end{align}
with $\psi$ the digamma function and
\begin{equation}
    H(\pi_k) = H_b(\delta_{k1}, \delta_{k2})
\end{equation}
with $H_b$ the entropy of the beta distribution:
\begin{equation}
    H_b(\alpha, \beta) = \log B(\alpha, \beta) - (\alpha - 1) \psi(\alpha) - (\beta - 1) \psi(\beta) + (\alpha + \beta - 2)\psi(\alpha + \beta)
\end{equation}

\subsection{$A$}
Similarly,
\begin{equation}
    \mathbb{E}_{q(A)} \left[\log \frac{p(A)}{q(A)} \right] =
\sum_{ik} \left[ (\nu_{ki1} - 1) \overline{\log A_{k1i}} + (\nu_{ki2} - 1) \overline{\log A_{k0i}} - \log B(\nu_{ki1}, \nu_{ki2}) + H(A_{k1i}) \right]
\end{equation}
where
\begin{align}
    \overline{\log A_{k1i}} &= \psi(\gamma_{ki1}) - \psi(\gamma_{ki1} + \gamma_{ki2}) \\
    \overline{\log A_{k0i}} &= \psi(\gamma_{ki2}) - \psi(\gamma_{ki1} + \gamma_{ki2})
\end{align}
and again
\begin{equation}
    H(A_{k1i}) = H_b(\gamma_{ki1}, \gamma_{ki2})
\end{equation}

\subsection{$\lambda$}
Next, we want to calculate terms involving $\lambda$, for which we will use some properties of Gamma distributions:
\begin{align}
   \mathbb{E}[\lambda] &= \frac{\alpha}{\beta} \\
   \mathbb{E}[\log \lambda] &= \psi(\alpha) - \log \beta \\
   H_g(\alpha, \beta) &= \alpha - \log \beta + \log \Gamma(\alpha) + (1 - \alpha)\psi(\alpha)
\end{align}
to write
\begin{equation}
    \mathbb{E}_{q(\lambda)} \left[\log \frac{p(\lambda)}{q(\lambda)} \right] = \sum_{ku} \left[ (c_{ku} - 1)\overline{\log \lambda_{ku}} + d_{ku} \frac{\alpha_{ku}}{\beta_{ku}} + H_g(\alpha_{ku}, \beta_{ku})\right]
\end{equation}
with
\begin{equation}
    \overline{\log \lambda_{ku}} = \psi(\alpha_{ku}) - \log \beta_{ku}
\end{equation}

\subsection{Observation model}
Finally, we would like to calculate
\begin{multline}
    \label{KLobs}
    \mathbb{E}_{q}\left[ \log \frac{p(N, z|\lambda, A, \pi)}{q(z)}\right] = \sum_{ktu} N_{tu}\xi_{tk}\overline{\log \lambda_{ku}} - \sum_{tu} \prod_k \left( 1 - \xi_{tk} + \xi_{tk} \frac{\alpha_{ku}}{\beta_{ku}}\right)
    \\
    + \sum_{kt} \left[\mathrm{tr}\left(\Xi_{kt} \overline{\log A_k^T}\right) + \xi_{0k}^T \overline{\log \pi_k} \right]
    \\
    - \sum_{kt} \left[ \xi_{tk}^T \eta_{tk} + \mathrm{tr}\left(\Xi_{kt} \tilde{A}_k^T\right) + \xi_{0k}^T \tilde{\pi}_k - \log Z_{kt} \right]
\end{multline}
where we make use of the outputs of the forward-backward algorithm and the vector/matrix representations of $\tilde{A}$, $\tilde{\pi}$, $\eta$, $\xi$, and $\Xi$.

\section{Variational Updates}
Technically, the variational parameters above are $(\alpha, \beta, \gamma, \delta, \eta, \tilde{A}, \tilde{\pi})$. However, $\xi = \xi(\eta, \tilde{A}, \tilde{\pi})$ and $\Xi = \Xi(\eta, \tilde{A}, \tilde{\pi})$ so we can instead treat these as the effective variational parameters. This then readily gives as updates:
\begin{align}
    \eta_{tk} &\leftarrow
    \begin{pmatrix}
        -\sum_u F_{tku} \\
        \sum_u N_{tu} \overline{\log \lambda_{ku}} -
        \sum_u \frac{\alpha_{ku}}{\beta_{ku}} F_{tku}
    \end{pmatrix} \\
    \tilde{A}_{k} &\leftarrow \overline{\log A_k} \\
    \tilde{\pi}_k &\leftarrow \overline{\log \pi_k}
\end{align}
where we define
\begin{equation}
    F_{tku} \equiv \prod_{j \neq k} \left( 1 - \xi_{tj} + \xi_{tj} \frac{\alpha_{ju}}{\beta_{ju}}\right)
\end{equation}
We note, after Beal, that as a result of these updates, $\tilde{A}$ and $\tilde{\pi}$ are subadditive (i.e., they do not sum to 1), but that the forward-backward algorithm nonetheless returns a correctly normalized posterior.


Similarly, variation with respect to the prior parameters for $(\lambda, A, \pi)$ gives
\begin{align}
    \alpha_{ku} &\leftarrow \sum_t N_{tu} \xi_{tk} + c_{ku} \\
    \beta_{ku} &\leftarrow \sum_t F_{tku}\xi_{tk} + d_{ku} \\
    \gamma_{ki1} &\leftarrow \nu_{ki1} + \sum_t \Xi_{kt, 1i} \\
    \gamma_{ki2} &\leftarrow \nu_{ki2} + \sum_t \Xi_{kt, 0i} \\
    \delta_{k1} &\leftarrow \rho_{k1} + \xi_{0k} \\
    \delta_{k2} &\leftarrow \rho_{k2} + 1 - \xi_{0k}
\end{align}
These, then, give the proper updates for coordinate ascent.

\section{Multiple observations}
We have thus far used the time index $t$ assuming no ambiguity between stimulus time and presentation time. In the case that each stimulus is presented once, this presents no problem, but here we extend the analysis to the case where some stimuli are presented multiple times. To do so, we will continue to let $t$ designate the time within the stimulus but introduce an additional index $m$ that takes on a unique value for each stimulus presentation. Thus, different trials will have different values of $m$, but may have the same value of $t$.

We can easily modify the observation model to incorporate this setup. Instead of observing a single count $N_{tu}$ for a given unit at a given stimulus time, we observe a \emph{set} of counts $\{ N_{m u} \vert t(m) = t \}$. (Here, we abuse notation by writing $t$ as both the index and the mapping from presentation index to stimulus time.) If we assume trials are independent, the log likelihoods of these observations simply add, in which case we simply replace sums over $t$ with sums over $m$:
\begin{align}
    \sum_{ktu} N_{tu} \xi_{tk} \overline{\log \lambda_{ku}} &\rightarrow \sum_{km u} N_{m u} \xi_{t(m) k} \overline{\log \lambda_{ku}} \\
    \sum_{tu} \prod_k \left( 1 - \xi_{tk} + \xi_{tk} \frac{\alpha_{ku}}{\beta_{ku}}\right) &\rightarrow \sum_{m u} \prod_k \left( 1 - \xi_{t(m) k} + \xi_{t(m) k} \frac{\alpha_{ku}}{\beta_{ku}}\right)
\end{align}
Clearly, if we group the sum over $m$ into sums over trials at the same stimulus time $t$, we can easily rewrite these expressions in the form
\begin{align}
    \sum_{km u} N_{m u} \xi_{t(m) k} \overline{\log \lambda_{ku}} &= \sum_{ktu} \hat{N}_{tu} \xi_{tk} \overline{\log \lambda_{ku}} \\
    \sum_{m u} \prod_k \left( 1 - \xi_{t(m) k} + \xi_{t(m) k} \frac{\alpha_{ku}}{\beta_{ku}}\right) &= \sum_{tu} M_{tu}\prod_k \left( 1 - \xi_{tk} + \xi_{tk} \frac{\alpha_{ku}}{\beta_{ku}}\right)
\end{align}
where we have defined
\begin{align}
    \hat{N}_{tu} = \sum_{m:\, t(m) = t} N_{m u} \\
    M_{tu} = \sum_{m:\, t(m) = t} 1
\end{align}
as the cumulative spike count and effective number of observations at each stimulus time, respectively. Note that the result of this process has simply been to replace $N \rightarrow \hat{N}$, $F \rightarrow M F$, meaning we can write modified update equations as follows:
\begin{align}
    \eta_{tk} &\leftarrow
    \begin{pmatrix}
        -\sum_u M_{tu} F_{tku} \\
        \sum_u \hat{N}_{tu} \overline{\log \lambda_{ku}} -
        \sum_u M_{tu}\frac{\alpha_{ku}}{\beta_{ku}} F_{tku}
    \end{pmatrix} \\
    \alpha_{ku} &\leftarrow \sum_t \hat{N}_{tu} \xi_{tk} + c_{ku} \\
    \beta_{ku} &\leftarrow \sum_t M_{tu} F_{tku}\xi_{tk} + d_{ku}
\end{align}
In fact, for simplicity in what follows, we will drop the hat notation on $N$, with the understanding that when $N$ appears with a $t$ index, it is the sum over all counts at that time.

\section{Overdispersion}
\subsection{Fluctuation in multiple observations}
To model overdispersion in our count data, we can include an additional moment-by-moment fluctuation in the firing rate of each unit:
\begin{equation}
    (\lambda_{\mathrm{eff}})_{tu} = \prod_k \lambda_{ku}^{z_{tk}}\theta_{tu}
\end{equation}
If, like $\lambda$, $\theta$ is assumed to be gamma-distributed, then this is equivalent (upon marginalizing $\theta$) to a negative binomial model for the counts $N$. However, it will be simpler for the variational updating if we retain $\theta$. We will assume that the overdispersion varies across units but not in time:
\begin{align}
    p(\theta_{mu}) &= \mathrm{Gamma}(s_u, r_u) \\
    q(\theta_{mu}) &= \mathrm{Gamma}(\omega_{mu}, \zeta_{mu})
\end{align}
and include additional terms in the pieces of the evidence lower bound above:
\begin{align*}
    \sum_{ktu} N_{tu} \xi_{tk} \overline{\log \lambda_{ku}} &\rightarrow \sum_{kmu} N_{mu} \xi_{t(m)k} \overline{\log \lambda_{ku}} + \sum_{mu} N_{mu} \overline{\log \theta_{mu}} \\
    &= \sum_{ktu} N_{tu} \xi_{tk} \overline{\log \lambda_{ku}} + \sum_{mu} N_{mu} \overline{\log \theta_{mu}} \\
    - \sum_{tu} \prod_k \left( 1 - \xi_{tk} + \xi_{tk} \frac{\alpha_{ku}}{\beta_{ku}}\right) &\rightarrow - \sum_{mu} \frac{\omega_{mu}}{\zeta_{mu}} \prod_k \left( 1 - \xi_{t(m)k} + \xi_{t(m)k} \frac{\alpha_{ku}}{\beta_{ku}}\right)
\end{align*}
Note in particular that the overdispersion term is assumed to always be present, and that it is unique to every stimulus presentation ($m$ index), not merely every moment during the stimulus itself ($t$ index). Nevertheless, the fact that the prior for this term depends only on the unit, $u$, means that we can aggregate sufficient statistics across repetitions, eliminating the $m$ index in favor of $t$.

yielding
\begin{align}
    \mathbb{E}_{q(\theta)} \left[ \log \frac{p(\theta)}{q(\theta)} \right] &=
    \sum_{mu} \left[ (s_u - 1) \overline{\log \theta_{mu}} - r_u \overline{\theta_{mu}} + H_g(\omega_u, \zeta_u) \right] \\
    &= \sum_{mu} \left[ (s_u - 1) (\psi(\omega_{mu}) - \log \zeta_{mu}) - r_u \frac{\omega_{mu}}{\zeta_{mu}} + H_g(\omega_{mu}, \zeta_{mu}) \right]
\end{align}
with $H_g$ the differential entropy for the gamma distribution, as above. By analogy with $\lambda$, we can easily write down the updates for $\omega$ and $\zeta$
\begin{align}
    \omega_{mu} &\leftarrow N_{mu} + s_u \\
    \zeta_{mu} &\leftarrow F_{t(m)u} + r_u
\end{align}
with
\begin{equation}
    F_{tu} \equiv \prod_k \left( 1 - \xi_{tk} + \xi_{tk} \frac{\alpha_{ku}}{\beta_{ku}}\right)
\end{equation}
Similarly, the update for the local emission probability, $\eta$ takes the form
\begin{equation}
    \eta_{tk} \leftarrow
    \begin{pmatrix}
        -\sum_{u, m: \, t(m) = t} \frac{\omega_{mu}}{\zeta_{mu}} F_{t(m)ku} \\
        \sum_u N_{tu} \overline{\log \lambda_{ku}} -
        \sum_{u, m: \, t(m) = t} \frac{\omega_{mu}} {\zeta_{mu}}\frac{\alpha_{ku}}{\beta_{ku}} F_{t(m)ku}
    \end{pmatrix}
\end{equation}
All other updates should remain unchanged.

\subsection{Fluctuation in natural time}
Here we consider the correlation of firing rates in consequential natural time slots. Different from the discussion above, we include the moment-by-moment fluctuation in the firing rate of each unit:
\begin{equation}
    (\lambda_{\mathrm{eff}})_{tu} = \prod_k \theta_{\tau u} \lambda_{ku}^{z_{tk}}
\end{equation}
where $\tau$ is the natural time when movie clip is played.

Further, we assume the overdispersion parameter $\theta_{\tau u} = \phi_{\tau u} \theta_{\tau - 1, u}$ is modulated by $\phi$ from the last moment. Let $\phi_{0u} = \theta_{0, u}$, then we have $\theta_{\tau u} = \prod_{\tau' \le \tau} \phi_{\tau' u}$.

Therefore, the terms that contains $\lambda$ in ELBO can be modified as follows. One term that corresponds to $N\log(\lambda_{\mathrm{}})$ is:
\begin{align*}
    \sum_{tu} N_{tu} \log(\lambda_{\mathrm{eff}})_{tu}
    % = \sum_{tu} N_{tu} \log \left(\prod_{\tau' \le \tau} \phi_{\tau' u}  \prod_k \lambda_{ku}^{z_{tk}} \right) \\
    &= \sum_{\tau u} N_{\tau u} \sum_{\tau' \le \tau} \log\phi_{\tau' u} + \sum_{tu} N_{tu} \sum_k z_{tk} \log\lambda_{ku} \\
    &= \sum_{\tau u} \log\phi_{\tau u} \sum_{j \ge \tau}N_{ju} + \sum_{tu} N_{tu} \sum_k z_{tk} \log\lambda_{ku} \\
    &= \log\phi_{ju} \sum_{j' \ge \tau}N_{j'u} + \sum_{u, \tau \ne j} \log\phi_{\tau u} \sum_{j' \ge \tau}N_{j'u} + \sum_{tu} N_{tu} \sum_k z_{tk} \log\lambda_{ku}
\end{align*}

The other term corresponds to $\lambda_{\mathrm{eff}}$ is:
\begin{align}
    \sum_{tu}(\lambda_{\mathrm{eff}})_{tu} &= \sum_{\tau u} \prod_{\tau' \le \tau} \phi_{\tau' u} \prod_k \lambda_{ku}^{z_{t(\tau)k}} \\
    &= \phi_{ju} \sum_{u, \tau \ge j} \prod_{\substack{\tau' \ge \tau \\ \tau' \ne j}} \phi_{\tau'u} \prod_k \lambda_{ku}^{z_{t(\tau)k}}
\end{align}

Assume the error correlation $\phi$ follows a gamma distribution for every natural time $\tau$, and all $\phi$'s are independent of each other. Then we have:
\begin{align}
    p(\phi_{\tau u}) &= \mathrm{Gamma}(s_u, r_u) \\
    q(\phi_{\tau u}) &= \mathrm{Gamma}(\omega_{\tau u}, \zeta_{\tau u})
\end{align}

Take expectation with respect to $q(\phi)$, we have:
\begin{align}
    \mathbb{E}_{q}[\cdot] &= \mathbb{E}_{q} \left[\sum_{\tau u} \log\phi_{\tau u} (\sum_{j \ge \tau}N_{ju}) \right]
    + \mathbb{E}_{q}\left[\sum_{tu} N_{tu} \sum_k z_{tk} \log\lambda_{ku} \right] \\
    &= \sum_{\tau u}\overline{\log\phi_{\tau u}} \sum_{j \ge \tau}N_{ju} + \sum_{ktu} N_{tu}\xi_{tk} \overline{\log \lambda_{ku}}
\end{align}

For the second term, assume that $\phi_{\tau u}$ is independent of $\lambda_{ku}$, and follows a Gamma distribution as stated above:
\begin{align}
    \mathbb{E}_{q}[\cdot] &= \sum_{\tau u} \mathbb{E}_{q} \left( \prod_{\substack{\tau' \le \tau}} \phi_{\tau' u} \right) \mathbb{E}_{q} \left(\prod_k \lambda_{ku}^{z_{t(\tau)k}} \right) \\
    &= \sum_{\tau u} \prod_{\substack{\tau' \le \tau}} \frac{\omega_{\tau' u}}{\zeta_{\tau' u}} \prod_k \left( 1 - \xi_{t(\tau)k} + \xi_{t(\tau)k} \frac{\alpha_{ku}}{\beta_{ku}} \right)
    %&= \sum_{u, \tau \ge j} \prod_{\tau' \le \tau} \frac{\omega_{\tau' u}}{\zeta_{\tau' u}} \prod_k \left( 1 - \xi_{t(\tau)k} + \xi_{t(\tau)k} \frac{\alpha_{ku}}{\beta_{ku}} \right)
\end{align}

Then in the formula of ELBO, the piece that contributes to $\lambda$ now becomes:
\begin{align*}
    \sum_{ktu} N_{tu}\xi_{tk} \overline{\log \lambda_{ku}} &\rightarrow \sum_{ktu} N_{tu}\xi_{tk} \overline{\log \lambda_{ku}} + \sum_{\tau u} \overline{\log\phi_{\tau u}} \sum_{j \ge \tau} N_{ju} \\
    - \sum_{tu} \prod_k \left( 1 - \xi_{tk} + \xi_{tk} \frac{\alpha_{ku}}{\beta_{ku}}\right) &\rightarrow - \sum_{\tau u} \prod_{\tau' \le \tau} \frac{\omega_{\tau' u}}{\zeta_{\tau' u}} \prod_k \left( 1 - \xi_{t(\tau)k} + \xi_{t(\tau)k} \frac{\alpha_{ku}}{\beta_{ku}} \right)
\end{align*}

Assume that the correlation over all natural time is always present. Therefore, we have
\begin{equation}
    \mathbb{E}_{q(\phi)} = \left[ \log \frac{p(\phi)}{q(\phi)} \right] &= \sum_{\tau u} [(s_u - 1) \overline{\log \phi_{\tau u}} - r_u \overline{\phi_{\tau u}} + H_g(\omega_u, \zeta_u)]
\end{equation}

By comparing the terms that involves $\log \phi_{\tau u}$ and $\phi_{\tau u}$ in the ELBO, we can write down the updates for $\omega_{j u}$ and $\zeta_{j u}$ in gradient ascent as
\begin{align*}
    \omega_{j u} &\leftarrow s_u + \sum_{j' \ge j} N_{j'u} \\
    \zeta_{j u} &\leftarrow r_u + \sum_{u, \tau \ge j} F_{t(\tau)u} \prod_{\substack{\tau' \le \tau \\ \tau' \ne j}} \frac{\omega_{\tau' u}}{\zeta_{\tau' u}}
\end{align*}

where $j \in \{1, 2, \ldots, T \}$ and $F_{t(\tau)u} \equiv \prod_k \left( 1 - \xi_{t(\tau)k} + \xi_{t(\tau)k} \frac{\alpha_{ku}}{\beta_{ku}} \right)$.

Similarly, the update for the local emission probability, $\eta$ now becomes:

\begin{align*}
    \eta_{tk} \leftarrow
    \begin{pmatrix}
        -\sum_{u, \tau: \, t(\tau) = t} F_{t(\tau)ku} \prod_{\tau' \le \tau}\frac{\omega_{\tau' u}}{\zeta_{\tau' u}} \\
        \sum_u N_{tu} \overline{\log \lambda_{ku}} - \sum_{u, \tau: \, t(\tau) = t} F_{t(\tau)ku} \frac{\alpha_{ku}}{\beta_{ku}} \prod_{\tau' \le \tau}\frac{\omega_{\tau' u}}{\zeta_{\tau' u}}
    \end{pmatrix}
\end{align*}

\section{External covariates}
\subsection{Gamma priors}
In addition, we might also want to include external covariates $X(t)$ with an effect on firing rate. Thus we will include an $X$-dependent gain change of firing rate:
\begin{equation}
    \lambda_{u}(t) \propto \prod_i \upsilon_{iu}^{x_{iu}(t)}
\end{equation}
where $i$ indexes the particular regressor. Thus the total expression for firing rate for a given unit $u$ at time $t$ for a given presentation $m$ with overdispersion is
\begin{equation}
    \lambda_{mu} = \theta_{mu}\left(\prod_k \lambda_{ku}^{z_{t(m)k}} \right) \left(\prod_i \upsilon_{iu}^{x_{t(m)iu}} \right)
\end{equation}
Note that we have discretized $t$ as above and assume that the external covariates $x$ depend only on the stimulus time, not the particular presentation, so that they carry an index $t(m)$, while $\theta$ carries an index particular to each repeated presentation.

It will be convenient for us to assume that both the priors and the variational posterior for $\upsilon$ are gamma in form:
\begin{align}
    p(\upsilon_{iu}) &= \mathrm{Gamma}(v_{iu}, w_{iu}) \\
    q(\upsilon_{iu}) &= \mathrm{Gamma}(a_{iu}, b_{iu})
\end{align}
This contributes an additional factor to the ELBO
\begin{multline}
    \mathbb{E}_{q(\upsilon)} \left[ \log \frac{p(\upsilon)}{q(\upsilon)} \right] =
    \sum_{iu} \left[ (v_{iu} - 1) \overline{\log \upsilon_{iu}} - w_{iu} \frac{a_{iu}}{b_{iu}} + H_g(a_{iu}, b_{iu}) \right] =\\
    \sum_{iu} \left[ (v_{iu} - 1) (\psi(a_{iu}) - \log b_{iu}) - w_{iu} \frac{a_{iu}}{b_{iu}} + H_g(a_{iu}, b_{iu}) \right]
\end{multline}
plus corrections to the observation probability piece of $\mathbb{E}_q[\log p(N, z|\lambda, A, \pi) / q(z)]$:
\begin{multline}
    \sum_{ktu} N_{tu} \xi_{tk} \overline{\log \lambda_{ku}} + \sum_{mu} N_{mu} \overline{\log \theta_{mu}} + \sum_{tiu} N_{tu} x_{tiu} \overline{\log \upsilon_{iu}} \\
    - \sum_{mu} \frac{\omega_{mu}}{\zeta_{mu}} \prod_k \left( 1 - \xi_{t(m)k} + \xi_{t(m)k} \frac{\alpha_{ku}}{\beta_{ku}}\right)\prod_i \left(\frac{a_{iu}}{b_{iu}} \right)^{x_{t(m)iu}}
\end{multline}

This leads straightforwardly to updates for the posterior parameters of $q(\upsilon)$:
\begin{align}
    a_{iu} &\leftarrow \sum_t N_{tu} x_{tiu} + v_{iu} \\
\end{align}
For $b_{iu}$, we can more easily calculate the gradient with respect to the parameter $\log b$:
\begin{align}
    \nabla_{\log b_{iu}} \mathcal{L} = &-(v_{iu} - 1) +
    w_{iu} \frac{a_{iu}}{b_{iu}} - 1 - \sum_t N_{tu} x_{tiu} \\
    & + \sum_m x_{t(m)iu} \frac{\omega_{mu}}{\zeta_{mu}}
    \prod_k \left(1 - \xi_{t(m)k} + \xi_{t(m)k}
    \frac{\alpha_{ku}}{\beta_{ku}}\right)
    \prod_j \left(\frac{a_{ju}}{b_{ju}}\right)^{x_{t(m)ju}} \\
    &= -a_{iu} + w_{iu} \frac{a_{iu}}{b_{iu}}
    + \sum_m x_{t(m)iu} \frac{\omega_{mu}}{\zeta_{mu}}
    \prod_k \left(1 - \xi_{t(m)k} + \xi_{t(m)k}
    \frac{\alpha_{ku}}{\beta_{ku}}\right)
    \prod_j \left(\frac{a_{ju}}{b_{ju}}\right)^{x_{t(m)ju}}
\end{align}
Thus, the updated value of $b_{iu}$, $b^*_{iu}$, is the solution to the transcendental equation
\begin{equation}
    b_{iu} = w_{iu} + \left( \frac{b_{iu}}{a_{iu}}\right) \sum_{m} x_{t(m)iu}\left[ \frac{\omega_{mu}}{\zeta_{mu}} \prod_k \left( 1 - \xi_{t(m)k} + \xi_{t(m)k} \frac{\alpha_{ku}}{\beta_{ku}}\right)\prod_{j} \left(\frac{a_{ju}}{b_{ju}} \right)^{x_{t(m)ju}} \right]
\end{equation}

Alternately, since we expect $\lvert (a/b) - 1 \rvert \ll 1$ when $x \gg 1$, we can write $b_{iu} = a_{iu}e^{-\epsilon_{iu}}$, in which case
\begin{multline}
    \mathcal{L}_b = \sum_{iu} \left[a_{iu} \epsilon_{iu} - w_{iu} e^{\epsilon_{iu}}\right] \\
     - \sum_{mu} \frac{\omega_{mu}}{\zeta_{mu}}
    \prod_k \left(1 - \xi_{t(m)k} + \xi_{t(m)k}
    \frac{\alpha_{ku}}{\beta_{ku}}\right)
    e^{\sum_j \epsilon_{ju} x_{t(m)ju}}
\end{multline}
and
\begin{multline}
    \nabla_\epsilon \mathcal{L}_b = a_{iu} - w_{iu} e^{\epsilon_{iu}} \\
    - \sum_m x_{t(m)iu} \frac{\omega_{mu}}{\zeta_{mu}}
    \prod_k \left(1 - \xi_{t(m)k} + \xi_{t(m)k}
    \frac{\alpha_{ku}}{\beta_{ku}}\right)
    e^{\sum_j \epsilon_{ju} x_{t(m)ju}}
\end{multline}

 In addition, the additional regressor terms necessitate changes to the update rules given above:
\begin{align}
    \beta_{ku} &\leftarrow \sum_t M_{tu} F_{tku} \xi_{tk} G_{tu} \\
    \zeta_{mu} &\leftarrow F_{t(m)u} G_{t(m)u} + r_u \\
    \eta_{tk} &\leftarrow
    \begin{pmatrix}
        -\sum_{u, m: \, t(m) = t} \frac{\omega_{mu}}{\zeta_{mu}} F_{t(m)ku}
        G_{t(m)u}\\
        \sum_u N_{tu} \overline{\log \lambda_{ku}} -
        \sum_{u, m: \, t(m) = t} \frac{\omega_{mu}} {\zeta_{mu}}\frac{\alpha_{ku}}{\beta_{ku}} F_{t(m)ku}  G_{t(m)u}
    \end{pmatrix}
\end{align}
where
\begin{align}
    G_{tu} &\equiv \prod_i G_{tiu} \\
    G_{tiu} &\equiv \left(\frac{a_{iu}}{b_{iu}} \right)^{x_{tiu}}
\end{align}

Possible strategies here:
\begin{itemize}
    \item Update $a$ exactly. Use a Newton's Method approach to solve for $b$.
    \item Update $a$ exactly. Use a single Newton step on $b$.
    \item Gradient descent on $a$ and $b$ together.
\end{itemize}

\subsection{Log-Normal priors}
Here, we will write the change in log firing as linear in $x(t)$:
\begin{equation}
    \log \lambda_{tu} \propto \sum_{iu} b_{iu} x_{tiu}
\end{equation}
We will also assume a normal distribution for both prior and posterior on $b$:
\begin{align}
    p(b_{iu}) &= \mathcal{N}(m_{iu}, \varsigma^2_{iu}) \\
    q(b_{iu}) &= \mathcal{N}(\mu_{iu}, \sigma^2_{iu})
\end{align}
Using standard standard formulas for the entropy of normal distributions, along with the fact that $\mathbb{E}[e^{tx}] = \exp(t\mu + t^2\sigma^2/2)$ for $x \sim \mathcal{N}(\mu, \sigma^2)$, it is then straightforward to write down the portion of the ELBO dependent on $\mu$ and $\sigma^2$:
\begin{multline}
    \mathcal{L} = \sum_{iu} \left[ -\frac{1}{\varsigma^2_{iu}} \left( \sigma^2_{iu} + (\mu_{iu} - m_{iu})^2 \right) + \frac{1}{2} \log \frac{\sigma^2_{iu}}{\varsigma^2_{iu}} \right] + \sum_{tiu} N_{tu} x_{tiu} \mu_{iu} \\
    - \sum_{mu} \overline{\theta_{mu}} F_{t(m)u} G_{t(m)u}
\end{multline}
where we have defined
\begin{equation}
    G_{tu} = \prod_i e^{\mu_{iu} x_{tiu} + \frac{1}{2} \sigma^2_{iu} x^2_{tiu}} = \exp\left(\sum_i\left( \mu_{iu} x_{tiu} + \frac{1}{2} \sigma^2_{iu} x^2_{tiu}\right)\right)
\end{equation}
In this case, the equations that must be solved to update $\mu$ and $\sigma^2$ take the form
\begin{align}
    \mu_{iu} &= m_{iu} + \varsigma^2_{iu} \sum_t N_{tu} x_{tiu} - \varsigma^2_{iu} \sum_{m} \overline{\theta_{mu}} F_{t(m)u} G_{t(m)u} x_{t(m)iu} \\
    \frac{1}{\sigma^2_{iu}} &= \frac{1}{\varsigma^2_{iu}} + \sum_{m} \overline{\theta_{mu}} F_{t(m)u} G_{t(m)u} x^2_{t(m)iu}
\end{align}
Since $G_{tu}$ depends on both $\mu_{iu}$ and $\sigma^2_{iu}$, these are both transcendental equations. In the case of $x(t) = c$ a constant in time, they can be solved via variable transform using the Lambert $W$ function, but for time-varying $x$, root-finding algorithms will be needed.

\subsubsection{Approximating the sum of exponentials}
We would like a cheap way of evaluating the objective $\mathcal{L}$ above, but the last term involves all variables and is a sum over time (the other sum over time decomposes easily). In fact, there is a nice trick to approximate this term.

We can begin by writing the non-$G$ terms, which are constants in $\mu$ and $\sigma^2$ in exponential form:
\begin{equation}
    \theta_{mu} F_{t(m)u} = e^{A_{mu}}
\end{equation}
so that we can write the final term as
\begin{equation}
    \sum_{mu} \exp\left(A_{mu} +  \sum_i \left[ \mu_{iu} x_{t(m)iu} +
    \frac{1}{2} \sigma^2_{iu} x^2_{t(m)iu}\right]\right)
\end{equation}
But recall that this is equal to the expectation
\begin{equation}
    \sum_{mu}\mathbb{E}\left[ \theta_{mu} \prod_k \lambda_{ku}^{z_{t(m)k}}
    \prod_i e^{b_{iu} x_{t(m)iu}}\right]
\end{equation}
and often in practice, the expectations we are summing are quite close to 1 (exponents close to 0). This means, of course, that we can approximate
\begin{equation}
    \sum_n e^{x_n} \approx \sum_n (1 + x_n + \ldots) \approx e^{\sum_n x_n}
\end{equation}
In fact, even in cases where a scaling constant $\Lambda$ exists such that $\Lambda e^{x_n} \approx 1$ for all $n$ (i.e., $x - \log \Lambda \approx 0$), we have
\begin{equation}
    \sum_n e^{x_n} \approx \Lambda^{-1} \sum_n e^{x_i + \log \Lambda} \approx
    \Lambda^{N - 1} e^{\sum_n x_n}
\end{equation}
Thus, we might well consider approximating the last term in $\mathcal{L}$ as
\begin{multline}
    \sum_{mu} \exp\left(A_{mu} +  \sum_i \left[ \mu_{iu} x_{t(m)iu} +
    \frac{1}{2} \sigma^2_{iu} x^2_{t(m)iu}\right]\right) \approx \\
    \exp\left(\sum_{mu} A_{mu} +  \sum_{imu} \left[ \mu_{iu} x_{t(m)iu} +
    \frac{1}{2} \sigma^2_{iu} x^2_{t(m)iu}\right]\right)
\end{multline}
which leads to dramatically simpler expressions for the gradient and Hessian.

\subsubsection{Natural Gradients}
In case it's useful later, here are the natural gradients. Since the natural paramter of the normal distribution is $\eta = (\mu/\sigma^2, -1/2\sigma^2)$, we can write for the natural gradient
\begin{equation}
    \nabla_\eta \mathcal{L} = \left( \sigma^2 \frac{\partial \mathcal{L}}{\partial \mu}, 2\sigma^4 \frac{\partial \mathcal{L}}{\partial \sigma^2}\right)
\end{equation}
and use
\begin{align}
    \frac{\partial \mathcal{L}}{\partial \mu_{iu}} &=
    -\frac{\mu_{iu}}{\varsigma^2_{iu}} + \frac{m_{iu}}{\varsigma^2_{iu}} + \sum_t N_{tu} x_{tiu} - \sum_{m} \overline{\theta_{mu}} F_{t(m)u} G_{t(m)u} x_{t(m)iu} \\
    \frac{\partial \mathcal{L}}{\partial \sigma^2_{iu}} &=
    \frac{1}{2\sigma^2_{iu}} - \frac{1}{2\varsigma^2_{iu}} - \frac{1}{2} \sum_{m} \overline{\theta_{mu}} F_{t(m)u} G_{t(m)u} x^2_{t(m)iu}
\end{align}

\section{Hierarchy over units}
Up to this point, we have not made the very natural assumption that parameters for a given neural unit are drawn from a common distribution. Equivalently, we might want to make inferences not only about coefficients for single units, but about distributions for the population as a whole. That is, we might want to assume
\begin{align}
    \lambda_{ku} &\sim \mathrm{Ga}(c_k, d_k) \\
\end{align}
With appropriate priors on $c_k$ and $d_k$

\subsection{Derivation of closed-form hyperpriors}
What form should the distribution of the hyperpriors on $c$ and $d$ take? (In this section, we will suppress the index $k$.) To begin, we can write the likelihood for the $\lambda_u$ terms:
\begin{equation}
    \log p(\lambda) = \sum_u \log p(\lambda_u|c, d) = \sum_u \left[
    (c - 1) \log \lambda_u - d\lambda_u + c \log d - \log \Gamma(c)
    \right]
\end{equation}
The $\log \Gamma(c)$ term presents a challenge, but we can use bounds on the gamma function of the form
\begin{equation}
    \sqrt{2\pi} \le \frac{z!}{z^{z+\frac{1}{2}} e^{-z}} \le e
\end{equation}
along with the identities $z! = \Gamma(z + 1)$ and $\log \Gamma(z + 1) = \log \Gamma (z) + \log z$ to write
\begin{equation}
    \log \sqrt{2\pi} + \left(z - \frac{1}{2}\right)\log z - z \le
    \log \Gamma (z) \le 1 + \left(z - \frac{1}{2}\right) \log z - z
\end{equation}
which we can use to get a lower bound on $-\log \Gamma (z)$. That is
\begin{multline}
    \log p(\lambda) \ge \sum_u \left[
    (c - 1) \log \lambda_u - d\lambda_u + c \log d -
    \left(1 + \left(c - \frac{1}{2}\right) \log c - c\right)
    \right] \\
    = \sum_u \left[
    (c - 1) (\log \lambda_u + 1) - d\lambda_u + c \log \frac{d}{c} +
    \frac{1}{2} \log c
    \right]
\end{multline}
Here, it is the $c\log c$ term that presents a challenge for finding a conjugate prior, but the choice $d = \theta c$, corresponding to a $\mathrm{Ga}(c, c\theta)$ prior on firing rate effects --- equivalent to a mean effect of $\frac{1}{\theta}$ --- allows us to cancel terms and write
\begin{equation}
    \label{plambda}
    \log p(\lambda) \ge \sum_u \left[
    (c - 1) (\log \lambda_u + 1) - c\theta\lambda_u + c \log \theta + \frac{1}{2}\log c\right]
\end{equation}
Clearly, the conditional distributions for $c$ and $\theta$ have the form
\begin{align}
    c &\sim \mathrm{Ga}\left(\frac{U}{2} + 1, \sum_u \left[
    \theta\lambda_{u} - \log \theta - \log \lambda_{u} - 1
    \right]\right) \\
    \theta &\sim \mathrm{Ga}\left(
    cU + 1, c \sum_u \lambda_u
    \right)
\end{align}
As a result, we can easily implement a hierarchical model with closed-form updates by choosing Gamma priors on $c_k$ and $\theta_k$. More intuitively, we might want to think of putting Inverse-Gamma priors on $\theta^{-1} = \mathbb{E}[\lambda]$ and $c^{-1} = \mathbb{E}[\lambda]^2 \mathrm{var}[\lambda]$. A sparse prior on $\lambda$ then consists of a pair of priors that concentrates $\theta^{-1}$ around 1 and $c^{-1}$ around 0. In this case, given the model
\begin{align}
    \theta &\sim \text{Ga}(a, b) \\
    c &\sim \text{Ga}(g, h)
\end{align}
The posterior distributions are
\begin{align}
    \theta &\sim \text{Ga}\left(a + Uc, b + c\sum_u \lambda_u \right) \\
    c &\sim \text{Ga}\left(g + \frac{U}{2}, h - U(\log \theta + 1)
    + \sum_u \left[ \theta \lambda_u - \log \lambda_u \right]\right)
\end{align}

\subsection{Unit-level sparsity}
The above discussion implements ARD-like sparsity at the level of features, but expression of features may also be sparse within the neural population. For instance, we may have
\begin{align}
    \lambda \sim \mathrm{Ga}(c, c\theta)
\end{align}
for units with the feature but $\lambda = 1$ for units without the feature. Indeed, we can combine these cases by introducing a discrete latent variable for each unit and feature, $\alpha_{ku} \in \lbrace 0, 1 \rbrace$ such that
\begin{align}
    \lambda &\sim
    \begin{cases}
        \mathrm{Ga}(c, c\theta) & \alpha = 1 \\
        \mathrm{Ga}(C, C) & \alpha = 0
    \end{cases}
\end{align}
with $C \gg 1$ large and fixed. That is, $\alpha$ is the probability that the feature will be drawn from the population distribution, while $1 - \alpha$ is the probability it will be drawn from a population that is approximately a delta function around 1.

With this ansatz, we then write, in analogy with (\ref{plambda})
\begin{align}
    \mathbb{E}_q [\log p(\lambda, \alpha, \pi)] &=
    \mathbb{E}_q[\log p(\lambda|\alpha)] + \mathbb{E}_q[\log p(\alpha|\pi)]
    + \mathbb{E}_q[\log p(\pi)] \\
    &\ge \sum_u \alpha_u \left[
    (c - 1) (\log \lambda_u + 1) - c\theta\lambda_u + c \log \theta + \frac{1}{2}\log c\right] \\
    &+ \sum_u (1 - \alpha_u) \left[
        (C - 1)(\log \lambda_u + 1) - C\lambda_u + \frac{1}{2}\log C
     \right] \\
     &+ \sum_u \left[\alpha_u \log \pi + (1 - \alpha_u) \log (1 - \pi)\right] \\
     &+ a \log \pi + b \log (1 - \pi)
\end{align}
which leads to revised posterior updates
\begin{align}
    \theta &\sim \text{Ga}\left(a + c\sum_u \alpha_u, b + c\sum_u \alpha_u\lambda_u \right) \\
    c &\sim \text{Ga}\left(g + \frac{1}{2}\sum_u \alpha_u,
    h - (\log \theta + 1)\sum_u \alpha_u
    + \sum_u \alpha_u \left[ \theta \lambda_u - \log \lambda_u \right]\right)
\end{align}
Assuming a Bernoulli prior on $\alpha_{ku}$ likewise leads to conjugate updates, with sufficient statistics
\begin{align}
    &\mathbb{E}_q \left[
        (c - 1) (\log \lambda_u + 1) - c\theta\lambda_u + c \log \theta + \frac{1}{2}\log c
    \right] \\
    &\mathbb{E}_q \left[
        (C - 1)(\log \lambda_u + 1) - C\lambda_u + \frac{1}{2}\log C
    \right]
\end{align}

\section{Semi-Markov Models}
This section follows the paper by Yu and Kobayashi (2006), as well as papers by Mitchell and Jamieson (1993) and Mitchell, Harper, and Jamieson (1995).

We again begin with the parameters defining the Hidden Markov Model (HMM): $A_{ji} = p({i \rightarrow j})$ is the transition matrix between states, with the columns of $A$ summing to 1 (again, the opposite of the usual convention, such that time evolution is equivalent to $A$ acting to the right on a state vector). Likewise, the initial probability of state $i$ is $\pi_i = p(z_0 = i)$. Finally, we will write $\psi_{tj} = p(y_t|z_t = j)$ for the local evidence for the observation $y_t$. Here, we will follow Murphy in adopting the convention that observations are indexed from 1 to $T$, with initial conditions indexed by 0. (Note that, for the forward-backward algorithm, $\psi$ does not have to be normalized along its second index. In fact, we have the freedom to rescale $\psi$ by an overall constant \emph{at each $t$}.)

Now, for the semi-Markov case, we assume that states $\tau$ persist for (integer) durations $d_\tau$ governed by a probability mass function $p(d_\tau)$ such that $\sum_{\tau} d_{\tau} = T$. We can then write the marginal probability of the observation sequence over all time $T$ (divided into $n_\tau$ segments) as
\begin{align}
    p(y_{1:T}) &= \sum_{n_\tau} p(n_\tau)\sum_z \prod_{\tau = 0}^{n_\tau} p(z_{\tau+1}|z_\tau) p(d_{\tau}|z_{\tau})
    \prod_{i = t_{i(\tau)}}^{t_{f(\tau)}} p(y_i|z_\tau) \\
    &= \sum_{n_\tau} p(n_\tau) \sum_z \pi(z_0) \prod_{\tau = 1}^{n_\tau} A_{z_{\tau+1}, z_{\tau}} p(d_{\tau}|z_{\tau})\prod_{i = t_{i(\tau)}}^{t_{f(\tau)}} \psi_{iz_{\tau}}
\end{align}
with $t_{i(\tau)}$ and $t_{f(\tau)}$ the start and end points of the given state and we have made the strong conditional independence assumptions that state durations depend only on the current state, state transitions are independent of duration, and observations within each state are iid.

\subsection{Forward-Backward Algorithm for HSMM}
Here, we follow Yu and Kobayashi, mutatis mutandis. Define:
\begin{align*}
    \psi_t(m) &= p(y_t|z_t=m) &\text{observation probability}\\
    \alpha_{t|x}(m, d) &= p(z_t=m, d_t=d|y_{1:x}) &\text{condition on data}\\
    \gamma_{t|x}(m) &= \sum_d \alpha_{t|x} (m, d) &\text{marginalize out }d\\
    \psi^*_t(m) &= \frac{\alpha_{t|t}(m, d)}{\alpha_{t|t-1}(m, d)} =
    \frac{\psi_t(m)}{p(y_t|y_{1:t-1})} \\
    r_t^{-1} &= p(y_t|y_{1:t-1}) = \sum_{m,d} \alpha_{t|t-1}(m, d)\psi_t(m)
    = \sum_m \gamma_{t|t-1}(m) \psi_t(m)\\
    Z &= p(y_{1:T}) = \left(\prod_{t=1}^T r_t\right)^{-1} &\text{probability of data} \\
    \mathcal{D}_{t|x}(m, d) &= p(z_t=m, d_t=d, d_{t-1}=1|y_{1:x}) &\rightarrow (m, d) \\
    \mathcal{T}_{t|x}(n, m) &= p(z_t=n, z_{t-1}=m, d_{t-1}=1|y_{1:x}) &m \rightarrow n \\
    \mathcal{E}_t(m) &= p(z_t=m, d_t=1|y_{1:t}) = \alpha_{t|t-1}(m, 1) \psi^*_t(m) &m \text{ ends at } t \\
    \mathcal{S}_t(m) &= p(d_t=1, z_{t+1}=m|y_{1:t}) = \sum_n A(m, n)\mathcal{E}_t(n) &m \text{ starts at } t+1
\end{align*}
and for the backward pieces
\begin{align*}
    \beta_t(m, d) &= \frac{p(z_t=m, d_t=d|y_{1:T})}{p(z_t=m, d_t=d|y_{1:t-1})}
    = \frac{p(y_{t:T}|z_t=m, d_t=d)}{p(y_{t:T}|y_{1:t-1})} \\
    \mathcal{E}^*_t(m) &= \frac{p(y_{t:T}|z_t=m, d_{t-1} = 1)}{p(y_{t:T}|y_{1:t-1})} = \sum_d p_m(d) \beta_t(m, d) \\
    \mathcal{S}^*_t(m) &= \frac{p(y_{t:T}|z_{t-1}=m, d_{t-1}=1)}{p(y_{t:T}|y_{1:t-1})} = \sum_n \mathcal{E}^*_t(n) A(n, m)
\end{align*}
These quantities then allow us to write the posterior probabilities
\begin{align*}
    \alpha_{t|T}(m, d) &= \beta_t(m, d) \alpha_{t|t-1}(m, d) &\text{posterior prob of }(m, d) \\
    \mathcal{T}_{t|T}(n, m) &= \mathcal{E}^*_t(n) A(n, m) \mathcal{E}_{t - 1}(m) &\text{posterior prob of } m \rightarrow n \\
    \mathcal{D}_{t|T}(m, d) &= \beta_t(m, d)p_m(d) \mathcal{S}_{t-1}(m) &\text{posterior prob of entering }(m, d) \text{ at } t
\end{align*}

\subsubsection{Forward}
From Yu and Kobayashi, we have the following forward pass:
\begin{enumerate}
    \item $\alpha_{1|0}(m, d) = \pi_m p_m(d)$ for time 1; otherwise, use
    \begin{equation}
        \alpha_{t|t-1}(m, d) = S_{t-1}(m) p_m(d) + \psi^*_{t-1}(m) \alpha_{t-1|t-2}(m, d + 1)
    \end{equation}
    \item Use $\alpha_{t|t-1}$ and $\psi_t$ to get $r_t$; together, these give
    $\psi_t^*$. Store $r_t$
    \item Calculate and save $\mathcal{E}_t$.
    \item Calculate $\mathcal{S}_t$.
    \item Loop.
\end{enumerate}

\subsubsection{Backward}
Again following Yu and Kobayashi:
\begin{enumerate}
    \item Initialize $\beta_T(m, d) = \psi^*_T(m) = \psi_T(m) r_T$
    \item $\psi^*_t(m) = \psi_t(m) r_t$
    \item Calculate $\beta_t(m, d)$ by
    \begin{equation}
        \beta_t(m, d) =
        \begin{cases}
            \mathcal{S}^*_{t+1}(m)\psi^*_t(m), & d=1 \\
            \beta_{t+1}(m, d - 1) \psi^*_t(m), & d > 1
        \end{cases}
    \end{equation}
    where, again,
    \begin{align}
        \mathcal{S}^*_{t + 1}(m) &= \sum_{n} \mathcal{E}^*_{t+1}(n) A(n, m) \\
        \mathcal{E}^*_{t + 1}(n) &= \sum_d \beta_{t+1}(n, d) p_n(d)
    \end{align}
    \item Use the above equation to calculate $\mathcal{E}^*_t$ and $\mathcal{S}^*_t$. Save $\mathcal{E}^*$.
\end{enumerate}

\subsubsection{Sufficient Statistics}
Finally, we can calculate and return:
\begin{align}
    \log Z &= - \sum_{t=1}^T \log r_t \\
    \xi_t(m) &= \sum_d \alpha_{t|T}(m,d) = \gamma_{t|T}(m) = \sum_d \alpha_{t|t-1}(m, d) \beta_t(m, d) \\
    \Xi_{t+1, t}(n, m) &= \mathcal{T}_{t+1|T}(n, m) = \mathcal{E}^*_{t+1}(n) A(n, m) \mathcal{E}_t(m) \\
    C_t(m, d) &= \mathcal{D}_{t|T}(m, d) =
    \begin{cases}
        \pi_m p_m(d) \beta_1(m, d) & t = 1 \\
        \mathcal{S}_{t-1}(m)p_m(d) \beta_t(m, d) & t > 1 \\
    \end{cases}
\end{align}
Note that, because $\Xi_{t+1, t}$ is the \emph{joint} absolute probability of the transition (i.e., not conditioned on $d_t = 1$) it is \emph{not} normalized when summing over $m$ and $n$. The same is true for $C$ when summing over $m$ and $d$.

\subsection{Contributions to the evidence lower bound}
\subsubsection{$\mathbb{E}_q[\log p]$}
We would like to calculate $\mathbb{E}_{q}\left[ \log \frac{p(N, z|\lambda, A, \pi)}{q(z)}\right]$ for the semi-Markov model above. We begin by noting that the first term inside the expectation can be rewritten $p(N, z) = p(N|z)p(z)$. The first term remains the same as in the sections above, while the probability of the state sequence, $p(z)$, is significantly more complicated than in the Markov case. This is because the $z$ chain (obviously) no longer has the Markov property, and so its log cannot be written as a simple sum over time steps.

However, if we use the expanded state space $Z \otimes D$ with deterministic countdown nodes $D$, we can write the transitions as\footnote{Of course, adding the $D$ nodes adds no new information, provided we know all the $Z$s.}
\begin{align}
    p(z'|z, d) &=
        \begin{cases}
            A_{z'z}, & d=1 \\
            \delta_{z'z}, & d > 1
        \end{cases} \\
    p(d'|z', d) &=
        \begin{cases}
            p(d'|z'), & d=1 \\
            \delta_{d', d - 1}, & d > 1
        \end{cases}
\end{align}
This allows us to write the entire system as Markov, with the transition matrix
\begin{equation}
    p(z', d'|z, d) = p(d'|z', d) p(z'|z, d) =
    \delta_{d1} A_{z'z}p(d'|z') + (1 - \delta_{d1}) \delta_{z'z} \delta_{d', d-1}
\end{equation}
leading to
\begin{equation}
    \mathbb{E}_q[\log p(z)] = \mathbb{E}_q\left[
    \sum_{t = 1}^{T - 1} \log p(z_{t + 1}, d_{t + 1}|z_t, d_t) +
    \log p(z_1, d_1)
    \right]
\end{equation}
with the boundary condition $d_T = 0$ Thus,
\begin{equation}
    \log p(z_{t + 1}, d_{t + 1}|z_t, d_t) =
    \begin{cases}
        -\infty, & d > 0, (z'\neq z \vee d' \neq d - 1) \\
        0, & d > 0, z' = z, d' = d - 1 \\
        \log A_{z'z} + \log p(d'|z'), & d = 1
    \end{cases}
\end{equation}
Clearly, the first condition is our constraint, and the terms in the second condition do not contribute to the sum. For the third term, we must weight by the probability of observing the given transition $(z, d) \rightarrow (z', d')$ and then take the expectation. However, the first piece of this term is independent of $d$, while the second is independent of $z$, allowing us to marginalize and yielding:
\begin{align}
    \mathbb{E}_q[\log p(z)] &= \sum_{t = 1}^{T - 1}
    \mathrm{tr}(\Xi_{t+1, t}^T \cdot \log A) + \xi_1 \cdot \log \pi + \sum_d C(d) \cdot \mathbb{E}_q[\log p(d)]
\end{align}
where $C_{id}$ is defined above.\footnote{In taking the expectation of the $\log A$ terms, we have marginalized out $d$ to leave us with the two-slice marginals. In the second term, we have marginalized out $z$ to leave us with the sufficient statistics for observations, i.e., the number of times we enter each state $z'$ and draw duration $d$.} Thus we confirm that $C_{id}$ are indeed the correct sufficient statistics to calculate in performing maximum likelihood inference for $p(d|z)$. Moreover, the first and second terms are the same as in the HMM case, while the third is a new addition to be used in updating our estimate of the duration distribution in each state (see below).

\subsubsection{$\mathbb{E}_q[-\log q]$}
Finally, we can ask about the entropy term in the observation piece, $\mathbb{E}_q[-\log q(z)]$. From free-form variational arguments, $q(z)$ should take the same form as $\mathbb{E}_q[\log p(N, z|\eta, \lambda, A, \pi)]$. However, the joint posterior over $(z, d)$ also contains a term of the same form as $C \mathbb{E}[\log p]$, where the expectations are replaced by variational parameters, but, the expression in (\ref{KLobs}) is unchanged, save for the addition of a term
\begin{equation}
    \sum_{k, i, d} C(k, d, i) [\mathbb{E}_q\left[ \log p(d|i, k) \right]
    - \nu_{dik} ]
\end{equation}
with $k$ labeling hidden states, $i$ labeling levels of those states, and $\nu$ a set of functions of variational parameters. Just as with $\tilde{A}$ and $\tilde{\pi}$ above, variation with respect to $\nu$ trivially yields
\begin{equation}
     \nu_{dik} = \mathbb{E}_q[\log p(d|i, k)]
 \end{equation}

\subsubsection{Updates for $p(d)$}
Now assume the delay distribution is a member of the exponential family with base measure $h$ and natural parameter $\eta$:
\begin{equation}
    p(d|z=i) = h(d) \exp(\eta_i \cdot T(d) - A(\eta_i))
\end{equation}
Thus
\begin{equation}
    \mathbb{E}_q[\log p(d|i)] = \log h(d) + \mathbb{E}_q[\eta_i] \cdot T(d) -
    \mathbb{E}_q[A(\eta_i)]
\end{equation}
where we have assumed a factorized component of the posterior $q(\eta_i)$.\footnote{Note that if we treat the $\eta_i$ as parameters instead of random variables and differentiate with respect to $\eta_i$ to get the maximum likelihood value, we arrive at the result $\mathbb{E}_{\eta_i}[T(d)] = \mathbb{E}_{\hat{p}_i}[T(d)]$, where $\hat{p}_i \equiv C(d, i) / \sum_d C(d, i)$, the result reported by Mitchell and Jamieson.}

As a result of all this, we can finally write the observation term in the evidence lower bound as
\begin{equation}
    \mathbb{E}_q[\log p(N, z|\lambda, A, \pi)] =
    \mathbb{E}_q[\log p(N|z) + \log p(z|\eta, \lambda, A, \pi) + \log p(\eta)]
\end{equation}
Of these, the first term is unchanged from the HMM case, the third is simply the prior on the parameters of the duration distribution, and the second is
\begin{multline}
    \mathbb{E}_q [\log p(z|\eta, \lambda, A, \pi)] =
    \mathrm{tr}(\Xi^T_{t+1, t} \cdot \log A) + \xi_1 \cdot \log \pi + \\
    \sum_{i, d} C(d, i) [ \log h(d) + \mathbb{E}_q[\eta_i] \cdot T(d) -
    \mathbb{E}_q[A(\eta_i)] ]
\end{multline}
Here, the first two terms are identical to the HMM case, while the last will contribute to the posterior over $\eta_i$, the duration distribution parameters in each state.

\subsubsection{Corrections for truncation}
The above treatment assumes that $p(d|z)$ can be described by any member of the exponential family, but in fact, the durations $d$ are discrete and have a maximum value, $D$. Thus, if $p(d|z)$ is \emph{any} distribution with specified form, the term above becomes
\begin{align}
    \sum_{i, d} C(d, i) \log \hat{p}(d|i) &= \sum_{i, d} C(d, i) \left[
    \log p(d|i) - \log \left(\sum_{d=1}^D p(d|i) \right)
    \right]
\end{align}
When attempting to calculate the expectation of this term with respect to the variational posterior, we can make use of the fact that $-\log x$ is convex to again lower bound the variational objective:
\begin{equation}
    \mathbb{E}_q\left[-\log \left(\sum_{d=1}^D p(d|i) \right)\right] \ge
    -\log \sum_{d=1}^D \mathbb{E}_q\left[ p(d|i) \right]
\end{equation}

\subsubsection{Log-Normal durations}
Consider the case of lognormally distributed durations: $\log d \sim \mathcal{N}(m, s^2)$. In this case, we have
\begin{align}
    h(d) &= \frac{1}{\sqrt{2\pi} d} \\
    T(d) &= \begin{bmatrix}
    \log d \\
    (\log d) ^2
    \end{bmatrix} \\
    \eta &= \begin{bmatrix}
    \frac{m}{s^2} \\
    -\frac{1}{2s^2}
    \end{bmatrix} \\
    A(\eta) &= \frac{m^2}{2s^2} + \log s
\end{align}
If we then define $\tau = s^{-2}$ and put a Normal-Gamma posterior on $(m, \tau)$ with parameters $(\mu, \lambda, \alpha, \beta)$, we can easily calculate
\begin{align}
    \mathbb{E}_q[\eta] &= \mathbb{E}_q
    \begin{bmatrix}
    m\tau \\
    -\frac{1}{2}\tau
    \end{bmatrix} =
    \begin{bmatrix}
    \mu\frac{\alpha}{\beta} \\
    -\frac{\alpha}{2\beta}
    \end{bmatrix} \\
    \mathbb{E}_q[A(\eta)] &= \mathbb{E}_q\left[
    \frac{1}{2}m^2\tau - \frac{1}{2} \log \tau
    \right] \\
    &= \frac{1}{2} \mathbb{E}_\tau\left[
    \left(\mu^2 + \frac{1}{\lambda \tau}\right)\tau
    \right]
    -\frac{1}{2} (\psi(\alpha) - \log \beta) \\
    &= \frac{1}{2} \left(\mu^2 \frac{\alpha}{\beta} + \frac{1}{\lambda} \right)
    -\frac{1}{2} (\psi(\alpha) - \log \beta)
\end{align}
The relevant piece of the evidence lower bound for updating $(\mu, \lambda, \alpha, \beta)$ is
\begin{multline}
    \sum_{i, d} C(d, i) [ \log h(d) + \mathbb{E}_q[\eta_i] \cdot T(d) -
    \mathbb{E}_q[A(\eta_i)] + \mathbb{E}_q\left[\log \frac{p(m, \tau)}{q(m, \tau)} \right]
\end{multline}
again, with $q(m, \tau) = \text{Normal-Gamma}(\mu, \lambda, \alpha, \beta)$. We can thus write
\begin{align}
    \mathbb{E}_q[\log p(d|z)] &= -\frac{1}{2}\log 2\pi C_0 - C_1 +
    \mathbb{E}_q[m\tau] C_1 -\frac{1}{2}\mathbb{E}_q[\tau] C_2  \\
    &- \frac{1}{2} C_0 \mathbb{E}_q[m^2\tau] + \frac{1}{2} C_0 \mathbb{E}_q[\log \tau] + \mathbb{E}_q\left[\log \frac{p(m, \tau)}{q(m, \tau)} \right] \\
    &= G + F \cdot T(m, \tau) + \mathbb{E}_q\left[\log \frac{p(m, \tau)}{q(m, \tau)} \right]
\end{align}
where
\begin{align}
    G &\equiv -\frac{1}{2}\log 2\pi C_0 - C_1 \\
    F \cdot T &=
    \begin{bmatrix}
        \frac{C_0}{2} &
        -\frac{C_2}{2} &
        C_1 &
        -\frac{C_0}{2}
    \end{bmatrix} \cdot \mathbb{E}_q
    \begin{bmatrix}
        \log \tau \\
        \tau \\
        m\tau \\
        m^2 \tau
    \end{bmatrix} \\
    C_0 &\equiv \sum_{id} C_{id} \\
    C_1 &\equiv \sum_{id} C_{id} \log d \\
    C_2 &\equiv \sum_{id} C_{id} (\log d)^2
\end{align}

\subsubsection{Log-Normal updates}
For the case above (lognormal durations, Normal-Gamma priors on the lognormal parameters), a convenient simplification occurs. We can see this by noting that the terms involving $C$ above include the posterior variational parameters only through linear combinations of $\mathbb{E}_q[\eta]$ and $\mathbb{E}_q[A(\eta)]$. But because the normal-gamma is conjugate to the lognormal, these quantites are themselves the expected natural parameters of the normal-gamma distribution: $(\log \tau, \tau, m\tau, m^2\tau)$. As a result, we can do Bayesian inference for the natural parameters of the normal-gamma in closed form:
\begin{equation}
    \begin{bmatrix}
    \alpha - \frac{1}{2} \\
    -\beta - \frac{\lambda\mu^2}{2} \\
    \lambda\mu \\
    -\frac{\lambda}{2}
    \end{bmatrix}
    \leftarrow
    \begin{bmatrix}
    \frac{1}{2}\sum_d C(d) + \alpha_0 - \frac{1}{2} \\
    -\frac{1}{2} \sum_d C(d) (\log d)^2 -\beta_0 - \frac{\lambda_0\mu_0^2}{2} \\
    \sum_d C(d) \log d + \lambda_0\mu_0 \\
    -\frac{1}{2}\sum_d C(d) - \frac{\lambda_0}{2}
    \end{bmatrix}
\end{equation}
We can also make use of the conversion from natural to conventional parameters:
\begin{equation}
    \begin{bmatrix}
        \alpha \\
        \beta \\
        \mu \\
        \lambda
    \end{bmatrix} =
    \begin{bmatrix}
        \eta_1 + \frac{1}{2} \\
        -\eta_2 + \frac{\eta_3^2}{4\eta_4} \\
        -\frac{\eta_3}{2\eta_4} \\
        -2\eta_4
    \end{bmatrix}
\end{equation}
and the entropy:
\begin{align}
    H[q] &= \mathbb{E}_q[-\log q] = \mathbb{E}_q[-\log q(\tau) - \log q(m|\tau)] \\
    &= H_g(\alpha, \beta) + \mathbb{E}_q\left[
    -\log \sqrt{\frac{\lambda\tau}{2\pi}} +
    \frac{\lambda\tau}{2} (m - \mu)^2
    \right] \\
    &= \alpha - \log \beta + \log \Gamma(\alpha) + (1 - \alpha) \psi(\alpha) \\
    & - \frac{1}{2} \log \frac{\lambda}{2\pi} - \frac{1}{2} \left(\psi(\alpha) - \log \beta\right)
    + \frac{1}{2}
\end{align}
We can also use this to calculate the normalization correction:
\begin{equation}
    \mathbb{E}_q[p(d|i, m, \tau)] = \int d\tau dm \; p(d|i, m, \tau) q(m, \tau)
    = \frac{1}{\sqrt{2\pi}d} \sqrt{\frac{\lambda}{1 + \lambda}}
    \frac{\Gamma(\alpha + 1/2)}{\Gamma(\alpha)}
    \frac{\beta^{-\frac{1}{2}}}{\hat{\beta}^{\alpha + \frac{1}{2}}}
\end{equation}
with
\begin{equation}
    \hat{\beta} = 1 + \frac{1}{2\beta} \frac{\lambda}{1 + \lambda}
    (\log d - \mu)^2
\end{equation}
This can be derived either by performing the integral (using a log-normal for $p(d)$ and a normal-gamma for $(m, \tau)$) or by noting that the result should be proportional to the posterior (normal-gamma, by conjugacy) of $(m, \tau)$ after having observed a single data point, $\log d$.

\end{document}
