{
 "metadata": {
  "name": "",
  "signature": "sha256:53c7d66499f5a81b61d4e5cf5878424e3004d5edc350fc01ceeffe38dd3d7fb5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model 3: The Gamma-Poisson Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we derive the variational updates for the Gamma-Poisson model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Model:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start with the GLM for a Poisson process. Assume $T$ observation times, $N$ observation units, and $K$ latent categories (potentially including a constant baseline for each unit):\n",
      "$$\n",
      "p(N_{tu}) = \\frac{\\mu_{tu}^{N_{tu}}}{N_{tu}!} e^{-\\mu_{tu}}\n",
      "$$\n",
      "With the canonical link $\\mu_{tu} = \\sum_k z_{tk}b_{ku}$, where $z$ is the time series of latent states for each category and $b$ are regression coefficients."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition, we assume the $z_{t}$ have their own Markov dynamics within each category (see below)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, if we write $b_{ku} = \\log \\lambda_{ku}$, we can rewrite the above expression:\n",
      "$$\n",
      "p(N_{tu}) = \\frac{\\prod_k \\lambda_{ku}^{N_{tu}z_{tk}}}{N_{tu}!} e^{-\\prod_k \\lambda_{ku}^{z_{tk}}}\n",
      "$$\n",
      "which has the nearly exponential form\n",
      "$$\n",
      "\\log p(N_{tu}) = N_{tu} \\sum_k z_{tk} \\log \\lambda_{ku} - \\prod_k \\lambda_{ku}^{z_{tk}} - \\log N_{tu}!\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now if we consider the marginals for the $\\lambda_{ku}$ given $z_{tk}$, we can easily convince ourselves that they take the form of gamma distributions with shape parameter $N + 1$ and rate parameter an expectation over products of the lambdas.\n",
      "\n",
      "Thus, we would like to approximate the distribution $p(N_{tu})$ as a product over of distributions over **independent** categories:\n",
      "$$\n",
      "p(N_{tu}) = \\prod_k q(\\lambda_{ku}|z_{tk})q(z_{tk})\n",
      "$$\n",
      "where again, $p(z_{tk})$ contains Markov dynamics.\n",
      "\n",
      "In particular, we assume \n",
      "$$\n",
      "\\lambda_{ku} \\sim \\text{Ga}(\\alpha_{ku}, \\beta_{ku})\n",
      "$$\n",
      "and contributes to the log likelihood at time $t$ only if $z_{tk} = 1$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With this assumption, we can write\n",
      "$$\n",
      "\\log q(N_{tu}) = \\sum_k z_{tk} \\left[\n",
      "\\alpha_{ku} \\log \\beta_{ku} + (\\alpha_{ku} - 1)\\log \\lambda_{ku} - \\beta_{ku}\\lambda_{ku} - \\log \\Gamma(\\alpha_{ku})\n",
      "\\right]\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variational Updates"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to choose the $\\alpha$ and $\\beta$ above to minimize the divergence between $p$ and $q$. To do so, we will maximize the lower bound $\\mathcal{L} \\equiv \\mathbb{E}_q[\\log \\frac{p}{q}] = \\mathbb{E}_q[\\log p] + H[q]$ with respect to these parameters. In what follows, we will suppress the indices $u$ and $t$ for clarity, since they do not enter meaningfully."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To calculate $\\mathcal{L}$, we will make use of the following properties of Gamma distributions:\n",
      "$$\n",
      "\\mathbb{E}[\\lambda] = \\frac{\\alpha}{\\beta} \\\\\n",
      "\\mathbb{E}[\\log \\lambda] = \\psi(\\alpha) - \\log \\beta \\\\\n",
      "H = -\\mathbb{E}[\\log p] = \\alpha - \\log \\beta + \\log \\Gamma(\\alpha) + (1 - \\alpha) \\psi(\\alpha)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus\n",
      "$$\n",
      "\\mathbb{E}_{q}[\\log p(N)] = N \\sum_k \\bar{z}_k (\\psi(\\alpha_k) - \\log \\beta_k) -\n",
      "\\prod_k \\left(1 - \\bar{z}_k + \\bar{z}_k \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "- \\log N!\n",
      "$$\n",
      "where we designate $\\mathbb{E}_q[z_k]$ by $\\bar{z}_k$ and use the conditional independence of $\\lambda_k$ on $z_k$ and the independence of $z$s and $\\lambda$s for different $k$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With all this, we can now write\n",
      "$$\n",
      "\\mathcal{L} =\n",
      "N \\sum_k \\bar{z}_k (\\psi(\\alpha_k) - \\log \\beta_k) -\n",
      "\\prod_k \\left(1 - \\bar{z}_k + \\bar{z} \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "- \\log N! +\n",
      "\\alpha_k - \\log \\beta_k + \\log \\Gamma(\\alpha_k) + (1 - \\alpha_k) \\psi(\\alpha_k)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can maximize by taking\n",
      "$$\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\alpha_k} =\n",
      "N\\bar{z}_k \\psi'(\\alpha_k) - \n",
      "\\frac{\\bar{z}_k}{\\beta_k} F_k + \n",
      "\\bar{z}_k + \n",
      "\\bar{z}_k (1 - \\alpha_k)\\psi'(\\alpha_k) = 0 \n",
      "\\\\\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\beta_k} =\n",
      "-N \\frac{\\bar{z}_k}{\\beta_k} + \n",
      "\\frac{\\bar{z}_k}{\\beta_k}\\frac{\\alpha_k}{\\beta_k}F_k -\n",
      "\\frac{\\bar{z}_k}{\\beta_k} = 0\n",
      "$$\n",
      "with \n",
      "$$\n",
      "F_k \\equiv \\prod_{j \\neq k} \\left(1 - \\bar{z}_k + \\bar{z}_k \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is not too difficult to show that both these equations can be satisfied if we choose\n",
      "$$\n",
      "\\alpha_k = N + 1 \\\\\n",
      "\\beta_k = F_k\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This suggests a simple iterative update procedure whereby, given $\\bar{z}$, we take turns calculating $F_k$ for the current values of $\\beta$ and updating $\\beta_k$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Priors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Naturally, we can put $\\text{Ga}(c_k, d_k)$ priors on the $\\lambda_k$, in which case we have \n",
      "$$\n",
      "\\alpha_k = N + 1 + c_k \\\\\n",
      "\\beta = F_k + d_k\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "HMM Inference"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Rationale"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To perform variational inference above, we need to know $\\bar{z}$. We will determine this by doing inference on the Hidden Markov Model describing the $z_t$s for each category via the forwards-backwards algorithm."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Chain parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is natural for our timeseries $z_t$ for each category to assume a Markov structure. That is, we assume a transition matrix $A_{ij} = p(z_{t+1} = i|z_t = j)$ with columns summing to one. (This is opposite the common convention, and means that, in matrix notation, $z_{t+1} = A\\cdot z_t$.\n",
      "\n",
      "We also assume an initial distribution of probability over states $(\\pi_0)_i = p(z_0 = i)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It will also be natural to put priors on the parameters of this chain. In our case, the number of states is $M = 2$. And we choose priors as follows\n",
      "$$\n",
      "A_{1i} \\sim \\text{Be}(\\nu^{(1)}_i, \\nu^{(2)}_i) \\\\\n",
      "(\\pi_0)_1 \\sim \\text{Be}(\\rho^{(1)}, \\rho^{(2)})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Observation Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To implement the forwards-backwards algorithm, we need to know $q(N_t|z_t)$. Given the independence of each chain, integrating out other $z$s and $\\lambda$s is trivial. However, we can also integrate out $\\lambda$ for our chain of interest by noting\n",
      "$$\n",
      "p(N|z) = \\int \\! d\\lambda \\, q(N|\\lambda)q(\\lambda|z) = \\mathbb{E}_{q(\\lambda|z)}[q(N|\\lambda)] \\approx \\frac{\\beta^N e^{Nz\\overline{\\log \\lambda}}}{N!} e^{-\\beta\\bar{\\lambda}^z}\n",
      "$$\n",
      "which is a Poisson distribution when $\\bar{\\lambda} \\approx \\overline{\\log \\lambda}$ (true when $\\alpha \\gg 1$). We also note that, just as desired, $\\beta$ serves as a \"base rate\" that incorporates the mean-field effect of all other chains.\n",
      "\n",
      "Thus our relevant comparison in $p(N_t|z_t)$ is between a \"background\" process from all other chains with rate $\\beta$ and an \"active\" process in which $z$ is turned on with rate $\\beta\\bar{\\lambda}$.\n",
      "\n",
      "With these parameters, it is then straighforward to run forwards-backwards to calculate both the posterior $\\mathbb{E}_q[z_{tk}]$ and the two-slice marginals $(\\Xi_{t+1, t})_{ij} \\equiv p(z_{t+1} = i|z_t = j)$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Updating the Markov chain parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the parameters of the Markov chain come from simple exponential families, their updates can be written straightforwardly:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "$A$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The transition probabilities for the chain are updated according to the two-slice marginal (roughly, the proportion of transitions between states).\n",
      "\n",
      "$$\n",
      "A_{1i} \\sim \\text{Be}\\left(\n",
      "\\nu^{(1)}_i + \\sum_t (\\Xi_{t+1, t})_{1i} , \\; \n",
      "\\nu^{(2)}_i + \\sum_t (\\Xi_{t+1, t})_{0i}\n",
      "\\right)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly,\n",
      "$$\n",
      "(\\pi_0)_1 \\sim \\text{Be}\n",
      "\\left(\\rho^{(1)} + \\mathbb{E}_q[z_0], \\;\n",
      "\\rho^{(2)}_i + 1 - \\mathbb{E}_q[z_0]\n",
      "\\right)\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}