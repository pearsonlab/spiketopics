{
 "metadata": {
  "name": "",
  "signature": "sha256:3b755e329e438237b39acf2708e82f4dfdae30220d7015a97f1786e807648f83"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model 3: The Gamma-Poisson Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we derive the variational updates for the Gamma-Poisson model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Model:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start with the GLM for a Poisson process. Assume $T$ observation times, $N$ observation units, and $K$ latent categories (potentially including a constant baseline for each unit):\n",
      "$$\n",
      "p(N_{tu}|\\mu) = \\frac{\\mu_{tu}^{N_{tu}}}{N_{tu}!} e^{-\\mu_{tu}}\n",
      "$$\n",
      "With the canonical link $\\mu_{tu} = \\sum_k z_{tk}b_{ku}$, where $z$ is the time series of latent states for each category and $b$ are regression coefficients."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition, we assume the $z_{t}$ have their own Markov dynamics within each category (see below)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, if we write $b_{ku} = \\log \\lambda_{ku}$, we can rewrite the above expression:\n",
      "$$\n",
      "p(N_{tu}|\\lambda, z) = \\frac{\\prod_k \\lambda_{ku}^{N_{tu}z_{tk}}}{N_{tu}!} e^{-\\prod_k \\lambda_{ku}^{z_{tk}}}\n",
      "$$\n",
      "which has the nearly exponential form\n",
      "$$\n",
      "\\log p(N_{tu}|\\lambda, z) = N_{tu} \\sum_k z_{tk} \\log \\lambda_{ku} - \\prod_k \\lambda_{ku}^{z_{tk}} - \\log N_{tu}!\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now if we consider the marginals for the $\\lambda_{ku}$ given $z_{tk}$, we can easily convince ourselves that they take the form of gamma distributions with shape parameter $N + 1$ and rate parameter an expectation over products of the lambdas."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus, we would like to approximate the distribution $p(N_{tu},\\lambda, z)$ as a product of distributions over **independent** categories:\n",
      "$$\n",
      "p(N_{tu}, \\lambda, z) \\propto p(\\lambda, z|N_{tu})p(\\lambda)p(z) = \\prod_{k} q(z_{tk}, N_{tu})q(\\lambda_{ku})q(z_{tk})\n",
      "$$\n",
      "where again, $p(z)$ and $q(z)$ contain Markov dynamics, $p(\\lambda)$ is a prior over $\\lambda$, and $q(z_{tk},N_{tu})$ is proportional to the observation model of the chain."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In particular, we assume \n",
      "$$\n",
      "q(\\lambda_{ku}) = \\text{Ga}(\\alpha_{ku}, \\beta_{ku}) \\\\\n",
      "q(z, N_{tu}) = \\prod_k \\text{Pois}(\\eta_{tku}\\mu_{ku}^{z_{tk}})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With this assumption, we can write\n",
      "$$\n",
      "\\log q_{tu} = \\sum_k  \\left[\n",
      "\\alpha_{ku} \\log \\beta_{ku} + (\\alpha_{ku} - 1)\\log \\lambda_{ku} - \\beta_{ku}\\lambda_{ku} - \\log \\Gamma(\\alpha_{ku})\n",
      "\\right] \\\\\n",
      "+ N_{tu} \\sum_k z_{tk}\\log \\mu_{ku} + \n",
      "N_{tu} \\sum_k \\log \\eta_{tku} -\n",
      "\\sum_k \\eta_{tku} \\mu_{ku}^{z_{tk}} \n",
      "\\\\\n",
      "+ \\text{Markov} + \\text{constant}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That is, each chain can be modeled as disconneted from all others, with the \"background rate\" $\\eta$ encapsulating the mean field effect of the other chains."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the constant here includes the normalization constant calculated by the Forward-Backward algorithm, which includes appropriate normalizers for the Poisson observation process and the transitions."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The aim of our variational inference will be to determine the appropriate values of $\\alpha$ and $\\beta$ to minimize the KL divergence between $p$ and $q$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variational Updates"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to choose the $\\alpha$ and $\\beta$ above to minimize the divergence between $p$ and $q$. To do so, we will maximize the lower bound $\\mathcal{L} \\equiv \\mathbb{E}_q[\\log \\frac{p}{q}] = \\mathbb{E}_q[\\log p] + H[q]$ with respect to these parameters. In what follows, we will suppress the indices $u$ and $t$ for clarity, since they do not enter meaningfully."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To calculate $\\mathcal{L}$, we will make use of the following properties of Gamma distributions:\n",
      "$$\n",
      "\\mathbb{E}[\\lambda] = \\frac{\\alpha}{\\beta} \\\\\n",
      "\\mathbb{E}[\\log \\lambda] = \\psi(\\alpha) - \\log \\beta \\\\\n",
      "H = -\\mathbb{E}[\\log p] = \\alpha - \\log \\beta + \\log \\Gamma(\\alpha) + (1 - \\alpha) \\psi(\\alpha)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus\n",
      "$$\n",
      "\\mathbb{E}_{q}[\\log p(N)] = \\sum_k N_k \\bar{z}_k (\\psi(\\alpha_k) - \\log \\beta_k) -\n",
      "\\prod_k \\left(1 - \\bar{z}_k + \\bar{z}_k \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "+ \\text{constant} \\\\\n",
      "$$\n",
      "where we use the conditional independence of $\\lambda_k$ on $z_k$ and the independence of $z$s and $\\lambda$s for different $k$ and write $\\mathbb{E}_q[z_k] = \\bar{z}_k$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With all this, we can now write\n",
      "$$\n",
      "\\mathcal{L} =\n",
      "N \\sum_k \\bar{z}_k (\\psi(\\alpha_k) - \\log \\beta_k) -\n",
      "\\prod_k \\left(1 - \\bar{z}_k + \\bar{z}_k \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "+ \\sum_k \\left[\n",
      "\\alpha_k - \\log \\beta_k + \\log \\Gamma(\\alpha_k) + (1 - \\alpha_k) \\psi(\\alpha_k)\n",
      "\\right]\n",
      "\\\\\n",
      "- N \\sum_k \\bar{z}_k \\log \\mu_{k} \n",
      "- N \\sum_k \\log \\eta_{k}\n",
      "+ \\sum_k \\eta_k( 1 - \\bar{z}_k + \\bar{z}_k\\mu_k)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can maximize by taking\n",
      "$$\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\alpha_k} =\n",
      "\\bar{N}\\bar{z}_k \\psi'(\\alpha_k) - \n",
      "\\frac{\\bar{z}_k}{\\beta_k} F_k + \n",
      "1 + \n",
      "(1 - \\alpha_k)\\psi'(\\alpha_k) = 0 \n",
      "\\\\\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\beta_k} =\n",
      "-\\bar{N} \\frac{\\bar{z}_k}{\\beta_k} + \n",
      "\\frac{\\bar{z}_k}{\\beta_k}\\frac{\\alpha_k}{\\beta_k}F_k -\n",
      "\\frac{1}{\\beta_k} = 0\n",
      "\\\\\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\mu_k} =\n",
      "N \\frac{\\partial \\bar{z}_k}{\\partial \\mu_k} \n",
      "(\\psi(\\alpha_k) - \\log \\beta_k - \\log \\mu_k) - \n",
      "\\frac{\\partial \\bar{z}_k}{\\partial \\mu_k} \n",
      "\\left(\\frac{\\alpha_k}{\\beta_k} - 1 \\right)F_k \\\\\n",
      "- N \\bar{z}_k \\frac{1}{\\mu_k} +\n",
      "\\bar{z}_k \\eta_k + \\eta_k (\\mu_k - 1) \\frac{\\partial \\bar{z}_k}{\\partial \\mu_k} = 0\\\\\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\eta_k} =\n",
      "-\\frac{N}{\\eta_k} + (1 - \\bar{z}_k + \\bar{z}_k \\mu_k) + \n",
      "\\frac{\\partial \\bar{z}_k}{\\partial \\eta_k}\\left(\\ldots \\right) = 0\n",
      "$$\n",
      "with \n",
      "$$\n",
      "F_k \\equiv \\prod_{j \\neq k} \\left(1 - \\bar{z}_k + \\bar{z}_k \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "$$\n",
      "and the omitted terms in the last equation similar to those in the one before."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is not too difficult to show that these equations can be satisfied if we choose\n",
      "$$\n",
      "\\alpha_{ku} = \\sum_t N_{tu}z_{tk} + 1 \\\\\n",
      "\\beta_{ku} = \\sum_t F_{tku} z_{tk}\\\\\n",
      "\\log \\mu_{ku} = \\psi(\\alpha_{ku}) - \\log \\beta_{ku} \\\\\n",
      "\\eta_{tku} = F_{tku} \\\\\n",
      "N_{tu} = \\eta_{tku} (1 - \\bar{z}_{tk} + \\bar{z}_{tk}\\mu_{ku})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is then easy to show that if the third equation holds and $\\alpha$ and $\\beta$ are large enough that $e^\\mu \\approx \\alpha/\\beta$, then the final equation gives\n",
      "$$\n",
      "N_{tu} = \\prod_{k} (1 - \\bar{z}_{tk} + \\bar{z}_{tk}\\mu_{ku}) = \\mathcal{F} \\equiv \\mathbb{E}_q\\left[\\prod_k\\mu_k^{z_k}\\right]\n",
      "$$\n",
      "which is to say that the mean rate of any given chain in the mean field should be the observed $N$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note also that when this holds, \n",
      "$$\n",
      "\\sum_k \\log \\eta_{k} = \\sum_k \\sum_{j \\neq k} \\left(1 - \\bar{z}_j + \\bar{z}_j \\mu_j\\right) =\n",
      "(K - 1)\\sum_k \\left(1 - \\bar{z}_k + \\bar{z}_k \\mu_k\\right) = (K - 1) \\log \\mathcal{F}\n",
      "$$\n",
      "and\n",
      "$$\n",
      "\\sum_k \\eta_k \\left(1 - \\bar{z}_k + \\bar{z}_k \\mu_k\\right) = \\sum_k \\mathcal{F} = K\\mathcal{F}\n",
      "$$\n",
      "Thus our effective Lagrangian, neglecting priors and terms that cancel in our updates (basically, only the coupling between chains in $p$ and its counterpart in $q$) can be written\n",
      "$$\n",
      "\\mathcal{L}_{eff} = -\\mathcal{F} - N(K - 1) \\log \\mathcal{F} + K\\mathcal{F} \\\\\n",
      "= (K - 1)\\left[\\mathcal{F} - N\\log\\mathcal{F} \\right]\n",
      "$$\n",
      "which has its extremum at $\\mathcal{F} = N$, as we found above.\n",
      "\n",
      "(Here, that extremum is a minimum, but this effect is offset by the change in $\\log Z_k$, the evidence likelihood from the Markov chain.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This suggests a simple iterative update procedure whereby, given $\\bar{z}$, we take turns calculating $F_k$ for the current values of $\\beta$ and updating $\\beta_k$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Priors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Naturally, we can put $\\text{Ga}(c_k, d_k)$ priors on the $\\lambda_k$. However, we do this so that the effective rate to observe $N_{tu}$ is \n",
      "$$\n",
      "p(N|z, \\lambda)p(\\lambda) = \\prod_{tu}\\left(\\frac{\\prod_k \\lambda_{ku}^{z_{tk}N_{tu}}}{N_{tu}!} \n",
      "e^{\\prod_k \\lambda_{ku}^{z_{tk}} }\\right)\n",
      "\\prod_{ku} \\left(\\frac{d_{ku}^{c_{ku}} \\lambda_{ku}^{c_{ku} - 1}}{\\Gamma(c_{ku})} \\right)\n",
      "e^{- \\sum_k  d_{ku}\\lambda_{ku}}\n",
      "$$\n",
      "That is, the prior contributes pseudocounts $c_{ku}$ and pseudorate $d_{ku}$. Given this convenient prior, the updates take the following simple form:\n",
      "$$\n",
      "\\alpha_{ku} = \\sum_t N_{tu}\\bar{z}_{tk} + c_{ku}\\\\\n",
      "\\beta_{ku} = \\sum_t F_{tku}\\bar{z}_{tk} + d_{ku}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In practice, we observe $N$, so we will not bother to set priors in this case, though we could choose an additional Poisson prior on $N$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "HMM Inference"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Rationale"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To perform variational inference above, we need to know $\\bar{z}$. We will determine this by doing inference on the Hidden Markov Model describing the $z_t$s for each category via the forwards-backwards algorithm."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Chain parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is natural for our timeseries $z_t$ for each category to assume a Markov structure. That is, we assume a transition matrix $A_{ij} = p(z_{t+1} = i|z_t = j)$ with columns summing to one. (This is opposite the common convention, and means that, in matrix notation, $z_{t+1} = A\\cdot z_t$.\n",
      "\n",
      "We also assume an initial distribution of probability over states $(\\pi_0)_i = p(z_0 = i)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It will also be natural to put priors on the parameters of this chain. In our case, the number of states is $M = 2$. And we choose priors as follows\n",
      "$$\n",
      "A_{1i} \\sim \\text{Be}(\\nu^{(1)}_i, \\nu^{(2)}_i) \\\\\n",
      "(\\pi_0)_1 \\sim \\text{Be}(\\rho^{(1)}, \\rho^{(2)})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus, in our $q$ ansatz, we will also assume that these parameters have Beta distributions:\n",
      "$$\n",
      "A_{1i} \\sim \\text{Be}(\\gamma^{(1)}_i, \\gamma^{(2)}_i) \\\\\n",
      "(\\pi_0)_1 \\sim \\text{Be}(\\delta^{(1)}, \\delta^{(2)})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Updating the Markov chain parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the parameters of the Markov chain come from simple exponential families, their updates can be written straightforwardly:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The transition probabilities for the chain are updated according to the two-slice marginals (roughly, the proportions of transitions between each pair of states):\n",
      "$$\n",
      "\\gamma_{ik}^{(1)} \\leftarrow \\nu_{ik}^{(1)} + \\sum_t (\\Xi^{(k)}_{t+1,t})_{1i}\\xi_{tki} \\\\\n",
      "\\gamma_{ik}^{(2)} \\leftarrow \\nu_{ik}^{(2)} + \\sum_t(\\Xi^{(k)}_{t+1,t})_{0i}\\xi_{tki}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where we assume that the forwards-backwards algorithm can be used to compute both the posterior $\\mathbb{E}_q[z_{tk}]$ and the two-slice marginals $(\\Xi_{t+1, t})_{ij} \\equiv q(z_{t+1} = i|z_t = j)$. \n",
      "\n",
      "That is, if we let $\\xi_{tk} \\equiv \\mathbb{E}_q[z_{tk}]$ then\n",
      "$$\n",
      "\\sum_t \\mathbb{E}_q[z_{i, t+1, k} \\log \\mathcal{A}^{(k)}_{ij} z_{j, t,k}] = \n",
      "\\sum_t (\\Xi_{t+1, t})_{ij} \\xi_{tj} \\log \\mathcal{A}^{(k)}_{ij}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where we have used \n",
      "$$\n",
      "\\mathbb{E}_q[z_{i, t + 1} z_{j, t}] = (\\Xi_{t+1, t})_{ij} \\xi_{tj}\n",
      "$$\n",
      "i.e.,  $q(z_{t+1} = i, z_t = j) = q(z_{t+1} = i|z_t = j) q(z_t = j)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly,\n",
      "$$\n",
      "\\delta^{(1)}_k \\leftarrow \\rho^{(1)}_k + \\mathbb{E}_q[z_{0k}] \\\\\n",
      "\\delta^{(2)}_k \\leftarrow \\rho^{(2)}_k + 1 - \\mathbb{E}_q[z_{0k}]\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Observation Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To implement the forwards-backwards algorithm, we need to know $q(N_t|z_t)$. Given the independence of each chain, integrating out all $\\lambda$s is trivial (we just neglect the $\\lambda$ pieces in $q$). In addition, we can integrate out $z_k$ for other chains by taking expectations over them:\n",
      "$$\n",
      "p(N|z_k) = \\frac{\\eta_k^N \\mu_k^{Nz_k}}{N!} e^{-\\eta_k\\mu_k^{z_k}}\n",
      "$$\n",
      "where\n",
      "$$\n",
      "\\eta_k = \\mathbb{E}_{-z_k}\\left[\n",
      "\\prod_{j \\neq k} \\mu_j^{z_j}\n",
      "\\right] =\n",
      "\\prod_{j \\neq k} (1 - \\bar{z}_j + \\bar{z}_j \\mu_j)\n",
      "$$\n",
      "and $\\log \\mu_k = \\overline{\\log \\lambda_k}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a Poisson distribution. We also note that, just as desired, $\\eta$ serves as a \"base rate\" that incorporates the mean-field effect of all other chains.\n",
      "\n",
      "Thus our relevant comparison in determining $z_t$ from $p(N_t|z_t)$ is between a \"background\" process from all other chains (rate $\\eta$) and an \"active\" process in which $z$ is turned on (rate $\\eta\\mu$)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Determining parameters for forwards-backwards"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have not yet determined which parameters for transition probabilites and initial state probabilities should be used in the forwards-backwards algorithm."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To do this, we note that the Markov portion of the distribution of $p$ is written\n",
      "$$\n",
      "\\log p(z) = \\sum_t z_{t+1,k}^T \\cdot \\log A^{(k)} \\cdot z_{t,k} +\n",
      "z_{0k}^T \\cdot \\log \\pi^{(k)}_{0}\n",
      "$$\n",
      "where log of the matrix $A^{(k)}$ is elementwise and we have designated by $z_{t, k}$ the vector with entries $p(z_{tk}=j)$ indexed by $j$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Following this, we can straightforwardly take\n",
      "$$\n",
      "\\log q(z) = \\sum_t z_{t+1,k}^T \\cdot \\log \\mathcal{A}^{(k)} \\cdot z_{t,k} +\n",
      "z_{0k}^T \\cdot \\phi^{(k)}_{0}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given similar derivations above, it is then easy to show that we should take\n",
      "$$\n",
      "\\log \\mathcal{A}^{(k)} = \\mathbb{E}_q[\\log A^{(k)}] \\\\\n",
      "\\phi_0^{(k)} = \\mathbb{E}_q[\\log \\pi_0^{(k)}]\n",
      "$$\n",
      "which, given our $q$ ansatz for these variables, gives\n",
      "$$\n",
      "\\log (\\mathcal{A}^{(k)})_{1i} = \\psi(\\gamma_{ik}^{(1)}) - \n",
      "\\psi(\\gamma_{ik}^{(1)} + \\gamma_{ik}^{(2)})\n",
      "\\\\\n",
      "\\log (\\phi_0^{(k)})_1 = \\psi(\\delta_{k}^{(1)}) - \n",
      "\\psi(\\delta_{k}^{(1)} + \\delta_{k}^{(2)})\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}