{
 "metadata": {
  "name": "",
  "signature": "sha256:d0b99f3c716cf5aed8d3b8fd118432adfab924222cd5d33a2f010939d444ff94"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model 3: The Gamma-Poisson Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we derive the variational updates for the Gamma-Poisson model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Model:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start with the GLM for a Poisson process. Assume $T$ observation times, $N$ observation units, and $K$ latent categories (potentially including a constant baseline for each unit):\n",
      "$$\n",
      "p(N_{tu}|\\mu) = \\frac{\\mu_{tu}^{N_{tu}}}{N_{tu}!} e^{-\\mu_{tu}}\n",
      "$$\n",
      "With the canonical link $\\mu_{tu} = \\sum_k z_{tk}b_{ku}$, where $z$ is the time series of latent states for each category and $b$ are regression coefficients."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition, we assume the $z_{t}$ have their own Markov dynamics within each category (see below)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, if we write $b_{ku} = \\log \\lambda_{ku}$, we can rewrite the above expression:\n",
      "$$\n",
      "p(N_{tu}|\\lambda, z) = \\frac{\\prod_k \\lambda_{ku}^{N_{tu}z_{tk}}}{N_{tu}!} e^{-\\prod_k \\lambda_{ku}^{z_{tk}}}\n",
      "$$\n",
      "which has the nearly exponential form\n",
      "$$\n",
      "\\log p(N_{tu}|\\lambda, z) = N_{tu} \\sum_k z_{tk} \\log \\lambda_{ku} - \\prod_k \\lambda_{ku}^{z_{tk}} - \\log N_{tu}!\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now if we consider the marginals for the $\\lambda_{ku}$ given $z_{tk}$, we can easily convince ourselves that they take the form of gamma distributions with shape parameter $N + 1$ and rate parameter an expectation over products of the lambdas."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus, we would like to approximate the distribution $p(N_{tu},\\lambda, z)$ as a product of distributions over **independent** categories:\n",
      "$$\n",
      "p(N_{tu}, \\lambda, z) = p(N_{tu}|\\lambda, z)p(\\lambda)p(z) = \\prod_{k} q(N_{tu}|z_{tk})q(\\lambda_{ku}|z_{tk})q(z_{tk})\n",
      "$$\n",
      "where again, $p(z)$ and $q(z)$ contain Markov dynamics and $p(\\lambda)$ is a prior over $\\lambda$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In particular, we assume \n",
      "$$\n",
      "q(\\lambda_{ku}|z) = \\text{Ga}(\\alpha_{ku}, \\beta_{ku}) \\\\\n",
      "q(N_{tu}|z) = \\text{Pois}(\\prod_k\\mu_{ku}^{z_{tk}})\n",
      "$$\n",
      "and $\\lambda_{ku}$ contributes to the log likelihood at time $t$ only if $z_{tk} = 1$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With this assumption, we can write\n",
      "$$\n",
      "\\log q_{tu} = \\sum_k z_{tk} \\left[\n",
      "\\alpha_{ku} \\log \\beta_{ku} + (\\alpha_{ku} - 1)\\log \\lambda_{ku} - \\beta_{ku}\\lambda_{ku} - \\log \\Gamma(\\alpha_{ku})\n",
      "\\right] \\\\\n",
      "+ N_{tu} \\sum_k z_{tk}\\log \\mu_{ku} - \n",
      "\\prod_k \\mu_{ku}^{z_{tk}} - \n",
      "\\log N_{tu}! \\\\\n",
      "+ \\sum_k \\log q(z_{tk})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The aim of our variational inference will be to determine the appropriate values of $\\alpha$ and $\\beta$ to minimize the KL divergence between $p$ and $q$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variational Updates"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to choose the $\\alpha$ and $\\beta$ above to minimize the divergence between $p$ and $q$. To do so, we will maximize the lower bound $\\mathcal{L} \\equiv \\mathbb{E}_q[\\log \\frac{p}{q}] = \\mathbb{E}_q[\\log p] + H[q]$ with respect to these parameters. In what follows, we will suppress the indices $u$ and $t$ for clarity, since they do not enter meaningfully."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To calculate $\\mathcal{L}$, we will make use of the following properties of Gamma distributions:\n",
      "$$\n",
      "\\mathbb{E}[\\lambda] = \\frac{\\alpha}{\\beta} \\\\\n",
      "\\mathbb{E}[\\log \\lambda] = \\psi(\\alpha) - \\log \\beta \\\\\n",
      "H = -\\mathbb{E}[\\log p] = \\alpha - \\log \\beta + \\log \\Gamma(\\alpha) + (1 - \\alpha) \\psi(\\alpha)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also use the fact that for our Poisson hypothesis with rate $\\prod_k \\mu_{k}^{z_{k}}$\n",
      "$$\n",
      "\\mathbb{E}[N] = \\prod_k (1 - \\bar{z}_k + \\bar{z}_k \\mu_k) \\\\\n",
      "\\mathbb{E}[Nz_k] = \\bar{z}_k\\mu_k \\prod_{j \\neq k} (1 - \\bar{z}_j + \\bar{z}_j \\mu_k)\n",
      "$$\n",
      "where we designate $\\mathbb{E}_q[z_k]$ by $\\bar{z}_k$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus\n",
      "$$\n",
      "\\mathbb{E}_{q}[\\log p(N)] = \\sum_k \\bar{N}_k \\bar{z}_k (\\psi(\\alpha_k) - \\log \\beta_k) -\n",
      "\\prod_k \\left(1 - \\bar{z}_k + \\bar{z}_k \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "- \\mathbb{E}_q[\\log N!] \\\\\n",
      "\\bar{N}_k \\bar{z}_k \\equiv \\mathbb{E}_q[Nz_k] = \n",
      "\\bar{z}_k \\mu_k \\prod_{j \\neq k} (1 - \\bar{z}_j + \\bar{z}_j \\mu_j)\n",
      "$$\n",
      "where we use the conditional independence of $\\lambda_k$ on $z_k$ and the independence of $z$s and $\\lambda$s for different $k$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With all this, we can now write\n",
      "$$\n",
      "\\mathcal{L} =\n",
      "\\sum_k \\bar{N}_k \\bar{z}_k (\\psi(\\alpha_k) - \\log \\beta_k) -\n",
      "\\prod_k \\left(1 - \\bar{z}_k + \\bar{z}_k \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "+ \\sum_k \\bar{z}_k \\left[\n",
      "\\alpha_k - \\log \\beta_k + \\log \\Gamma(\\alpha_k) + (1 - \\alpha_k) \\psi(\\alpha_k)\n",
      "\\right]\n",
      "\\\\\n",
      "- \\sum_k \\bar{N}_k \\bar{z}_k \\log \\mu_{k} + \\prod_k ( 1 - \\bar{z}_k + \\bar{z}_k\\mu_k)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can maximize by taking\n",
      "$$\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\alpha_k} =\n",
      "\\bar{N}\\bar{z}_k \\psi'(\\alpha_k) - \n",
      "\\frac{\\bar{z}_k}{\\beta_k} F_k + \n",
      "\\bar{z}_k + \n",
      "\\bar{z}_k (1 - \\alpha_k)\\psi'(\\alpha_k) = 0 \n",
      "\\\\\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\beta_k} =\n",
      "-\\bar{N} \\frac{\\bar{z}_k}{\\beta_k} + \n",
      "\\frac{\\bar{z}_k}{\\beta_k}\\frac{\\alpha_k}{\\beta_k}F_k -\n",
      "\\frac{\\bar{z}_k}{\\beta_k} = 0\n",
      "\\\\\n",
      "\\frac{\\partial \\mathcal{L}}{\\partial \\mu_k} =\n",
      "\\sum_j \\frac{\\partial \\bar{N}_j}{\\partial \\mu_k} \\bar{z}_j \n",
      "(\\psi(\\alpha_j) - \\log \\beta_j - \\log \\mu_j) + \n",
      "\\bar{N}_k \\bar{z}_k \\frac{1}{\\mu_k} -\n",
      "\\bar{z}_k \\prod_{j \\neq k} (1 - \\bar{z}_j + \\bar{z}_j \\mu_j) = 0\\\\\n",
      "= \\sum_j \\frac{\\partial \\bar{N}_j}{\\partial \\mu_k} \\bar{z}_j \n",
      "(\\psi(\\alpha_j) - \\log \\beta_j - \\log \\mu_j) = 0\n",
      "$$\n",
      "with \n",
      "$$\n",
      "F_k \\equiv \\prod_{j \\neq k} \\left(1 - \\bar{z}_k + \\bar{z}_k \\frac{\\alpha_k}{\\beta_k} \\right)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is not too difficult to show that these equations can be satisfied if we choose\n",
      "$$\n",
      "\\alpha_{ku} = \\frac{\\sum_t \\bar{N}_{tu}z_{tk}}{\\sum_t z_{tk}} + 1 \\\\\n",
      "\\beta_{ku} = \\frac{\\sum_t F_{tku} z_{tk}}{\\sum_t z_{tk}}\\\\\n",
      "\\log \\mu_{ku} = \\psi(\\alpha_{ku}) - \\log \\beta_{ku}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This suggests a simple iterative update procedure whereby, given $\\bar{z}$, we take turns calculating $F_k$ for the current values of $\\beta$ and updating $\\beta_k$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "N observed:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Naturally, in cases where $N$ is observed, we set $\\alpha_k = N + 1$. But we can then also dispense with the parameter $\\mu$ entirely by letting \n",
      "$$\n",
      "\\mu_{ku} = \\frac{e^{\\psi(\\alpha_{ku})}}{\\beta_{ku}}\n",
      "$$\n",
      "and using this to calculate the likelihood $p(N|z)$ in HMM inference."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Priors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Naturally, we can put $\\text{Ga}(c_k, d_k)$ priors on the $\\lambda_k$. However, we do this so that the effective rate to observe $N_{tu}$ is \n",
      "$$\n",
      "p(N_{tu}|z, \\lambda) = \\frac{\\prod_k \\lambda_{ku}^{z_{tk}(N_{tu} + c_{ku})}}{N_{tu}!} \n",
      "e^{\\prod_k \\lambda_{ku}^{z_{tk}} - \\sum_k z_{tk} d_{ku}\\lambda_{ku}}\n",
      "$$\n",
      "That is, the prior contributes pseudocounts $c_{ku}$ and pseudorate $d_{ku}$ **at each time**, but **only when the effect is present** (which, in effect, is simply setting the same Gamma prior on each $\\lambda_{tku}$). Given this convenient prior, the updates take the following simple form:\n",
      "$$\n",
      "\\alpha_{ku} = \\frac{\\sum_t \\bar{N}_{tu}z_{tk}}{\\sum_t z_{tk}} + 1 + c_{ku}\\\\\n",
      "\\beta_{ku} = \\frac{\\sum_t F_{tku} z_{tk}}{\\sum_t z_{tk}} + d_{ku}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In practice, we observe $N$, so we will not bother to set priors in this case, though we could choose an additional Poisson prior on $N$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "HMM Inference"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Rationale"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To perform variational inference above, we need to know $\\bar{z}$. We will determine this by doing inference on the Hidden Markov Model describing the $z_t$s for each category via the forwards-backwards algorithm."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Chain parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is natural for our timeseries $z_t$ for each category to assume a Markov structure. That is, we assume a transition matrix $A_{ij} = p(z_{t+1} = i|z_t = j)$ with columns summing to one. (This is opposite the common convention, and means that, in matrix notation, $z_{t+1} = A\\cdot z_t$.\n",
      "\n",
      "We also assume an initial distribution of probability over states $(\\pi_0)_i = p(z_0 = i)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It will also be natural to put priors on the parameters of this chain. In our case, the number of states is $M = 2$. And we choose priors as follows\n",
      "$$\n",
      "A_{1i} \\sim \\text{Be}(\\nu^{(1)}_i, \\nu^{(2)}_i) \\\\\n",
      "(\\pi_0)_1 \\sim \\text{Be}(\\rho^{(1)}, \\rho^{(2)})\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus, in our $q$ ansatz, we will also assume that these parameters have Beta distributions:\n",
      "$$\n",
      "A_{1i} \\sim \\text{Be}(\\gamma^{(1)}_i, \\gamma^{(2)}_i) \\\\\n",
      "(\\pi_0)_1 \\sim \\text{Be}(\\delta^{(1)}, \\delta^{(2)})\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Updating the Markov chain parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the parameters of the Markov chain come from simple exponential families, their updates can be written straightforwardly:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The transition probabilities for the chain are updated according to the two-slice marginals (roughly, the proportions of transitions between each pair of states):\n",
      "$$\n",
      "\\gamma_{ik}^{(1)} \\leftarrow \\nu_{ik}^{(1)} + \\sum_t (\\Xi^{(k)}_{t+1,t})_{1i} \\\\\n",
      "\\gamma_{ik}^{(2)} \\leftarrow \\nu_{ik}^{(2)} + \\sum_t (\\Xi^{(k)}_{t+1,t})_{0i} \n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly,\n",
      "$$\n",
      "\\delta^{(1)}_k \\leftarrow \\rho^{(1)}_k + \\mathbb{E}_q[z_{0k}] \\\\\n",
      "\\delta^{(2)}_k \\leftarrow \\rho^{(2)}_k + 1 - \\mathbb{E}_q[z_{0k}]\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Observation Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To implement the forwards-backwards algorithm, we need to know $q(N_t|z_t)$. Given the independence of each chain, integrating out all $\\lambda$s is trivial (we just neglect the $\\lambda$ pieces in $q$). In addition, we can integrate out $z_k$ for other chains by taking expectations over them:\n",
      "$$\n",
      "p(N|z_k) = \\frac{\\eta_k^N \\mu_k^{Nz_k}}{N!} e^{-\\eta_k\\mu_k^{z_k}}\n",
      "$$\n",
      "where\n",
      "$$\n",
      "\\eta_k = \\mathbb{E}_{-z_k}\\left[\n",
      "\\prod_{j \\neq k} \\mu_j^{z_j}\n",
      "\\right] =\n",
      "\\prod_{j \\neq k} (1 - \\bar{z}_j + \\bar{z}_j \\mu_j)\n",
      "$$\n",
      "and $\\log \\mu_k = \\overline{\\log \\lambda_k}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a Poisson distribution. We also note that, just as desired, $\\eta$ serves as a \"base rate\" that incorporates the mean-field effect of all other chains.\n",
      "\n",
      "Thus our relevant comparison in determining $z_t$ from $p(N_t|z_t)$ is between a \"background\" process from all other chains (rate $\\eta$) and an \"active\" process in which $z$ is turned on (rate $\\eta\\mu$)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Determining parameters for forwards-backwards"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have not yet determined which parameters for transition probabilites and initial state probabilities should be used in the forwards-backwards algorithm."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To do this, we note that the Markov portion of the distribution of $p$ is written\n",
      "$$\n",
      "\\log p(z) = \\sum_t z_{t+1,k}^T \\cdot \\log A^{(k)} \\cdot z_{t,k} +\n",
      "z_{0k}^T \\cdot \\pi^{(k)}_{0}\n",
      "$$\n",
      "where log of the matrix $A^{(k)}$ is elementwise and we have designated by $z_{t, k}$ the vector with entries $p(z_{tk}=j)$ indexed by $j$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Following this, we can straightforwardly take\n",
      "$$\n",
      "\\log q(z) = \\sum_t z_{t+1,k}^T \\cdot \\log \\mathcal{A}^{(k)} \\cdot z_{t,k} +\n",
      "z_{0k}^T \\cdot \\phi^{(k)}_{0}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given similar derivations above, it is then easy to show that we should take\n",
      "$$\n",
      "\\log \\mathcal{A}^{(k)} = \\mathbb{E}_q[\\log A^{(k)}] \\\\\n",
      "\\phi_0^{(k)} = \\mathbb{E}_q[\\pi_0^{(k)}]\n",
      "$$\n",
      "which, given our $q$ ansatz for these variables, gives\n",
      "$$\n",
      "\\log (\\mathcal{A}^{(k)})_{1i} = \\psi(\\gamma_{ik}^{(1)}) - \n",
      "\\psi(\\gamma_{ik}^{(1)} + \\gamma_{ik}^{(2)})\n",
      "\\\\\n",
      "(\\phi_0^{(k)})_1 = \\frac{\\delta_k^{(1)}}{\\delta_k^{(1)} + \\delta_k^{(2)}}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With these parameters, it is then straighforward to run forwards-backwards to calculate both the posterior $\\mathbb{E}_q[z_{tk}]$ and the two-slice marginals $(\\Xi_{t+1, t})_{ij} \\equiv p(z_{t+1} = i|z_t = j)$."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}