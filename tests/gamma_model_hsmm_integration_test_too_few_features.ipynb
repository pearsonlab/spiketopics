{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gamma model integration test (for semi-Markov models): too few features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we limit the model to fewer features than there really are?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want overdispersion in the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overdisp = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spiketopics.gamma_model as gp\n",
    "from spiketopics.helpers import *\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "np.random.seed(11738)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U = 100  # units\n",
    "T = int(1e4)  # time points/frames\n",
    "D = 100  # durations\n",
    "Kdata = 10  # number of latent states\n",
    "dt = 1/30  # seconds per frame\n",
    "Mz = 2  # number of states for each latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# want 0 more prevalent than 1\n",
    "mm_dur = np.empty((Mz, Kdata))\n",
    "mm_dur[0] = 40 * np.random.rand(Kdata) + 10\n",
    "mm_dur[1] = 15 * np.random.rand(Kdata) + 5\n",
    "\n",
    "ss_dur = np.empty((Mz, Kdata))\n",
    "ss_dur[0] = 1 * np.random.rand(Kdata) + 1\n",
    "ss_dur[1] = 2 * np.random.rand(Kdata) + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvec = np.arange(1, D + 1)\n",
    "for (m, s) in zip(mm_dur.ravel(), ss_dur.ravel()):\n",
    "    plt.plot(np.log(dvec), stats.norm.pdf(np.log(dvec), scale=s, loc=np.log(m)))\n",
    "plt.xlabel('log Duration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make transition matrix\n",
    "A = np.array([[0, 1.0], [1.0, 0]])\n",
    "pi = np.array([0.0, 1.])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chain = np.empty((T, Kdata))\n",
    "\n",
    "# initialize\n",
    "for k in xrange(Kdata):\n",
    "    t = 0\n",
    "    while t < T:\n",
    "        if t == 0:\n",
    "            pp = pi[1]\n",
    "        else:\n",
    "            pp = A[1, chain[t - 1, k]]\n",
    "\n",
    "        # pick a new state\n",
    "        z = stats.bernoulli.rvs(pp, size=1)\n",
    "\n",
    "        # pick a duration\n",
    "        while True:\n",
    "            d = stats.lognorm.rvs(scale=mm_dur[z, k], s=ss_dur[z, k], size=1)[0].astype('int')\n",
    "            if (d >= 1) and (d <= D):\n",
    "                d = np.min([d, T - d])\n",
    "                break\n",
    "\n",
    "        # fill in the next d steps of the chain\n",
    "        chain[t:(t+d), k] = z\n",
    "        t += d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matshow(chain.T[:, 500:1000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl_shape = 3\n",
    "bl_scale = 4\n",
    "# baselines should follow a different distribution\n",
    "bl = stats.gamma.rvs(a=bl_shape, scale=bl_scale, size=U) \n",
    "\n",
    "xx = np.linspace(0, 50, 1000)\n",
    "plt.plot(xx, stats.gamma.pdf(xx, a=bl_shape, scale=bl_scale))\n",
    "plt.title('Baseline firing distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firing rate effect distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# firing rates\n",
    "fr_shape = 15\n",
    "fr_rate = 15\n",
    "lam = np.empty((Kdata, U))\n",
    "\n",
    "xx = np.linspace(0, 5, 1000)\n",
    "for kk in xrange(Kdata):\n",
    "    offset = kk\n",
    "    this_shape = fr_shape + offset + kk\n",
    "    this_rate = fr_rate + offset\n",
    "    lam[kk, :] = stats.gamma.rvs(a=this_shape, scale=1/this_rate, size=U)\n",
    "\n",
    "\n",
    "    plt.plot(xx, stats.gamma.pdf(xx, a=this_shape, scale=1/this_rate), label=kk)\n",
    "plt.title('Category effect firing distribution');\n",
    "\n",
    "# reverse, so that effect 0 is biggest\n",
    "lam = lam[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overdispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if overdisp:\n",
    "    xx = np.linspace(0, 2, 300)\n",
    "    th_scale = 100\n",
    "    plt.plot(xx, stats.gamma.pdf(xx, a=th_scale, scale=1./th_scale))\n",
    "    plt.title('Overdispersion Effect');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just as above, make a set of Markov-esque regressors\n",
    "\n",
    "# number of regressors\n",
    "R = 3  \n",
    "\n",
    "# \"transition matrix\" -- want regressors to have some temporal coherence\n",
    "AX = np.array([[0.98, 0.05], [0.02, 0.95]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xchain = np.empty((T, R))\n",
    "\n",
    "Xchain[0, :] = 0  # start second category off\n",
    "for t in xrange(1, T):\n",
    "    for k in xrange(0, R):\n",
    "        Xchain[t, k] = stats.bernoulli.rvs(AX[1, Xchain[t - 1, k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matshow(Xchain.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xf = pd.DataFrame(Xchain, columns=map(lambda x: 'X' + str(x), xrange(R)))\n",
    "Xf.index.name = 'frame'\n",
    "Xf = Xf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make firing rate effects for each (regressor, unit)\n",
    "Xfr_shape = 45\n",
    "Xfr_scale = 1. / 45\n",
    "Xlam = stats.gamma.rvs(a=Xfr_shape, scale=Xfr_scale, size=(R, U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 5, 1000)\n",
    "plt.plot(xx, stats.gamma.pdf(xx, a=Xfr_shape, scale=Xfr_scale))\n",
    "plt.title('Regressor effect firing distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate firing rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\lambda_0$ be the baseline, $\\lambda_k$ the firing rate for latent category $i$ with binary indicator variable $z_{tk}$ and $\\nu_{r}$ be the firing rate effect for external regressor $r$ with value $x_{tr}$. Let $\\theta_{t}$ be an overdispersion factor for each time bin. The firing rate of unit $u$ at time $t$ is then given by\n",
    "\n",
    "$$\n",
    "\\mu_{tu} = \\lambda_{0u} \\theta_{tu} \\prod_k  \\lambda_{ku}^{z_{tk}}\n",
    "\\prod_r \\nu_{ru}^{x_{tr}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate rate within each time bin\n",
    "fr = bl * np.exp(chain.dot(np.log(lam)) + Xchain.dot(np.log(Xlam))) * dt\n",
    "fr += 1e-5  # in case we get exactly 0\n",
    "\n",
    "# add overdispersion\n",
    "if overdisp:\n",
    "    theta = stats.gamma.rvs(a=10, scale=1./10, size=fr.shape)\n",
    "    fr *= theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get a crude sense of population firing\n",
    "plt.hist(fr.ravel() / dt, bins=1000);\n",
    "plt.xlim(0, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matshow(fr.T / dt, vmax=30);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# draw from Poisson\n",
    "N = stats.poisson.rvs(fr)\n",
    "matshow(N.T, vmax=1);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make count frame\n",
    "df = pd.DataFrame(N)\n",
    "df.index.name = 'frame'\n",
    "df = df.reset_index()\n",
    "df = pd.melt(df, id_vars='frame')\n",
    "df.columns = ['frame', 'unit', 'count']\n",
    "df['movie'] = 1\n",
    "\n",
    "df = df.merge(Xf)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, convert (frame, movie) pairs to unique times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = frames_to_times(df)\n",
    "M = df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors on baseline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a hierarchical model for both baselines and firing rate effects, with  \n",
    "$$\n",
    "\\lambda_{u} \\sim \\mathrm{Ga}(c, c\\theta) \\\\\n",
    "c \\sim \\text{Ga}(s, r) \\\\\n",
    "\\theta \\sim \\text{Ga}(t, w) \\\\\n",
    "\\mathbb{E}[\\lambda_{u}] = \\frac{1}{\\theta} \\\\\n",
    "\\mathrm{var}[\\lambda_{u}] = \\frac{1}{c \\theta^2}\n",
    "$$\n",
    "In other words, we can think of $\\frac{1}{\\theta}$ as a *mean parameter* and $\\frac{1}{c}$ as a *variance parameter*.\n",
    "\n",
    "We want the baseline rates to have a fairly reasonable prior and the effect rates to have a very sparse prior, closely concentrated around 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will help us get a sense of the distribution on $\\lambda$ induced by our hyperparameter choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl_mean_shape = 2.\n",
    "bl_mean_rate = 40 * dt  # actual parameter should be per-bin rate\n",
    "bl_shape_shape = 30.\n",
    "bl_shape_rate = 30.\n",
    "\n",
    "baseline_dict = ({\n",
    "            'prior_shape_shape': bl_shape_shape, \n",
    "            'prior_shape_rate': bl_shape_rate, \n",
    "            'prior_mean_shape': bl_mean_shape, \n",
    "            'prior_mean_rate': bl_mean_rate})\n",
    "\n",
    "# make some plots\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "xx = np.linspace(0, 50, 1000)\n",
    "plt.plot(xx, stats.invgamma.pdf(xx, a=bl_mean_shape, scale=bl_mean_rate / dt))\n",
    "plt.title('baseline mean parameter prior');\n",
    "plt.xlabel('spikes per second')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "xx = np.linspace(0, 80, 1000)\n",
    "plt.plot(xx, stats.invgamma.pdf(xx, a=bl_shape_shape, scale=bl_shape_rate))\n",
    "plt.title('baseline variance parameter prior');\n",
    "plt.xlim(0, 15)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "samples = gamma_from_hypers([bl_mean_shape, bl_mean_rate], \n",
    "                            [bl_shape_shape, bl_shape_rate], 1e5)\n",
    "sns.kdeplot(samples / dt, gridsize=1e4, clip=(0, 150))\n",
    "plt.title(r'$\\lambda$ baseline prior distribution')\n",
    "plt.xlim(0, 100);\n",
    "plt.xlabel('spikes per second');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors on latent firing rate effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set number of categories to fit\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr_shape_shape = 2. * np.ones((K,))\n",
    "fr_shape_rate = (.01 / T) * np.ones((K,))\n",
    "fr_mean_shape = 0.4 * T * np.ones((K,))\n",
    "fr_mean_rate = 0.4 * T * np.ones((K,))\n",
    "\n",
    "fr_latent_dict = ({\n",
    "            'prior_shape_shape': fr_shape_shape, \n",
    "            'prior_shape_rate': fr_shape_rate, \n",
    "            'prior_mean_shape': fr_mean_shape, \n",
    "            'prior_mean_rate': fr_mean_rate})\n",
    "\n",
    "# make some plots\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "xx = np.linspace(0, 2, 500)\n",
    "plt.plot(xx, stats.invgamma.pdf(xx, a=fr_mean_shape[0], scale=fr_mean_rate[0]))\n",
    "plt.title('effect mean parameter prior');\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "xx = np.linspace(0, 0.01, 500)\n",
    "plt.plot(xx, stats.invgamma.logpdf(xx, a=fr_shape_shape[0], scale=fr_shape_rate[0]))\n",
    "plt.title('effect variance parameter prior');\n",
    "plt.ylabel('log probability density')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "samples = gamma_from_hypers([fr_mean_shape[0], fr_mean_rate[0]], \n",
    "                            [fr_shape_shape[0], fr_shape_rate[0]], 1e5)\n",
    "sns.kdeplot(samples, gridsize=5000, clip=(0, 5))\n",
    "plt.title(r'$\\lambda$ effect prior distribution')\n",
    "plt.xlim(0, 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors on semi-Markov model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $A$, $\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### A ###############\n",
    "A_off = 10.\n",
    "A_on = 1.\n",
    "Avec = np.r_[A_off, A_on].reshape(2, 1, 1)\n",
    "A_prior = np.tile(Avec, (1, 2, K))\n",
    "\n",
    "###### pi ###############\n",
    "pi_off = 15.\n",
    "pi_on = 1.\n",
    "pi_prior = np.tile(np.r_[pi_off, pi_on].reshape(2, 1), (1, K))\n",
    "\n",
    "latent_dict = {'A_prior': A_prior, 'pi_prior': pi_prior}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(xx, stats.beta.pdf(xx, A_prior[1, 0, 0], A_prior[0, 0, 0]))\n",
    "plt.title(r'Transition $0 \\rightarrow 1$');\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(xx, stats.beta.pdf(xx, A_prior[1, 1, 0], A_prior[0, 1, 0]))\n",
    "plt.title(r'Transition $1 \\rightarrow 1$');\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(xx, stats.beta.pdf(xx, pi_prior[1, 0], pi_prior[0, 0]))\n",
    "plt.title('Initial state value');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_hypers = (2.5, 4., 2., 40.)\n",
    "drng = (min(dvec), max(dvec))\n",
    "samples = lognormal_from_hypers(*d_hypers, N=1e6)\n",
    "sns.kdeplot(samples, gridsize=1000, clip=drng);\n",
    "plt.xlim(*drng);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_pars = ({'d_prior_mean': d_hypers[0] * np.ones((Mz, K)), \n",
    "          'd_prior_scaling': d_hypers[1] * np.ones((Mz, K)),\n",
    "          'd_prior_shape': d_hypers[2] * np.ones((Mz, K)),\n",
    "          'd_prior_rate': d_hypers[3] * np.ones((Mz, K))})\n",
    "\n",
    "latent_dict.update(d_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors on $\\theta$ (overdispersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "od_shape = 6.\n",
    "od_rate = 5.\n",
    "od_dict = {'prior_shape': od_shape * np.ones((M,)), 'prior_rate': od_rate * np.ones((M,))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 4, 100)\n",
    "plt.plot(xx, stats.gamma.pdf(xx, a=od_shape, scale=1./od_rate))\n",
    "plt.title('Overdispersion effect prior');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors on $\\upsilon$ (regression coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ups_shape = 11.\n",
    "ups_rate = 10.\n",
    "reg_shape = ups_shape * np.ones((U, R))  # shape\n",
    "reg_rate = ups_rate * np.ones((U, R))  # rate\n",
    "\n",
    "reg_dict = {'prior_shape': reg_shape, 'prior_rate': reg_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 2, 100)\n",
    "plt.plot(xx, stats.gamma.pdf(xx, a=ups_shape, scale=1./ups_rate))\n",
    "plt.title('Regression effect prior');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial guesses for posterior parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# baseline posteriors\n",
    "bld = ({'post_shape_shape': bl_shape_shape, 'post_shape_rate': bl_shape_rate, \n",
    "        'post_mean_shape': bl_mean_shape, 'post_mean_rate': bl_mean_rate,\n",
    "        'post_child_shape': np.ones((U,)), 'post_child_rate': np.ones((U,))})\n",
    "baseline_dict.update(bld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# firing rate effects for latents\n",
    "frd = ({'post_shape_shape': fr_shape_shape, 'post_shape_rate': fr_shape_rate, \n",
    "        'post_mean_shape': fr_mean_shape, 'post_mean_rate': fr_mean_rate,\n",
    "        'post_child_shape': np.ones((U, K)), 'post_child_rate': np.ones((U, K))})\n",
    "fr_latent_dict.update(frd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# latent states\n",
    "\n",
    "# E[z]\n",
    "# initialize pretty much at random (10% 1's)\n",
    "rand_frac = 0.05\n",
    "xi_mat = (rand_frac >= np.random.rand(T, K))\n",
    "xi_mat = xi_mat.astype('float')\n",
    "z_prior = np.dstack([1 - xi_mat, xi_mat]).transpose((2, 0, 1))\n",
    "\n",
    "# E[zz]\n",
    "Xi_mat = rand_frac >= np.random.rand(2, 2, T - 1, K)\n",
    "Xi_mat = Xi_mat.astype('float')\n",
    "\n",
    "ld = ({'A_post': A_prior, 'pi_post': pi_prior, 'z_init': z_prior,\n",
    "       'zz_init': Xi_mat, 'logZ_init': np.zeros((K,))})\n",
    "latent_dict.update(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# durations\n",
    "d_inits = (3., 1., 1., 1.)\n",
    "\n",
    "d_post_pars = ({'d_post_mean': d_inits[0] * np.ones((Mz, K)), \n",
    "                'd_post_scaling': d_inits[1] * np.ones((Mz, K)),\n",
    "                'd_post_shape': d_inits[2] * np.ones((Mz, K)),\n",
    "                'd_post_rate': d_inits[3] * np.ones((Mz, K))})\n",
    "latent_dict.update(d_post_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# firing rate regressors\n",
    "# since we know exact update for a_mat, use that\n",
    "nn = df['count']\n",
    "uu = df['unit']\n",
    "NX = nn[:, np.newaxis] * df.iloc[:, -R:]\n",
    "a_mat = NX.groupby(uu).sum().values\n",
    "b_mat = a_mat.copy()\n",
    "\n",
    "reg_dict.update({'post_shape': a_mat, 'post_rate': b_mat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overdispersion\n",
    "od_dict.update({'post_shape': np.ones((M,)), 'post_rate': np.ones((M,))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference with random restarts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numstarts = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fitobjs = []\n",
    "Lvals = []\n",
    "for idx in xrange(numstarts):\n",
    "    gpm = gp.GammaModel(df, K, D)\n",
    "    gpm.initialize_baseline(**jitter_inits(baseline_dict, 0.25))\n",
    "    gpm.initialize_fr_latents(**jitter_inits(fr_latent_dict, 0.25))\n",
    "    gpm.initialize_latents(**jitter_inits(latent_dict, 0.25))\n",
    "    gpm.initialize_fr_regressors(**jitter_inits(reg_dict, 0.25))\n",
    "    if overdisp:\n",
    "        gpm.initialize_overdispersion(**jitter_inits(od_dict, 0.25))\n",
    "    gpm.finalize()\n",
    "    \n",
    "    print \"Start {} -----------------------\".format(idx)\n",
    "    %time gpm.do_inference(tol=1e-4, verbosity=2)\n",
    "    print \"Final L = {}\".format(gpm.L())\n",
    "    Lvals.append(gpm.L())\n",
    "    fitobjs.append(gpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pick out best fit\n",
    "bestind = np.argmax(Lvals)\n",
    "gpm = fitobjs[bestind]\n",
    "del fitobjs  # to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we correctly recover $z$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in on a small part of the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Trng = (500, 1000)\n",
    "matshow(chain.T[:, slice(*Trng)], vmin=0, vmax=1);\n",
    "xi = gpm.nodes['HMM'].nodes['z'].z[1]\n",
    "matshow(xi.T[:, slice(*Trng)], vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the whole time series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matshow(chain.T, vmin=0, vmax=1);\n",
    "matshow(xi.T, vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matshow(chain.T);\n",
    "plt.title('Actual states')\n",
    "matshow(xi.T, vmin=0, vmax=1);\n",
    "plt.title('Inferred states')\n",
    "matshow(fr.T / dt, vmax=30);\n",
    "plt.title('Actual firing rate')\n",
    "matshow(N.T, vmin=0, vmax=1);\n",
    "plt.title('Spike rastergram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match = (chain.T.dot(xi) + (1 - chain.T).dot(1 - xi)) / T\n",
    "mismatch = (chain.T.dot(1 - xi) + (1 - chain.T).dot(xi)) / T\n",
    "overlap = np.maximum(match, mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate overlap between actual and inferred latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the overlap as the maximum of the match or mismatch percentage. That is, if $x$ and $y$ are binary vectors, \n",
    "$$\n",
    "\\mathrm{overlap} = \\max \\{ \\mathbb{E}[xy + (1-x)(1-y)], \\mathbb{E}[(1-x)y + x(1-y)]\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matshow(overlap, vmin=0, vmax=1)\n",
    "plt.colorbar();\n",
    "plt.xlabel('Inferred categories');\n",
    "plt.ylabel('Actual categories');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to refresh us, here are the actual distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logd = np.log(dvec)\n",
    "for kk in xrange(Kdata):\n",
    "    plt.figure()\n",
    "    for m in xrange(Mz):\n",
    "        # plt distribution we drew from\n",
    "        plt.plot(logd, stats.norm.pdf(logd, loc=np.log(mm_dur)[m, kk], scale=ss_dur[m, kk]), label=str((kk, m)))\n",
    "        plt.title(\"Generating Duration distribution\")\n",
    "        xrng = plt.xlim()\n",
    "        \n",
    "    plt.gca().set_color_cycle(None)  # restart colors\n",
    "    for m in xrange(Mz):   \n",
    "        # histogram actual data run lengths\n",
    "        starts, lengths, vals = rle(chain[:, kk])\n",
    "        #sns.kdeplot(np.log(lengths[vals == m]), gridsize=1000, label=(kk, m))\n",
    "        plt.hist(np.log(lengths[vals==m]), bins=50, label=str((kk, m)), alpha=0.4, normed=True)\n",
    "        plt.xlim(xrng)\n",
    "        plt.title(\"Empirical distribution\")\n",
    "        \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now here are the inferred posteriors for the duration distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dnode = gpm.nodes['HMM'].nodes['d']\n",
    "par = dnode.parent\n",
    "\n",
    "logmeans = []\n",
    "logstds = []\n",
    "logd = np.log(dvec)\n",
    "for kk in xrange(K):\n",
    "    plt.figure()\n",
    "    for m in xrange(Mz):\n",
    "        lpd = np.exp(dnode.logpd())[m, :, kk]\n",
    "        \n",
    "        # calculate some summary stats\n",
    "        logdmean = logd.dot(lpd)\n",
    "        logdstd = np.sqrt(((logd - logdmean)**2).dot(lpd))\n",
    "        logmeans.append(logdmean)\n",
    "        logstds.append(logdstd)\n",
    "        \n",
    "        dpars = (par.post_mean[m, kk], par.post_scaling[m, kk], \n",
    "              par.post_shape[m, kk], par.post_rate[m, kk])\n",
    "        samples = np.around(lognormal_from_hypers(*dpars, N=5e4))\n",
    "        samples = samples[samples != 0]\n",
    "        plt.hist(np.log(samples), bins=50, label=str((kk, m)), alpha=0.4, normed=True)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.log(mm_dur).ravel(), ss_dur.ravel())\n",
    "plt.scatter(logmeans, logstds, color='g')\n",
    "plt.xlabel('Mean log(x)')\n",
    "plt.ylabel('Std log(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics for gamma-distributed variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what we get for $\\lambda$, $\\theta$, and $\\upsilon$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "th = gpm.nodes['baseline_mean']\n",
    "cc = gpm.nodes['baseline_shape']\n",
    "th_pars = [th.post_shape, th.post_rate]\n",
    "cc_pars = [cc.post_shape, cc.post_rate]\n",
    "samples = gamma_from_hypers(th_pars, cc_pars, 1e5)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "xx = np.linspace(0, 20, 500)\n",
    "plt.plot(xx, stats.invgamma.pdf(xx, a=th_pars[0], scale=th_pars[1]/dt))\n",
    "plt.title('Posterior for Baseline mean parameter');\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "xx = np.linspace(0, 2, 500)\n",
    "plt.plot(xx, stats.invgamma.pdf(xx, a=cc_pars[0], scale=cc_pars[1]))\n",
    "plt.title('Posterior for Baseline variance parameter');\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.kdeplot(samples / dt, gridsize=1e4, clip=(0, 100))\n",
    "plt.title(r'Posterior for $\\lambda$ baseline')\n",
    "plt.xlabel('Firing rate (Hz)')\n",
    "plt.xlim(0, 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "inferred_means = gpm.nodes['baseline'].expected_x() / dt\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(bl, bins=50, normed=True, alpha=0.25)\n",
    "plt.hist(inferred_means, bins=50, normed=True, alpha=0.25);\n",
    "plt.legend(['actual', 'inferred']);\n",
    "plt.title('Baseline firing rates');\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(bl, inferred_means);\n",
    "plt.xlim(0, 60)\n",
    "plt.ylim(0, 60)\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('inferred')\n",
    "plt.title('baseline rates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\lambda$ terms (firing rate latent effects for each unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "th = gpm.nodes['fr_latents_mean']\n",
    "cc = gpm.nodes['fr_latents_shape']\n",
    "th_pars = np.c_[th.post_shape, th.post_rate].T\n",
    "cc_pars = np.c_[cc.post_shape, cc.post_rate].T\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "xx = np.linspace(0, 2, 500)\n",
    "for kk in xrange(K):\n",
    "    plt.plot(xx, stats.invgamma.pdf(xx, a=th_pars[0, kk], scale=th_pars[1, kk]))\n",
    "plt.title('posterior mean parameter');\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "xx = np.linspace(0, 5, 500)\n",
    "for kk in xrange(K):\n",
    "    plt.plot(xx, stats.invgamma.pdf(xx, a=cc_pars[0, kk], scale=cc_pars[1, kk]))\n",
    "plt.title('posterior variance parameter');\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "for kk in xrange(K):\n",
    "    samples = gamma_from_hypers(th_pars[:, kk], cc_pars[:, kk], 1e5)\n",
    "    sns.kdeplot(samples, gridsize=1e4, clip=(0, 10), label=kk)\n",
    "plt.title(r'$\\lambda$ effect posterior distribution')\n",
    "plt.legend()\n",
    "plt.xlabel('Gain')\n",
    "plt.xlim(0, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(lam.ravel(), bins=50, normed=True, alpha=0.25)\n",
    "inferred_effects = gpm.nodes['fr_latents'].expected_x().ravel()\n",
    "plt.hist(inferred_effects, bins=50, normed=True, alpha=0.25);\n",
    "plt.legend(['actual', 'inferred']);\n",
    "plt.title('Firing rate effects');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\theta$ terms (overdispersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if overdisp:\n",
    "    inferred_means = gpm.nodes['overdispersion'].expected_x().ravel()\n",
    "    plt.hist(theta.ravel(), bins=500, normed=True, alpha=0.25)\n",
    "    plt.hist(inferred_means, bins=500, normed=True, alpha=0.25);\n",
    "    plt.legend(['actual', 'inferred']);\n",
    "    plt.title('Overdispersion effects');\n",
    "    plt.ylim(0, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(theta.ravel(), inferred_means, alpha=0.01);\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('inferred')\n",
    "plt.title('overdispersion');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\upsilon$ terms (regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inferred_means = gpm.nodes['fr_regressors'].expected_x().ravel()\n",
    "plt.hist(Xlam.ravel(), bins=50, normed=True, alpha=0.25)\n",
    "plt.hist(inferred_means, bins=50, normed=True, alpha=0.25);\n",
    "plt.legend(['actual', 'inferred']);\n",
    "plt.title('Regression effects');\n",
    "plt.ylim(0, 5);\n",
    "plt.xlim(0, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(Xlam.T.ravel(), inferred_means);\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('inferred')\n",
    "plt.title('regression weights');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
